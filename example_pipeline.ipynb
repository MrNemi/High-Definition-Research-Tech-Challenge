{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "train = pd.read_csv('./ae-data/training_set.csv')\n",
    "test = pd.read_csv('./ae-data/test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altered Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Harder to explain\" variables are:\n",
    "\n",
    "IMD_Decile_From_LSOA - IMD Decile Description. Goes from most deprived (1) to least deprived (10). Best to set to 5 if missing for now. The IMD Overall Ranking to identify which one of ten groups a Super Output Area belongs to, from most deprived through to least deprived.\n",
    "\n",
    "Sex - Based on the data dictionary, 1 for Male and 2 for Female, 9 for Indeterminate. Make 0 (unknown) for missing.\n",
    "\n",
    "AE_HRG - No idea. Not sure if it's important. Leaving it out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AE_Arrive_HourOfDay', 'ICD10_Chapter_Code', 'Treatment_Function_Code'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Removing columns with excessive number of null values\n",
    "## THIS CELL IS VERY MUCH EDITABLE\n",
    "\n",
    "# Define the threshold for missing values\n",
    "missing_threshold = 0.5\n",
    "\n",
    "# Identify columns in the training set that have more than 50% missing values\n",
    "# Not dropping after some exploratory analysis. When it's present it is a good (perfect?) indicator of if someone has been admitted.\n",
    "\n",
    "columns_to_drop_train = train.columns[((train.isnull().mean() > missing_threshold) & (train.columns != 'Length_Of_Stay_Days')) | (train.columns == 'AE_Arrive_HourOfDay')]\n",
    "\n",
    "print(columns_to_drop_train)\n",
    "\n",
    "# Drop these columns from the training set\n",
    "train_drop = train.drop(columns_to_drop_train, axis=1)\n",
    "\n",
    "# Drop the same columns from the test set\n",
    "test_drop = test.drop(columns_to_drop_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few acceptable data transformations\n",
    "# Set any null values in the 'Sex' column of test and train drop to 0\n",
    "\n",
    "train_drop['Sex'] = train_drop['Sex'].fillna(0)\n",
    "\n",
    "test_drop['Sex'] = test_drop['Sex'].fillna(0)\n",
    "\n",
    "# Set any null values in the 'Provider_Patient_Distance_Miles' column of test and train drop to the mean of the column\n",
    "\n",
    "train_drop['Provider_Patient_Distance_Miles'] = train_drop['Provider_Patient_Distance_Miles'].fillna(int(train_drop['Provider_Patient_Distance_Miles'].mean()))\n",
    "\n",
    "test_drop['Provider_Patient_Distance_Miles'] = test_drop['Provider_Patient_Distance_Miles'].fillna(int(train_drop['Provider_Patient_Distance_Miles'].mean()))\n",
    "\n",
    "\n",
    "# Set any null values in the 'IMD_Decile_From_LSOA' column of test and train drop to 5. This is the median value of the column.\n",
    "train_drop['IMD_Decile_From_LSOA'] = train_drop['IMD_Decile_From_LSOA'].fillna(5)\n",
    "\n",
    "test_drop['IMD_Decile_From_LSOA'] = test_drop['IMD_Decile_From_LSOA'].fillna(5)\n",
    "\n",
    "\n",
    "# Set any null values of 'Length_Of_Stays_Days' to 0. Throught it would make more sense for them not to have been put in the database rather than have stayed and not been recorded.\n",
    "\n",
    "train_drop['Length_Of_Stay_Days'] = train_drop['Provider_Patient_Distance_Miles'].fillna(0)\n",
    "\n",
    "test_drop['Length_Of_Stay_Days'] = test_drop['Provider_Patient_Distance_Miles'].fillna(0)\n",
    "\n",
    "\n",
    "# Replace 'NaN' in \"EA_HRG\" with the value \"Nothing\"\n",
    "\n",
    "train_drop['AE_HRG'] = train_drop['AE_HRG'].fillna('Nothing')\n",
    "\n",
    "test_drop['AE_HRG'] = test_drop['AE_HRG'].fillna('Nothing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Data removals\n",
    "# ## Planning to remove all null values for Arrival Hour. This is because it feels like a pretty important feature and there are only a couple hundred missing, doubt it will sway things too much.\n",
    "\n",
    "# train_drop = train_drop.dropna(subset=['AE_Arrive_HourOfDay'])\n",
    "\n",
    "# test_drop = test_drop.dropna(subset=['AE_Arrive_HourOfDay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMD_Decile_From_LSOA               0\n",
      "Age_Band                           0\n",
      "Sex                                0\n",
      "AE_Arrive_Date                     0\n",
      "AE_Time_Mins                       0\n",
      "AE_HRG                             0\n",
      "AE_Num_Diagnoses                   0\n",
      "AE_Num_Investigations              0\n",
      "AE_Num_Treatments                  0\n",
      "AE_Arrival_Mode                    0\n",
      "Provider_Patient_Distance_Miles    0\n",
      "ProvID                             0\n",
      "Admitted_Flag                      0\n",
      "Length_Of_Stay_Days                0\n",
      "Record_ID                          0\n",
      "dtype: int64\n",
      "IMD_Decile_From_LSOA               0\n",
      "Age_Band                           0\n",
      "Sex                                0\n",
      "AE_Arrive_Date                     0\n",
      "AE_Time_Mins                       0\n",
      "AE_HRG                             0\n",
      "AE_Num_Diagnoses                   0\n",
      "AE_Num_Investigations              0\n",
      "AE_Num_Treatments                  0\n",
      "AE_Arrival_Mode                    0\n",
      "Provider_Patient_Distance_Miles    0\n",
      "ProvID                             0\n",
      "Length_Of_Stay_Days                0\n",
      "Record_ID                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count of missing values in the training set\n",
    "print(train_drop.isnull().sum())\n",
    "\n",
    "# Count of missing values in the test set\n",
    "print(test_drop.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Val Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the training data into training and validation sets\n",
    "\n",
    "# Set the proportion of the dataset to include in the test split\n",
    "test_size = 0.20\n",
    "# Set the proportion of the training dataset to include in the validation split\n",
    "validation_size = 0.25\n",
    "\n",
    "# Separate the features and the target variable in the training set\n",
    "X_train = train_drop.drop('Admitted_Flag', axis=1)\n",
    "y_train = train_drop['Admitted_Flag']\n",
    "\n",
    "# Drop 'ProvID' from both sets\n",
    "X_train = X_train.drop('ProvID', axis=1)\n",
    "output_test = test_drop.drop('ProvID', axis=1)\n",
    "\n",
    "# Drop 'Record_ID' from the training set\n",
    "X_train = X_train.drop('Record_ID', axis=1)\n",
    "\n",
    "# Keep a copy of 'Record_ID' from the test set and then drop it from the test set\n",
    "test_record_id = output_test['Record_ID']\n",
    "output_test = output_test.drop('Record_ID', axis=1)\n",
    "\n",
    "# Split the training data into a smaller training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=test_size, random_state=42)\n",
    "\n",
    "# Split the training data into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Categroical variables in our dataset are:\n",
    "\n",
    "- Age Band\n",
    "- AE_Arrive_HourOfDay\n",
    "- AE_HRG\n",
    "\n",
    "We will perform one-hot encoding on the following variables:\n",
    "\n",
    "- AE_Arrive_HourOfDay\n",
    "- AE_HRG\n",
    "\n",
    "And we will perfrom ordinal encoding on the following variables (this is we want to preserve the order of the categories, since they aren't really independent of each other):\n",
    "\n",
    "- Age Band (There is a natural ordering to the age bands. If this fucks up classification downstream, we should try making this one-hot as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_encoded = pd.get_dummies(train_drop, columns=['AE_Arrive_HourOfDay','AE_HRG'])\n",
    "X_train = pd.get_dummies(X_train, columns=['AE_HRG'])\n",
    "X_test = pd.get_dummies(X_test, columns=['AE_HRG'])\n",
    "X_val = pd.get_dummies(X_val, columns=['AE_HRG'])\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "encoder.fit(X_train[['Age_Band']])\n",
    "\n",
    "X_train['Age_Band'] = encoder.transform(X_train[['Age_Band']])\n",
    "X_test['Age_Band'] = encoder.transform(X_test[['Age_Band']])\n",
    "X_val['Age_Band'] = encoder.transform(X_val[['Age_Band']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convert to datetime format\n",
    "X_train['AE_Arrive_Date'] = pd.to_datetime(X_train['AE_Arrive_Date'])\n",
    "X_test['AE_Arrive_Date'] = pd.to_datetime(X_test['AE_Arrive_Date'])\n",
    "X_val['AE_Arrive_Date'] = pd.to_datetime(X_val['AE_Arrive_Date'])\n",
    "\n",
    "# Then extract date components\n",
    "for df in [X_train, X_test, X_val]:\n",
    "    df['Arrival_Year'] = df['AE_Arrive_Date'].dt.year\n",
    "    df['Arrival_Month'] = df['AE_Arrive_Date'].dt.month\n",
    "    df['Arrival_Day'] = df['AE_Arrive_Date'].dt.day\n",
    "    df['Arrival_DayOfWeek'] = df['AE_Arrive_Date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# Drop the original 'AE_Arrive_Date' field\n",
    "X_train.drop('AE_Arrive_Date', axis=1, inplace=True)\n",
    "X_test.drop('AE_Arrive_Date', axis=1, inplace=True)\n",
    "X_val.drop('AE_Arrive_Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose standardization or min-max scaling\n",
    "# This is not needed for decision trees and random forests as they are not affected by the scale of the data\n",
    "# Needed for logistic regression, SVM, perceptron, kNN, neural networks, etc.\n",
    "\n",
    "# scaler = StandardScaler() - resulting distribution has a mean of 0 and a standard deviation of 1\n",
    "scaler = MinMaxScaler()  # - transforms your data to a range between 0 and 1\n",
    "\n",
    "# Fit on training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both training and test data\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "X_val = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN, THAT (HYPERPARAMETER GRID SEARCH) MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define hyperparameter grids for each model\n",
    "# param_grid_lr = {\n",
    "#     'lr__C': [5, 10, 15, 20],\n",
    "#     'lr__penalty': ['l1', 'l2'],\n",
    "#     'lr__solver': ['liblinear']\n",
    "# }\n",
    "\n",
    "# param_grid_rf = {\n",
    "#     'rf__n_estimators': [200, 250, 300],\n",
    "#     'rf__max_depth': [None, 8, 10, 12, 14],\n",
    "#     'rf__min_samples_split': [2, 5, 10],\n",
    "#     'rf__min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# param_grid_svm = {\n",
    "#     'svm__C': [5, 10, 15, 20],\n",
    "#     'svm__kernel': ['linear', 'rbf', 'poly'],\n",
    "#     'svm__degree': [2, 3, 4]\n",
    "# }\n",
    "\n",
    "\n",
    "# # Random Forests pipeline\n",
    "# pipeline_rf = Pipeline([\n",
    "#     ('rf', RandomForestClassifier(random_state=42))\n",
    "# ])\n",
    "\n",
    "# # SVM pipeline\n",
    "# pipeline_svm = Pipeline([\n",
    "#     ('svm', SVC(random_state=42))\n",
    "# ])\n",
    "\n",
    "# # Logistic Regression pipeline\n",
    "# pipeline_lr = Pipeline([\n",
    "#     ('lr', LogisticRegression(random_state=42))\n",
    "# ])\n",
    "\n",
    "# param_grids = [param_grid_rf, param_grid_svm, param_grid_lr]\n",
    "# pipelines = [pipeline_rf, pipeline_svm, pipeline_lr]\n",
    "# pipeline_names = ['Random Forests', 'SVM', 'Logistic Regression']\n",
    "\n",
    "# for i, (pipeline, param_grid) in enumerate(zip(pipelines, param_grids)):\n",
    "#     grid_search = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#     # Fit the pipeline on the training data\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     best_params = grid_search.best_params_\n",
    "#     best_pipeline = grid_search.best_estimator_   \n",
    "\n",
    "#     # Display the best hyperparameters\n",
    "#     print(f\"Best hyperparameters for {pipeline_names[i]}: {best_params}\")\n",
    "     \n",
    "#     # Make predictions on the validation data\n",
    "#     y_val_pred = best_pipeline.predict(X_val)\n",
    "    \n",
    "#     # Evaluate the predictions\n",
    "#     accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "#     print(f'{pipeline_names[i]} validation accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slightly more advanced models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Class Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: input_dim --> 128\n",
    "        self.fc1 = nn.Linear(input_dim, 128) \n",
    "        # Non-linearity 1\n",
    "        self.relu1 = nn.Tanh()\n",
    "        \n",
    "        # Linear function 2: 128 --> 64\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.Tanh()\n",
    "\n",
    "        # Linear function 3: 64 --> 32\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        # Non-linearity 3\n",
    "        self.relu3 = nn.Tanh()\n",
    "        \n",
    "        # Linear function 4 (readout): 32 --> 1\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        # Sigmoid function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for the neural network\n",
    "\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "batch_sizes = [32, 64, 128, 256]\n",
    "optimizers = [optim.Adam, optim.RMSprop, optim.SGD]\n",
    "epochs_range = [50, 200, 500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the variables to work with Torch\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = FeedforwardNeuralNetModel(input_dim)\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_train_tensor = y_train_tensor.view(y_train_tensor.shape[0], 1)  # Reshaping to match output shape\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "y_val_tensor = y_val_tensor.view(y_val_tensor.shape[0], 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and validate the model\n",
    "def train_and_validate(model, criterion, optimizer, train_loader, val_loader, epochs, trial):\n",
    "    best_accuracy = 0.0\n",
    "    best_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 10\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Average Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        total_val_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "\n",
    "                val_outputs = model(X_val_batch)\n",
    "                val_loss = criterion(val_outputs, y_val_batch)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                val_preds = (val_outputs > 0.5).float()\n",
    "                correct_preds += (val_preds == y_val_batch).sum().item()\n",
    "                total_preds += y_val_batch.size(0)\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_accuracy = correct_preds / total_preds\n",
    "\n",
    "        # Check if validation loss has improved\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Check if we have waited for too long without improvement.\n",
    "        # Sign of overfitting\n",
    "        if patience_counter > patience:\n",
    "            print(f\"Early stopping at epoch {epoch}. Best loss was {best_val_loss:.4f}\")\n",
    "            break\n",
    "\n",
    "        if avg_val_accuracy > best_accuracy:\n",
    "            best_accuracy = avg_val_accuracy\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Average Validation Loss: {avg_val_loss:.4f}, Average Validation Accuracy: {avg_val_accuracy:.4f}')\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_accuracy:.4f} at epoch {best_epoch} for trial {trial}')\n",
    "\n",
    "    return best_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Average Training Loss: 0.6799\n",
      "Epoch [1/500], Average Validation Loss: 0.6643, Average Validation Accuracy: 0.7071\n",
      "Epoch [2/500], Average Training Loss: 0.6441\n",
      "Epoch [2/500], Average Validation Loss: 0.6199, Average Validation Accuracy: 0.7469\n",
      "Epoch [3/500], Average Training Loss: 0.5922\n",
      "Epoch [3/500], Average Validation Loss: 0.5643, Average Validation Accuracy: 0.7552\n",
      "Epoch [4/500], Average Training Loss: 0.5401\n",
      "Epoch [4/500], Average Validation Loss: 0.5190, Average Validation Accuracy: 0.7685\n",
      "Epoch [5/500], Average Training Loss: 0.5027\n",
      "Epoch [5/500], Average Validation Loss: 0.4900, Average Validation Accuracy: 0.7821\n",
      "Epoch [6/500], Average Training Loss: 0.4793\n",
      "Epoch [6/500], Average Validation Loss: 0.4727, Average Validation Accuracy: 0.7889\n",
      "Epoch [7/500], Average Training Loss: 0.4656\n",
      "Epoch [7/500], Average Validation Loss: 0.4629, Average Validation Accuracy: 0.7951\n",
      "Epoch [8/500], Average Training Loss: 0.4577\n",
      "Epoch [8/500], Average Validation Loss: 0.4573, Average Validation Accuracy: 0.7973\n",
      "Epoch [9/500], Average Training Loss: 0.4530\n",
      "Epoch [9/500], Average Validation Loss: 0.4540, Average Validation Accuracy: 0.7982\n",
      "Epoch [10/500], Average Training Loss: 0.4500\n",
      "Epoch [10/500], Average Validation Loss: 0.4518, Average Validation Accuracy: 0.7991\n",
      "Epoch [11/500], Average Training Loss: 0.4478\n",
      "Epoch [11/500], Average Validation Loss: 0.4501, Average Validation Accuracy: 0.7995\n",
      "Epoch [12/500], Average Training Loss: 0.4462\n",
      "Epoch [12/500], Average Validation Loss: 0.4488, Average Validation Accuracy: 0.7994\n",
      "Epoch [13/500], Average Training Loss: 0.4448\n",
      "Epoch [13/500], Average Validation Loss: 0.4477, Average Validation Accuracy: 0.7998\n",
      "Epoch [14/500], Average Training Loss: 0.4438\n",
      "Epoch [14/500], Average Validation Loss: 0.4467, Average Validation Accuracy: 0.8004\n",
      "Epoch [15/500], Average Training Loss: 0.4428\n",
      "Epoch [15/500], Average Validation Loss: 0.4458, Average Validation Accuracy: 0.8010\n",
      "Epoch [16/500], Average Training Loss: 0.4418\n",
      "Epoch [16/500], Average Validation Loss: 0.4451, Average Validation Accuracy: 0.8014\n",
      "Epoch [17/500], Average Training Loss: 0.4411\n",
      "Epoch [17/500], Average Validation Loss: 0.4443, Average Validation Accuracy: 0.8018\n",
      "Epoch [18/500], Average Training Loss: 0.4404\n",
      "Epoch [18/500], Average Validation Loss: 0.4436, Average Validation Accuracy: 0.8026\n",
      "Epoch [19/500], Average Training Loss: 0.4397\n",
      "Epoch [19/500], Average Validation Loss: 0.4430, Average Validation Accuracy: 0.8028\n",
      "Epoch [20/500], Average Training Loss: 0.4391\n",
      "Epoch [20/500], Average Validation Loss: 0.4425, Average Validation Accuracy: 0.8026\n",
      "Epoch [21/500], Average Training Loss: 0.4386\n",
      "Epoch [21/500], Average Validation Loss: 0.4419, Average Validation Accuracy: 0.8028\n",
      "Epoch [22/500], Average Training Loss: 0.4381\n",
      "Epoch [22/500], Average Validation Loss: 0.4414, Average Validation Accuracy: 0.8036\n",
      "Epoch [23/500], Average Training Loss: 0.4375\n",
      "Epoch [23/500], Average Validation Loss: 0.4408, Average Validation Accuracy: 0.8034\n",
      "Epoch [24/500], Average Training Loss: 0.4371\n",
      "Epoch [24/500], Average Validation Loss: 0.4404, Average Validation Accuracy: 0.8040\n",
      "Epoch [25/500], Average Training Loss: 0.4367\n",
      "Epoch [25/500], Average Validation Loss: 0.4400, Average Validation Accuracy: 0.8044\n",
      "Epoch [26/500], Average Training Loss: 0.4363\n",
      "Epoch [26/500], Average Validation Loss: 0.4395, Average Validation Accuracy: 0.8046\n",
      "Epoch [27/500], Average Training Loss: 0.4359\n",
      "Epoch [27/500], Average Validation Loss: 0.4391, Average Validation Accuracy: 0.8039\n",
      "Epoch [28/500], Average Training Loss: 0.4354\n",
      "Epoch [28/500], Average Validation Loss: 0.4388, Average Validation Accuracy: 0.8054\n",
      "Epoch [29/500], Average Training Loss: 0.4351\n",
      "Epoch [29/500], Average Validation Loss: 0.4385, Average Validation Accuracy: 0.8044\n",
      "Epoch [30/500], Average Training Loss: 0.4348\n",
      "Epoch [30/500], Average Validation Loss: 0.4381, Average Validation Accuracy: 0.8052\n",
      "Epoch [31/500], Average Training Loss: 0.4344\n",
      "Epoch [31/500], Average Validation Loss: 0.4377, Average Validation Accuracy: 0.8051\n",
      "Epoch [32/500], Average Training Loss: 0.4341\n",
      "Epoch [32/500], Average Validation Loss: 0.4374, Average Validation Accuracy: 0.8055\n",
      "Epoch [33/500], Average Training Loss: 0.4338\n",
      "Epoch [33/500], Average Validation Loss: 0.4372, Average Validation Accuracy: 0.8056\n",
      "Epoch [34/500], Average Training Loss: 0.4336\n",
      "Epoch [34/500], Average Validation Loss: 0.4369, Average Validation Accuracy: 0.8061\n",
      "Epoch [35/500], Average Training Loss: 0.4334\n",
      "Epoch [35/500], Average Validation Loss: 0.4366, Average Validation Accuracy: 0.8063\n",
      "Epoch [36/500], Average Training Loss: 0.4330\n",
      "Epoch [36/500], Average Validation Loss: 0.4364, Average Validation Accuracy: 0.8065\n",
      "Epoch [37/500], Average Training Loss: 0.4328\n",
      "Epoch [37/500], Average Validation Loss: 0.4361, Average Validation Accuracy: 0.8072\n",
      "Epoch [38/500], Average Training Loss: 0.4326\n",
      "Epoch [38/500], Average Validation Loss: 0.4359, Average Validation Accuracy: 0.8077\n",
      "Epoch [39/500], Average Training Loss: 0.4324\n",
      "Epoch [39/500], Average Validation Loss: 0.4358, Average Validation Accuracy: 0.8074\n",
      "Epoch [40/500], Average Training Loss: 0.4322\n",
      "Epoch [40/500], Average Validation Loss: 0.4355, Average Validation Accuracy: 0.8076\n",
      "Epoch [41/500], Average Training Loss: 0.4320\n",
      "Epoch [41/500], Average Validation Loss: 0.4353, Average Validation Accuracy: 0.8086\n",
      "Epoch [42/500], Average Training Loss: 0.4318\n",
      "Epoch [42/500], Average Validation Loss: 0.4351, Average Validation Accuracy: 0.8080\n",
      "Epoch [43/500], Average Training Loss: 0.4316\n",
      "Epoch [43/500], Average Validation Loss: 0.4351, Average Validation Accuracy: 0.8085\n",
      "Epoch [44/500], Average Training Loss: 0.4315\n",
      "Epoch [44/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8083\n",
      "Epoch [45/500], Average Training Loss: 0.4313\n",
      "Epoch [45/500], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8095\n",
      "Epoch [46/500], Average Training Loss: 0.4312\n",
      "Epoch [46/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8085\n",
      "Epoch [47/500], Average Training Loss: 0.4311\n",
      "Epoch [47/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8089\n",
      "Epoch [48/500], Average Training Loss: 0.4308\n",
      "Epoch [48/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8097\n",
      "Epoch [49/500], Average Training Loss: 0.4308\n",
      "Epoch [49/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8098\n",
      "Epoch [50/500], Average Training Loss: 0.4307\n",
      "Epoch [50/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8098\n",
      "Epoch [51/500], Average Training Loss: 0.4306\n",
      "Epoch [51/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8096\n",
      "Epoch [52/500], Average Training Loss: 0.4304\n",
      "Epoch [52/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8106\n",
      "Epoch [53/500], Average Training Loss: 0.4303\n",
      "Epoch [53/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8101\n",
      "Epoch [54/500], Average Training Loss: 0.4302\n",
      "Epoch [54/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8099\n",
      "Epoch [55/500], Average Training Loss: 0.4301\n",
      "Epoch [55/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8101\n",
      "Epoch [56/500], Average Training Loss: 0.4300\n",
      "Epoch [56/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8104\n",
      "Epoch [57/500], Average Training Loss: 0.4300\n",
      "Epoch [57/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8102\n",
      "Epoch [58/500], Average Training Loss: 0.4297\n",
      "Epoch [58/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8109\n",
      "Epoch [59/500], Average Training Loss: 0.4298\n",
      "Epoch [59/500], Average Validation Loss: 0.4330, Average Validation Accuracy: 0.8107\n",
      "Epoch [60/500], Average Training Loss: 0.4297\n",
      "Epoch [60/500], Average Validation Loss: 0.4329, Average Validation Accuracy: 0.8115\n",
      "Epoch [61/500], Average Training Loss: 0.4296\n",
      "Epoch [61/500], Average Validation Loss: 0.4328, Average Validation Accuracy: 0.8108\n",
      "Epoch [62/500], Average Training Loss: 0.4295\n",
      "Epoch [62/500], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8110\n",
      "Epoch [63/500], Average Training Loss: 0.4294\n",
      "Epoch [63/500], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8113\n",
      "Epoch [64/500], Average Training Loss: 0.4294\n",
      "Epoch [64/500], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8112\n",
      "Epoch [65/500], Average Training Loss: 0.4292\n",
      "Epoch [65/500], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8115\n",
      "Epoch [66/500], Average Training Loss: 0.4292\n",
      "Epoch [66/500], Average Validation Loss: 0.4324, Average Validation Accuracy: 0.8116\n",
      "Epoch [67/500], Average Training Loss: 0.4291\n",
      "Epoch [67/500], Average Validation Loss: 0.4324, Average Validation Accuracy: 0.8112\n",
      "Epoch [68/500], Average Training Loss: 0.4291\n",
      "Epoch [68/500], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8111\n",
      "Epoch [69/500], Average Training Loss: 0.4290\n",
      "Epoch [69/500], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8117\n",
      "Epoch [70/500], Average Training Loss: 0.4289\n",
      "Epoch [70/500], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8114\n",
      "Epoch [71/500], Average Training Loss: 0.4288\n",
      "Epoch [71/500], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8115\n",
      "Epoch [72/500], Average Training Loss: 0.4288\n",
      "Epoch [72/500], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8114\n",
      "Epoch [73/500], Average Training Loss: 0.4287\n",
      "Epoch [73/500], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8115\n",
      "Epoch [74/500], Average Training Loss: 0.4286\n",
      "Epoch [74/500], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8118\n",
      "Epoch [75/500], Average Training Loss: 0.4286\n",
      "Epoch [75/500], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8115\n",
      "Epoch [76/500], Average Training Loss: 0.4285\n",
      "Epoch [76/500], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8112\n",
      "Epoch [77/500], Average Training Loss: 0.4284\n",
      "Epoch [77/500], Average Validation Loss: 0.4317, Average Validation Accuracy: 0.8115\n",
      "Epoch [78/500], Average Training Loss: 0.4285\n",
      "Epoch [78/500], Average Validation Loss: 0.4317, Average Validation Accuracy: 0.8117\n",
      "Epoch [79/500], Average Training Loss: 0.4283\n",
      "Epoch [79/500], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8117\n",
      "Epoch [80/500], Average Training Loss: 0.4283\n",
      "Epoch [80/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8118\n",
      "Epoch [81/500], Average Training Loss: 0.4282\n",
      "Epoch [81/500], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8115\n",
      "Epoch [82/500], Average Training Loss: 0.4281\n",
      "Epoch [82/500], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8115\n",
      "Epoch [83/500], Average Training Loss: 0.4281\n",
      "Epoch [83/500], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8117\n",
      "Epoch [84/500], Average Training Loss: 0.4279\n",
      "Epoch [84/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8117\n",
      "Epoch [85/500], Average Training Loss: 0.4280\n",
      "Epoch [85/500], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8116\n",
      "Epoch [86/500], Average Training Loss: 0.4279\n",
      "Epoch [86/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8108\n",
      "Epoch [87/500], Average Training Loss: 0.4278\n",
      "Epoch [87/500], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8115\n",
      "Epoch [88/500], Average Training Loss: 0.4278\n",
      "Epoch [88/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8119\n",
      "Epoch [89/500], Average Training Loss: 0.4277\n",
      "Epoch [89/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8115\n",
      "Epoch [90/500], Average Training Loss: 0.4276\n",
      "Epoch [90/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8125\n",
      "Epoch [91/500], Average Training Loss: 0.4275\n",
      "Epoch [91/500], Average Validation Loss: 0.4309, Average Validation Accuracy: 0.8120\n",
      "Epoch [92/500], Average Training Loss: 0.4275\n",
      "Epoch [92/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8126\n",
      "Epoch [93/500], Average Training Loss: 0.4275\n",
      "Epoch [93/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8117\n",
      "Epoch [94/500], Average Training Loss: 0.4274\n",
      "Epoch [94/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8119\n",
      "Epoch [95/500], Average Training Loss: 0.4274\n",
      "Epoch [95/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8118\n",
      "Epoch [96/500], Average Training Loss: 0.4272\n",
      "Epoch [96/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8121\n",
      "Epoch [97/500], Average Training Loss: 0.4272\n",
      "Epoch [97/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8124\n",
      "Epoch [98/500], Average Training Loss: 0.4271\n",
      "Epoch [98/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8121\n",
      "Epoch [99/500], Average Training Loss: 0.4270\n",
      "Epoch [99/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8122\n",
      "Epoch [100/500], Average Training Loss: 0.4270\n",
      "Epoch [100/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8119\n",
      "Epoch [101/500], Average Training Loss: 0.4269\n",
      "Epoch [101/500], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8119\n",
      "Epoch [102/500], Average Training Loss: 0.4269\n",
      "Epoch [102/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8122\n",
      "Epoch [103/500], Average Training Loss: 0.4269\n",
      "Epoch [103/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8113\n",
      "Epoch [104/500], Average Training Loss: 0.4268\n",
      "Epoch [104/500], Average Validation Loss: 0.4302, Average Validation Accuracy: 0.8118\n",
      "Epoch [105/500], Average Training Loss: 0.4267\n",
      "Epoch [105/500], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8123\n",
      "Epoch [106/500], Average Training Loss: 0.4266\n",
      "Epoch [106/500], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8123\n",
      "Epoch [107/500], Average Training Loss: 0.4265\n",
      "Epoch [107/500], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8120\n",
      "Epoch [108/500], Average Training Loss: 0.4265\n",
      "Epoch [108/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8125\n",
      "Epoch [109/500], Average Training Loss: 0.4265\n",
      "Epoch [109/500], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8122\n",
      "Epoch [110/500], Average Training Loss: 0.4264\n",
      "Epoch [110/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8125\n",
      "Epoch [111/500], Average Training Loss: 0.4263\n",
      "Epoch [111/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8127\n",
      "Epoch [112/500], Average Training Loss: 0.4263\n",
      "Epoch [112/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8127\n",
      "Epoch [113/500], Average Training Loss: 0.4261\n",
      "Epoch [113/500], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8122\n",
      "Epoch [114/500], Average Training Loss: 0.4261\n",
      "Epoch [114/500], Average Validation Loss: 0.4297, Average Validation Accuracy: 0.8123\n",
      "Epoch [115/500], Average Training Loss: 0.4261\n",
      "Epoch [115/500], Average Validation Loss: 0.4297, Average Validation Accuracy: 0.8123\n",
      "Epoch [116/500], Average Training Loss: 0.4261\n",
      "Epoch [116/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8126\n",
      "Epoch [117/500], Average Training Loss: 0.4259\n",
      "Epoch [117/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8125\n",
      "Epoch [118/500], Average Training Loss: 0.4259\n",
      "Epoch [118/500], Average Validation Loss: 0.4295, Average Validation Accuracy: 0.8126\n",
      "Epoch [119/500], Average Training Loss: 0.4259\n",
      "Epoch [119/500], Average Validation Loss: 0.4295, Average Validation Accuracy: 0.8125\n",
      "Epoch [120/500], Average Training Loss: 0.4259\n",
      "Epoch [120/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8125\n",
      "Epoch [121/500], Average Training Loss: 0.4258\n",
      "Epoch [121/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8121\n",
      "Epoch [122/500], Average Training Loss: 0.4257\n",
      "Epoch [122/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8126\n",
      "Epoch [123/500], Average Training Loss: 0.4257\n",
      "Epoch [123/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8122\n",
      "Epoch [124/500], Average Training Loss: 0.4255\n",
      "Epoch [124/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8125\n",
      "Epoch [125/500], Average Training Loss: 0.4255\n",
      "Epoch [125/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8122\n",
      "Epoch [126/500], Average Training Loss: 0.4255\n",
      "Epoch [126/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8125\n",
      "Epoch [127/500], Average Training Loss: 0.4255\n",
      "Epoch [127/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8122\n",
      "Epoch [128/500], Average Training Loss: 0.4254\n",
      "Epoch [128/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8126\n",
      "Epoch [129/500], Average Training Loss: 0.4253\n",
      "Epoch [129/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8122\n",
      "Epoch [130/500], Average Training Loss: 0.4253\n",
      "Epoch [130/500], Average Validation Loss: 0.4289, Average Validation Accuracy: 0.8126\n",
      "Epoch [131/500], Average Training Loss: 0.4252\n",
      "Epoch [131/500], Average Validation Loss: 0.4289, Average Validation Accuracy: 0.8126\n",
      "Epoch [132/500], Average Training Loss: 0.4252\n",
      "Epoch [132/500], Average Validation Loss: 0.4289, Average Validation Accuracy: 0.8126\n",
      "Epoch [133/500], Average Training Loss: 0.4251\n",
      "Epoch [133/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8122\n",
      "Epoch [134/500], Average Training Loss: 0.4250\n",
      "Epoch [134/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8124\n",
      "Epoch [135/500], Average Training Loss: 0.4250\n",
      "Epoch [135/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8126\n",
      "Epoch [136/500], Average Training Loss: 0.4249\n",
      "Epoch [136/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8127\n",
      "Epoch [137/500], Average Training Loss: 0.4249\n",
      "Epoch [137/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8124\n",
      "Epoch [138/500], Average Training Loss: 0.4249\n",
      "Epoch [138/500], Average Validation Loss: 0.4286, Average Validation Accuracy: 0.8127\n",
      "Epoch [139/500], Average Training Loss: 0.4248\n",
      "Epoch [139/500], Average Validation Loss: 0.4286, Average Validation Accuracy: 0.8125\n",
      "Epoch [140/500], Average Training Loss: 0.4247\n",
      "Epoch [140/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8121\n",
      "Epoch [141/500], Average Training Loss: 0.4246\n",
      "Epoch [141/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8123\n",
      "Epoch [142/500], Average Training Loss: 0.4247\n",
      "Epoch [142/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8127\n",
      "Epoch [143/500], Average Training Loss: 0.4246\n",
      "Epoch [143/500], Average Validation Loss: 0.4284, Average Validation Accuracy: 0.8124\n",
      "Epoch [144/500], Average Training Loss: 0.4246\n",
      "Epoch [144/500], Average Validation Loss: 0.4284, Average Validation Accuracy: 0.8127\n",
      "Epoch [145/500], Average Training Loss: 0.4245\n",
      "Epoch [145/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8125\n",
      "Epoch [146/500], Average Training Loss: 0.4244\n",
      "Epoch [146/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8122\n",
      "Epoch [147/500], Average Training Loss: 0.4243\n",
      "Epoch [147/500], Average Validation Loss: 0.4282, Average Validation Accuracy: 0.8125\n",
      "Epoch [148/500], Average Training Loss: 0.4243\n",
      "Epoch [148/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8131\n",
      "Epoch [149/500], Average Training Loss: 0.4243\n",
      "Epoch [149/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8125\n",
      "Epoch [150/500], Average Training Loss: 0.4242\n",
      "Epoch [150/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8125\n",
      "Epoch [151/500], Average Training Loss: 0.4242\n",
      "Epoch [151/500], Average Validation Loss: 0.4280, Average Validation Accuracy: 0.8124\n",
      "Epoch [152/500], Average Training Loss: 0.4241\n",
      "Epoch [152/500], Average Validation Loss: 0.4280, Average Validation Accuracy: 0.8123\n",
      "Epoch [153/500], Average Training Loss: 0.4240\n",
      "Epoch [153/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8121\n",
      "Epoch [154/500], Average Training Loss: 0.4240\n",
      "Epoch [154/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8124\n",
      "Epoch [155/500], Average Training Loss: 0.4239\n",
      "Epoch [155/500], Average Validation Loss: 0.4278, Average Validation Accuracy: 0.8125\n",
      "Epoch [156/500], Average Training Loss: 0.4239\n",
      "Epoch [156/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8132\n",
      "Epoch [157/500], Average Training Loss: 0.4238\n",
      "Epoch [157/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8123\n",
      "Epoch [158/500], Average Training Loss: 0.4238\n",
      "Epoch [158/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8123\n",
      "Epoch [159/500], Average Training Loss: 0.4237\n",
      "Epoch [159/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8127\n",
      "Epoch [160/500], Average Training Loss: 0.4236\n",
      "Epoch [160/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8121\n",
      "Epoch [161/500], Average Training Loss: 0.4236\n",
      "Epoch [161/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8125\n",
      "Epoch [162/500], Average Training Loss: 0.4235\n",
      "Epoch [162/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8131\n",
      "Epoch [163/500], Average Training Loss: 0.4235\n",
      "Epoch [163/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8123\n",
      "Epoch [164/500], Average Training Loss: 0.4234\n",
      "Epoch [164/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8129\n",
      "Epoch [165/500], Average Training Loss: 0.4234\n",
      "Epoch [165/500], Average Validation Loss: 0.4274, Average Validation Accuracy: 0.8126\n",
      "Epoch [166/500], Average Training Loss: 0.4233\n",
      "Epoch [166/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8127\n",
      "Epoch [167/500], Average Training Loss: 0.4233\n",
      "Epoch [167/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8128\n",
      "Epoch [168/500], Average Training Loss: 0.4232\n",
      "Epoch [168/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8133\n",
      "Epoch [169/500], Average Training Loss: 0.4231\n",
      "Epoch [169/500], Average Validation Loss: 0.4272, Average Validation Accuracy: 0.8128\n",
      "Epoch [170/500], Average Training Loss: 0.4231\n",
      "Epoch [170/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8127\n",
      "Epoch [171/500], Average Training Loss: 0.4231\n",
      "Epoch [171/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8126\n",
      "Epoch [172/500], Average Training Loss: 0.4230\n",
      "Epoch [172/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8128\n",
      "Epoch [173/500], Average Training Loss: 0.4228\n",
      "Epoch [173/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8129\n",
      "Epoch [174/500], Average Training Loss: 0.4228\n",
      "Epoch [174/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8125\n",
      "Epoch [175/500], Average Training Loss: 0.4228\n",
      "Epoch [175/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8126\n",
      "Epoch [176/500], Average Training Loss: 0.4227\n",
      "Epoch [176/500], Average Validation Loss: 0.4268, Average Validation Accuracy: 0.8124\n",
      "Epoch [177/500], Average Training Loss: 0.4227\n",
      "Epoch [177/500], Average Validation Loss: 0.4268, Average Validation Accuracy: 0.8126\n",
      "Epoch [178/500], Average Training Loss: 0.4226\n",
      "Epoch [178/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8125\n",
      "Epoch [179/500], Average Training Loss: 0.4226\n",
      "Epoch [179/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8125\n",
      "Epoch [180/500], Average Training Loss: 0.4225\n",
      "Epoch [180/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8129\n",
      "Epoch [181/500], Average Training Loss: 0.4225\n",
      "Epoch [181/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8125\n",
      "Epoch [182/500], Average Training Loss: 0.4224\n",
      "Epoch [182/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8127\n",
      "Epoch [183/500], Average Training Loss: 0.4223\n",
      "Epoch [183/500], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8124\n",
      "Epoch [184/500], Average Training Loss: 0.4223\n",
      "Epoch [184/500], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8124\n",
      "Epoch [185/500], Average Training Loss: 0.4222\n",
      "Epoch [185/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8126\n",
      "Epoch [186/500], Average Training Loss: 0.4222\n",
      "Epoch [186/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8129\n",
      "Epoch [187/500], Average Training Loss: 0.4222\n",
      "Epoch [187/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8128\n",
      "Epoch [188/500], Average Training Loss: 0.4221\n",
      "Epoch [188/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8128\n",
      "Epoch [189/500], Average Training Loss: 0.4221\n",
      "Epoch [189/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8128\n",
      "Epoch [190/500], Average Training Loss: 0.4220\n",
      "Epoch [190/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8130\n",
      "Epoch [191/500], Average Training Loss: 0.4220\n",
      "Epoch [191/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8129\n",
      "Epoch [192/500], Average Training Loss: 0.4219\n",
      "Epoch [192/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8127\n",
      "Epoch [193/500], Average Training Loss: 0.4218\n",
      "Epoch [193/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8127\n",
      "Epoch [194/500], Average Training Loss: 0.4218\n",
      "Epoch [194/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8128\n",
      "Epoch [195/500], Average Training Loss: 0.4217\n",
      "Epoch [195/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8130\n",
      "Epoch [196/500], Average Training Loss: 0.4217\n",
      "Epoch [196/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8128\n",
      "Epoch [197/500], Average Training Loss: 0.4216\n",
      "Epoch [197/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8126\n",
      "Epoch [198/500], Average Training Loss: 0.4216\n",
      "Epoch [198/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8131\n",
      "Epoch [199/500], Average Training Loss: 0.4215\n",
      "Epoch [199/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8129\n",
      "Epoch [200/500], Average Training Loss: 0.4214\n",
      "Epoch [200/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8130\n",
      "Epoch [201/500], Average Training Loss: 0.4215\n",
      "Epoch [201/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8137\n",
      "Epoch [202/500], Average Training Loss: 0.4213\n",
      "Epoch [202/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8131\n",
      "Epoch [203/500], Average Training Loss: 0.4213\n",
      "Epoch [203/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8129\n",
      "Epoch [204/500], Average Training Loss: 0.4213\n",
      "Epoch [204/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8131\n",
      "Epoch [205/500], Average Training Loss: 0.4212\n",
      "Epoch [205/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8132\n",
      "Epoch [206/500], Average Training Loss: 0.4212\n",
      "Epoch [206/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8133\n",
      "Epoch [207/500], Average Training Loss: 0.4211\n",
      "Epoch [207/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8130\n",
      "Epoch [208/500], Average Training Loss: 0.4211\n",
      "Epoch [208/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8129\n",
      "Epoch [209/500], Average Training Loss: 0.4210\n",
      "Epoch [209/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8133\n",
      "Epoch [210/500], Average Training Loss: 0.4210\n",
      "Epoch [210/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8125\n",
      "Epoch [211/500], Average Training Loss: 0.4209\n",
      "Epoch [211/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8130\n",
      "Epoch [212/500], Average Training Loss: 0.4209\n",
      "Epoch [212/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8129\n",
      "Epoch [213/500], Average Training Loss: 0.4208\n",
      "Epoch [213/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8130\n",
      "Epoch [214/500], Average Training Loss: 0.4208\n",
      "Epoch [214/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8128\n",
      "Epoch [215/500], Average Training Loss: 0.4208\n",
      "Epoch [215/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8132\n",
      "Epoch [216/500], Average Training Loss: 0.4207\n",
      "Epoch [216/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8131\n",
      "Epoch [217/500], Average Training Loss: 0.4206\n",
      "Epoch [217/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8135\n",
      "Epoch [218/500], Average Training Loss: 0.4206\n",
      "Epoch [218/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8127\n",
      "Epoch [219/500], Average Training Loss: 0.4206\n",
      "Epoch [219/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8127\n",
      "Epoch [220/500], Average Training Loss: 0.4205\n",
      "Epoch [220/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8127\n",
      "Epoch [221/500], Average Training Loss: 0.4205\n",
      "Epoch [221/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8130\n",
      "Epoch [222/500], Average Training Loss: 0.4204\n",
      "Epoch [222/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8133\n",
      "Epoch [223/500], Average Training Loss: 0.4204\n",
      "Epoch [223/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8133\n",
      "Epoch [224/500], Average Training Loss: 0.4203\n",
      "Epoch [224/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8128\n",
      "Epoch [225/500], Average Training Loss: 0.4204\n",
      "Epoch [225/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8128\n",
      "Epoch [226/500], Average Training Loss: 0.4202\n",
      "Epoch [226/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8127\n",
      "Epoch [227/500], Average Training Loss: 0.4202\n",
      "Epoch [227/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8129\n",
      "Epoch [228/500], Average Training Loss: 0.4202\n",
      "Epoch [228/500], Average Validation Loss: 0.4245, Average Validation Accuracy: 0.8130\n",
      "Epoch [229/500], Average Training Loss: 0.4202\n",
      "Epoch [229/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8132\n",
      "Epoch [230/500], Average Training Loss: 0.4201\n",
      "Epoch [230/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8128\n",
      "Epoch [231/500], Average Training Loss: 0.4201\n",
      "Epoch [231/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8131\n",
      "Epoch [232/500], Average Training Loss: 0.4200\n",
      "Epoch [232/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8132\n",
      "Epoch [233/500], Average Training Loss: 0.4200\n",
      "Epoch [233/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8127\n",
      "Epoch [234/500], Average Training Loss: 0.4200\n",
      "Epoch [234/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8138\n",
      "Epoch [235/500], Average Training Loss: 0.4199\n",
      "Epoch [235/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8127\n",
      "Epoch [236/500], Average Training Loss: 0.4198\n",
      "Epoch [236/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8132\n",
      "Epoch [237/500], Average Training Loss: 0.4198\n",
      "Epoch [237/500], Average Validation Loss: 0.4242, Average Validation Accuracy: 0.8137\n",
      "Epoch [238/500], Average Training Loss: 0.4199\n",
      "Epoch [238/500], Average Validation Loss: 0.4242, Average Validation Accuracy: 0.8134\n",
      "Epoch [239/500], Average Training Loss: 0.4197\n",
      "Epoch [239/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8131\n",
      "Epoch [240/500], Average Training Loss: 0.4198\n",
      "Epoch [240/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8129\n",
      "Epoch [241/500], Average Training Loss: 0.4196\n",
      "Epoch [241/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8131\n",
      "Epoch [242/500], Average Training Loss: 0.4197\n",
      "Epoch [242/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8128\n",
      "Epoch [243/500], Average Training Loss: 0.4197\n",
      "Epoch [243/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8134\n",
      "Epoch [244/500], Average Training Loss: 0.4196\n",
      "Epoch [244/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8135\n",
      "Epoch [245/500], Average Training Loss: 0.4196\n",
      "Epoch [245/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8131\n",
      "Epoch [246/500], Average Training Loss: 0.4195\n",
      "Epoch [246/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8134\n",
      "Epoch [247/500], Average Training Loss: 0.4195\n",
      "Epoch [247/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8135\n",
      "Epoch [248/500], Average Training Loss: 0.4194\n",
      "Epoch [248/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8134\n",
      "Epoch [249/500], Average Training Loss: 0.4194\n",
      "Epoch [249/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8133\n",
      "Epoch [250/500], Average Training Loss: 0.4194\n",
      "Epoch [250/500], Average Validation Loss: 0.4237, Average Validation Accuracy: 0.8137\n",
      "Epoch [251/500], Average Training Loss: 0.4193\n",
      "Epoch [251/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8137\n",
      "Epoch [252/500], Average Training Loss: 0.4193\n",
      "Epoch [252/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8136\n",
      "Epoch [253/500], Average Training Loss: 0.4193\n",
      "Epoch [253/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8137\n",
      "Epoch [254/500], Average Training Loss: 0.4192\n",
      "Epoch [254/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8135\n",
      "Epoch [255/500], Average Training Loss: 0.4193\n",
      "Epoch [255/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8135\n",
      "Epoch [256/500], Average Training Loss: 0.4192\n",
      "Epoch [256/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8136\n",
      "Epoch [257/500], Average Training Loss: 0.4191\n",
      "Epoch [257/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8140\n",
      "Epoch [258/500], Average Training Loss: 0.4191\n",
      "Epoch [258/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8139\n",
      "Epoch [259/500], Average Training Loss: 0.4191\n",
      "Epoch [259/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8142\n",
      "Epoch [260/500], Average Training Loss: 0.4190\n",
      "Epoch [260/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8136\n",
      "Epoch [261/500], Average Training Loss: 0.4190\n",
      "Epoch [261/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8138\n",
      "Epoch [262/500], Average Training Loss: 0.4189\n",
      "Epoch [262/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8137\n",
      "Epoch [263/500], Average Training Loss: 0.4189\n",
      "Epoch [263/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8137\n",
      "Epoch [264/500], Average Training Loss: 0.4189\n",
      "Epoch [264/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8145\n",
      "Epoch [265/500], Average Training Loss: 0.4188\n",
      "Epoch [265/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8140\n",
      "Epoch [266/500], Average Training Loss: 0.4188\n",
      "Epoch [266/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8139\n",
      "Epoch [267/500], Average Training Loss: 0.4188\n",
      "Epoch [267/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8142\n",
      "Epoch [268/500], Average Training Loss: 0.4187\n",
      "Epoch [268/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8142\n",
      "Epoch [269/500], Average Training Loss: 0.4188\n",
      "Epoch [269/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8143\n",
      "Epoch [270/500], Average Training Loss: 0.4187\n",
      "Epoch [270/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8142\n",
      "Epoch [271/500], Average Training Loss: 0.4187\n",
      "Epoch [271/500], Average Validation Loss: 0.4230, Average Validation Accuracy: 0.8143\n",
      "Epoch [272/500], Average Training Loss: 0.4186\n",
      "Epoch [272/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8141\n",
      "Epoch [273/500], Average Training Loss: 0.4186\n",
      "Epoch [273/500], Average Validation Loss: 0.4230, Average Validation Accuracy: 0.8144\n",
      "Epoch [274/500], Average Training Loss: 0.4186\n",
      "Epoch [274/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8144\n",
      "Epoch [275/500], Average Training Loss: 0.4186\n",
      "Epoch [275/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8144\n",
      "Epoch [276/500], Average Training Loss: 0.4185\n",
      "Epoch [276/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8141\n",
      "Epoch [277/500], Average Training Loss: 0.4185\n",
      "Epoch [277/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8139\n",
      "Epoch [278/500], Average Training Loss: 0.4184\n",
      "Epoch [278/500], Average Validation Loss: 0.4228, Average Validation Accuracy: 0.8141\n",
      "Epoch [279/500], Average Training Loss: 0.4184\n",
      "Epoch [279/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8143\n",
      "Epoch [280/500], Average Training Loss: 0.4184\n",
      "Epoch [280/500], Average Validation Loss: 0.4228, Average Validation Accuracy: 0.8140\n",
      "Epoch [281/500], Average Training Loss: 0.4184\n",
      "Epoch [281/500], Average Validation Loss: 0.4228, Average Validation Accuracy: 0.8139\n",
      "Epoch [282/500], Average Training Loss: 0.4183\n",
      "Epoch [282/500], Average Validation Loss: 0.4227, Average Validation Accuracy: 0.8143\n",
      "Epoch [283/500], Average Training Loss: 0.4182\n",
      "Epoch [283/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8142\n",
      "Epoch [284/500], Average Training Loss: 0.4183\n",
      "Epoch [284/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8140\n",
      "Epoch [285/500], Average Training Loss: 0.4182\n",
      "Epoch [285/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8144\n",
      "Epoch [286/500], Average Training Loss: 0.4182\n",
      "Epoch [286/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8143\n",
      "Epoch [287/500], Average Training Loss: 0.4182\n",
      "Epoch [287/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8142\n",
      "Epoch [288/500], Average Training Loss: 0.4181\n",
      "Epoch [288/500], Average Validation Loss: 0.4225, Average Validation Accuracy: 0.8143\n",
      "Epoch [289/500], Average Training Loss: 0.4181\n",
      "Epoch [289/500], Average Validation Loss: 0.4225, Average Validation Accuracy: 0.8141\n",
      "Epoch [290/500], Average Training Loss: 0.4180\n",
      "Epoch [290/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8143\n",
      "Epoch [291/500], Average Training Loss: 0.4181\n",
      "Epoch [291/500], Average Validation Loss: 0.4224, Average Validation Accuracy: 0.8145\n",
      "Epoch [292/500], Average Training Loss: 0.4180\n",
      "Epoch [292/500], Average Validation Loss: 0.4223, Average Validation Accuracy: 0.8145\n",
      "Epoch [293/500], Average Training Loss: 0.4180\n",
      "Epoch [293/500], Average Validation Loss: 0.4223, Average Validation Accuracy: 0.8144\n",
      "Epoch [294/500], Average Training Loss: 0.4179\n",
      "Epoch [294/500], Average Validation Loss: 0.4224, Average Validation Accuracy: 0.8143\n",
      "Epoch [295/500], Average Training Loss: 0.4179\n",
      "Epoch [295/500], Average Validation Loss: 0.4223, Average Validation Accuracy: 0.8145\n",
      "Epoch [296/500], Average Training Loss: 0.4178\n",
      "Epoch [296/500], Average Validation Loss: 0.4222, Average Validation Accuracy: 0.8148\n",
      "Epoch [297/500], Average Training Loss: 0.4178\n",
      "Epoch [297/500], Average Validation Loss: 0.4222, Average Validation Accuracy: 0.8147\n",
      "Epoch [298/500], Average Training Loss: 0.4178\n",
      "Epoch [298/500], Average Validation Loss: 0.4222, Average Validation Accuracy: 0.8148\n",
      "Epoch [299/500], Average Training Loss: 0.4178\n",
      "Epoch [299/500], Average Validation Loss: 0.4221, Average Validation Accuracy: 0.8147\n",
      "Epoch [300/500], Average Training Loss: 0.4178\n",
      "Epoch [300/500], Average Validation Loss: 0.4221, Average Validation Accuracy: 0.8149\n",
      "Epoch [301/500], Average Training Loss: 0.4178\n",
      "Epoch [301/500], Average Validation Loss: 0.4221, Average Validation Accuracy: 0.8151\n",
      "Epoch [302/500], Average Training Loss: 0.4177\n",
      "Epoch [302/500], Average Validation Loss: 0.4220, Average Validation Accuracy: 0.8149\n",
      "Epoch [303/500], Average Training Loss: 0.4176\n",
      "Epoch [303/500], Average Validation Loss: 0.4221, Average Validation Accuracy: 0.8145\n",
      "Epoch [304/500], Average Training Loss: 0.4177\n",
      "Epoch [304/500], Average Validation Loss: 0.4219, Average Validation Accuracy: 0.8149\n",
      "Epoch [305/500], Average Training Loss: 0.4175\n",
      "Epoch [305/500], Average Validation Loss: 0.4219, Average Validation Accuracy: 0.8146\n",
      "Epoch [306/500], Average Training Loss: 0.4175\n",
      "Epoch [306/500], Average Validation Loss: 0.4219, Average Validation Accuracy: 0.8150\n",
      "Epoch [307/500], Average Training Loss: 0.4175\n",
      "Epoch [307/500], Average Validation Loss: 0.4219, Average Validation Accuracy: 0.8148\n",
      "Epoch [308/500], Average Training Loss: 0.4175\n",
      "Epoch [308/500], Average Validation Loss: 0.4218, Average Validation Accuracy: 0.8150\n",
      "Epoch [309/500], Average Training Loss: 0.4174\n",
      "Epoch [309/500], Average Validation Loss: 0.4218, Average Validation Accuracy: 0.8147\n",
      "Epoch [310/500], Average Training Loss: 0.4174\n",
      "Epoch [310/500], Average Validation Loss: 0.4217, Average Validation Accuracy: 0.8146\n",
      "Epoch [311/500], Average Training Loss: 0.4174\n",
      "Epoch [311/500], Average Validation Loss: 0.4217, Average Validation Accuracy: 0.8149\n",
      "Epoch [312/500], Average Training Loss: 0.4174\n",
      "Epoch [312/500], Average Validation Loss: 0.4217, Average Validation Accuracy: 0.8148\n",
      "Epoch [313/500], Average Training Loss: 0.4173\n",
      "Epoch [313/500], Average Validation Loss: 0.4216, Average Validation Accuracy: 0.8148\n",
      "Epoch [314/500], Average Training Loss: 0.4173\n",
      "Epoch [314/500], Average Validation Loss: 0.4216, Average Validation Accuracy: 0.8153\n",
      "Epoch [315/500], Average Training Loss: 0.4173\n",
      "Epoch [315/500], Average Validation Loss: 0.4215, Average Validation Accuracy: 0.8151\n",
      "Epoch [316/500], Average Training Loss: 0.4172\n",
      "Epoch [316/500], Average Validation Loss: 0.4216, Average Validation Accuracy: 0.8151\n",
      "Epoch [317/500], Average Training Loss: 0.4172\n",
      "Epoch [317/500], Average Validation Loss: 0.4215, Average Validation Accuracy: 0.8149\n",
      "Epoch [318/500], Average Training Loss: 0.4172\n",
      "Epoch [318/500], Average Validation Loss: 0.4215, Average Validation Accuracy: 0.8149\n",
      "Epoch [319/500], Average Training Loss: 0.4171\n",
      "Epoch [319/500], Average Validation Loss: 0.4214, Average Validation Accuracy: 0.8149\n",
      "Epoch [320/500], Average Training Loss: 0.4171\n",
      "Epoch [320/500], Average Validation Loss: 0.4214, Average Validation Accuracy: 0.8147\n",
      "Epoch [321/500], Average Training Loss: 0.4170\n",
      "Epoch [321/500], Average Validation Loss: 0.4214, Average Validation Accuracy: 0.8156\n",
      "Epoch [322/500], Average Training Loss: 0.4171\n",
      "Epoch [322/500], Average Validation Loss: 0.4213, Average Validation Accuracy: 0.8149\n",
      "Epoch [323/500], Average Training Loss: 0.4169\n",
      "Epoch [323/500], Average Validation Loss: 0.4215, Average Validation Accuracy: 0.8142\n",
      "Epoch [324/500], Average Training Loss: 0.4170\n",
      "Epoch [324/500], Average Validation Loss: 0.4212, Average Validation Accuracy: 0.8149\n",
      "Epoch [325/500], Average Training Loss: 0.4169\n",
      "Epoch [325/500], Average Validation Loss: 0.4212, Average Validation Accuracy: 0.8145\n",
      "Epoch [326/500], Average Training Loss: 0.4169\n",
      "Epoch [326/500], Average Validation Loss: 0.4212, Average Validation Accuracy: 0.8148\n",
      "Epoch [327/500], Average Training Loss: 0.4169\n",
      "Epoch [327/500], Average Validation Loss: 0.4213, Average Validation Accuracy: 0.8158\n",
      "Epoch [328/500], Average Training Loss: 0.4168\n",
      "Epoch [328/500], Average Validation Loss: 0.4211, Average Validation Accuracy: 0.8158\n",
      "Epoch [329/500], Average Training Loss: 0.4168\n",
      "Epoch [329/500], Average Validation Loss: 0.4211, Average Validation Accuracy: 0.8148\n",
      "Epoch [330/500], Average Training Loss: 0.4168\n",
      "Epoch [330/500], Average Validation Loss: 0.4210, Average Validation Accuracy: 0.8151\n",
      "Epoch [331/500], Average Training Loss: 0.4167\n",
      "Epoch [331/500], Average Validation Loss: 0.4210, Average Validation Accuracy: 0.8151\n",
      "Epoch [332/500], Average Training Loss: 0.4166\n",
      "Epoch [332/500], Average Validation Loss: 0.4210, Average Validation Accuracy: 0.8153\n",
      "Epoch [333/500], Average Training Loss: 0.4166\n",
      "Epoch [333/500], Average Validation Loss: 0.4210, Average Validation Accuracy: 0.8147\n",
      "Epoch [334/500], Average Training Loss: 0.4166\n",
      "Epoch [334/500], Average Validation Loss: 0.4209, Average Validation Accuracy: 0.8151\n",
      "Epoch [335/500], Average Training Loss: 0.4166\n",
      "Epoch [335/500], Average Validation Loss: 0.4209, Average Validation Accuracy: 0.8154\n",
      "Epoch [336/500], Average Training Loss: 0.4166\n",
      "Epoch [336/500], Average Validation Loss: 0.4209, Average Validation Accuracy: 0.8147\n",
      "Epoch [337/500], Average Training Loss: 0.4165\n",
      "Epoch [337/500], Average Validation Loss: 0.4208, Average Validation Accuracy: 0.8151\n",
      "Epoch [338/500], Average Training Loss: 0.4165\n",
      "Epoch [338/500], Average Validation Loss: 0.4208, Average Validation Accuracy: 0.8152\n",
      "Epoch [339/500], Average Training Loss: 0.4165\n",
      "Epoch [339/500], Average Validation Loss: 0.4207, Average Validation Accuracy: 0.8155\n",
      "Epoch [340/500], Average Training Loss: 0.4164\n",
      "Epoch [340/500], Average Validation Loss: 0.4207, Average Validation Accuracy: 0.8157\n",
      "Epoch [341/500], Average Training Loss: 0.4163\n",
      "Epoch [341/500], Average Validation Loss: 0.4207, Average Validation Accuracy: 0.8150\n",
      "Epoch [342/500], Average Training Loss: 0.4164\n",
      "Epoch [342/500], Average Validation Loss: 0.4206, Average Validation Accuracy: 0.8159\n",
      "Epoch [343/500], Average Training Loss: 0.4163\n",
      "Epoch [343/500], Average Validation Loss: 0.4206, Average Validation Accuracy: 0.8151\n",
      "Epoch [344/500], Average Training Loss: 0.4162\n",
      "Epoch [344/500], Average Validation Loss: 0.4205, Average Validation Accuracy: 0.8160\n",
      "Epoch [345/500], Average Training Loss: 0.4163\n",
      "Epoch [345/500], Average Validation Loss: 0.4205, Average Validation Accuracy: 0.8156\n",
      "Epoch [346/500], Average Training Loss: 0.4162\n",
      "Epoch [346/500], Average Validation Loss: 0.4205, Average Validation Accuracy: 0.8151\n",
      "Epoch [347/500], Average Training Loss: 0.4162\n",
      "Epoch [347/500], Average Validation Loss: 0.4204, Average Validation Accuracy: 0.8156\n",
      "Epoch [348/500], Average Training Loss: 0.4161\n",
      "Epoch [348/500], Average Validation Loss: 0.4204, Average Validation Accuracy: 0.8158\n",
      "Epoch [349/500], Average Training Loss: 0.4161\n",
      "Epoch [349/500], Average Validation Loss: 0.4203, Average Validation Accuracy: 0.8159\n",
      "Epoch [350/500], Average Training Loss: 0.4161\n",
      "Epoch [350/500], Average Validation Loss: 0.4204, Average Validation Accuracy: 0.8152\n",
      "Epoch [351/500], Average Training Loss: 0.4160\n",
      "Epoch [351/500], Average Validation Loss: 0.4203, Average Validation Accuracy: 0.8153\n",
      "Epoch [352/500], Average Training Loss: 0.4160\n",
      "Epoch [352/500], Average Validation Loss: 0.4203, Average Validation Accuracy: 0.8152\n",
      "Epoch [353/500], Average Training Loss: 0.4160\n",
      "Epoch [353/500], Average Validation Loss: 0.4202, Average Validation Accuracy: 0.8162\n",
      "Epoch [354/500], Average Training Loss: 0.4160\n",
      "Epoch [354/500], Average Validation Loss: 0.4202, Average Validation Accuracy: 0.8156\n",
      "Epoch [355/500], Average Training Loss: 0.4160\n",
      "Epoch [355/500], Average Validation Loss: 0.4201, Average Validation Accuracy: 0.8161\n",
      "Epoch [356/500], Average Training Loss: 0.4159\n",
      "Epoch [356/500], Average Validation Loss: 0.4201, Average Validation Accuracy: 0.8156\n",
      "Epoch [357/500], Average Training Loss: 0.4159\n",
      "Epoch [357/500], Average Validation Loss: 0.4200, Average Validation Accuracy: 0.8161\n",
      "Epoch [358/500], Average Training Loss: 0.4158\n",
      "Epoch [358/500], Average Validation Loss: 0.4203, Average Validation Accuracy: 0.8157\n",
      "Epoch [359/500], Average Training Loss: 0.4158\n",
      "Epoch [359/500], Average Validation Loss: 0.4200, Average Validation Accuracy: 0.8161\n",
      "Epoch [360/500], Average Training Loss: 0.4158\n",
      "Epoch [360/500], Average Validation Loss: 0.4200, Average Validation Accuracy: 0.8155\n",
      "Epoch [361/500], Average Training Loss: 0.4158\n",
      "Epoch [361/500], Average Validation Loss: 0.4199, Average Validation Accuracy: 0.8161\n",
      "Epoch [362/500], Average Training Loss: 0.4156\n",
      "Epoch [362/500], Average Validation Loss: 0.4200, Average Validation Accuracy: 0.8168\n",
      "Epoch [363/500], Average Training Loss: 0.4157\n",
      "Epoch [363/500], Average Validation Loss: 0.4199, Average Validation Accuracy: 0.8157\n",
      "Epoch [364/500], Average Training Loss: 0.4156\n",
      "Epoch [364/500], Average Validation Loss: 0.4198, Average Validation Accuracy: 0.8160\n",
      "Epoch [365/500], Average Training Loss: 0.4155\n",
      "Epoch [365/500], Average Validation Loss: 0.4198, Average Validation Accuracy: 0.8169\n",
      "Epoch [366/500], Average Training Loss: 0.4156\n",
      "Epoch [366/500], Average Validation Loss: 0.4198, Average Validation Accuracy: 0.8168\n",
      "Epoch [367/500], Average Training Loss: 0.4156\n",
      "Epoch [367/500], Average Validation Loss: 0.4197, Average Validation Accuracy: 0.8163\n",
      "Epoch [368/500], Average Training Loss: 0.4155\n",
      "Epoch [368/500], Average Validation Loss: 0.4197, Average Validation Accuracy: 0.8163\n",
      "Epoch [369/500], Average Training Loss: 0.4155\n",
      "Epoch [369/500], Average Validation Loss: 0.4196, Average Validation Accuracy: 0.8162\n",
      "Epoch [370/500], Average Training Loss: 0.4155\n",
      "Epoch [370/500], Average Validation Loss: 0.4196, Average Validation Accuracy: 0.8162\n",
      "Epoch [371/500], Average Training Loss: 0.4155\n",
      "Epoch [371/500], Average Validation Loss: 0.4196, Average Validation Accuracy: 0.8161\n",
      "Epoch [372/500], Average Training Loss: 0.4154\n",
      "Epoch [372/500], Average Validation Loss: 0.4195, Average Validation Accuracy: 0.8166\n",
      "Epoch [373/500], Average Training Loss: 0.4154\n",
      "Epoch [373/500], Average Validation Loss: 0.4195, Average Validation Accuracy: 0.8163\n",
      "Epoch [374/500], Average Training Loss: 0.4153\n",
      "Epoch [374/500], Average Validation Loss: 0.4194, Average Validation Accuracy: 0.8165\n",
      "Epoch [375/500], Average Training Loss: 0.4154\n",
      "Epoch [375/500], Average Validation Loss: 0.4195, Average Validation Accuracy: 0.8167\n",
      "Epoch [376/500], Average Training Loss: 0.4153\n",
      "Epoch [376/500], Average Validation Loss: 0.4194, Average Validation Accuracy: 0.8167\n",
      "Epoch [377/500], Average Training Loss: 0.4152\n",
      "Epoch [377/500], Average Validation Loss: 0.4194, Average Validation Accuracy: 0.8168\n",
      "Epoch [378/500], Average Training Loss: 0.4152\n",
      "Epoch [378/500], Average Validation Loss: 0.4194, Average Validation Accuracy: 0.8167\n",
      "Epoch [379/500], Average Training Loss: 0.4152\n",
      "Epoch [379/500], Average Validation Loss: 0.4193, Average Validation Accuracy: 0.8163\n",
      "Epoch [380/500], Average Training Loss: 0.4151\n",
      "Epoch [380/500], Average Validation Loss: 0.4193, Average Validation Accuracy: 0.8167\n",
      "Epoch [381/500], Average Training Loss: 0.4151\n",
      "Epoch [381/500], Average Validation Loss: 0.4192, Average Validation Accuracy: 0.8166\n",
      "Epoch [382/500], Average Training Loss: 0.4151\n",
      "Epoch [382/500], Average Validation Loss: 0.4192, Average Validation Accuracy: 0.8165\n",
      "Epoch [383/500], Average Training Loss: 0.4151\n",
      "Epoch [383/500], Average Validation Loss: 0.4192, Average Validation Accuracy: 0.8167\n",
      "Epoch [384/500], Average Training Loss: 0.4150\n",
      "Epoch [384/500], Average Validation Loss: 0.4191, Average Validation Accuracy: 0.8163\n",
      "Epoch [385/500], Average Training Loss: 0.4150\n",
      "Epoch [385/500], Average Validation Loss: 0.4191, Average Validation Accuracy: 0.8169\n",
      "Epoch [386/500], Average Training Loss: 0.4150\n",
      "Epoch [386/500], Average Validation Loss: 0.4191, Average Validation Accuracy: 0.8165\n",
      "Epoch [387/500], Average Training Loss: 0.4149\n",
      "Epoch [387/500], Average Validation Loss: 0.4191, Average Validation Accuracy: 0.8166\n",
      "Epoch [388/500], Average Training Loss: 0.4149\n",
      "Epoch [388/500], Average Validation Loss: 0.4190, Average Validation Accuracy: 0.8167\n",
      "Epoch [389/500], Average Training Loss: 0.4149\n",
      "Epoch [389/500], Average Validation Loss: 0.4189, Average Validation Accuracy: 0.8166\n",
      "Epoch [390/500], Average Training Loss: 0.4148\n",
      "Epoch [390/500], Average Validation Loss: 0.4189, Average Validation Accuracy: 0.8165\n",
      "Epoch [391/500], Average Training Loss: 0.4148\n",
      "Epoch [391/500], Average Validation Loss: 0.4189, Average Validation Accuracy: 0.8165\n",
      "Epoch [392/500], Average Training Loss: 0.4148\n",
      "Epoch [392/500], Average Validation Loss: 0.4188, Average Validation Accuracy: 0.8165\n",
      "Epoch [393/500], Average Training Loss: 0.4148\n",
      "Epoch [393/500], Average Validation Loss: 0.4188, Average Validation Accuracy: 0.8165\n",
      "Epoch [394/500], Average Training Loss: 0.4147\n",
      "Epoch [394/500], Average Validation Loss: 0.4188, Average Validation Accuracy: 0.8164\n",
      "Epoch [395/500], Average Training Loss: 0.4147\n",
      "Epoch [395/500], Average Validation Loss: 0.4189, Average Validation Accuracy: 0.8167\n",
      "Epoch [396/500], Average Training Loss: 0.4147\n",
      "Epoch [396/500], Average Validation Loss: 0.4187, Average Validation Accuracy: 0.8167\n",
      "Epoch [397/500], Average Training Loss: 0.4146\n",
      "Epoch [397/500], Average Validation Loss: 0.4187, Average Validation Accuracy: 0.8165\n",
      "Epoch [398/500], Average Training Loss: 0.4145\n",
      "Epoch [398/500], Average Validation Loss: 0.4187, Average Validation Accuracy: 0.8167\n",
      "Epoch [399/500], Average Training Loss: 0.4146\n",
      "Epoch [399/500], Average Validation Loss: 0.4186, Average Validation Accuracy: 0.8165\n",
      "Epoch [400/500], Average Training Loss: 0.4146\n",
      "Epoch [400/500], Average Validation Loss: 0.4186, Average Validation Accuracy: 0.8166\n",
      "Epoch [401/500], Average Training Loss: 0.4146\n",
      "Epoch [401/500], Average Validation Loss: 0.4186, Average Validation Accuracy: 0.8163\n",
      "Epoch [402/500], Average Training Loss: 0.4145\n",
      "Epoch [402/500], Average Validation Loss: 0.4185, Average Validation Accuracy: 0.8164\n",
      "Epoch [403/500], Average Training Loss: 0.4145\n",
      "Epoch [403/500], Average Validation Loss: 0.4185, Average Validation Accuracy: 0.8163\n",
      "Epoch [404/500], Average Training Loss: 0.4145\n",
      "Epoch [404/500], Average Validation Loss: 0.4185, Average Validation Accuracy: 0.8167\n",
      "Epoch [405/500], Average Training Loss: 0.4144\n",
      "Epoch [405/500], Average Validation Loss: 0.4184, Average Validation Accuracy: 0.8169\n",
      "Epoch [406/500], Average Training Loss: 0.4144\n",
      "Epoch [406/500], Average Validation Loss: 0.4184, Average Validation Accuracy: 0.8163\n",
      "Epoch [407/500], Average Training Loss: 0.4143\n",
      "Epoch [407/500], Average Validation Loss: 0.4184, Average Validation Accuracy: 0.8165\n",
      "Epoch [408/500], Average Training Loss: 0.4143\n",
      "Epoch [408/500], Average Validation Loss: 0.4184, Average Validation Accuracy: 0.8163\n",
      "Epoch [409/500], Average Training Loss: 0.4143\n",
      "Epoch [409/500], Average Validation Loss: 0.4183, Average Validation Accuracy: 0.8166\n",
      "Epoch [410/500], Average Training Loss: 0.4142\n",
      "Epoch [410/500], Average Validation Loss: 0.4183, Average Validation Accuracy: 0.8164\n",
      "Epoch [411/500], Average Training Loss: 0.4143\n",
      "Epoch [411/500], Average Validation Loss: 0.4183, Average Validation Accuracy: 0.8169\n",
      "Epoch [412/500], Average Training Loss: 0.4142\n",
      "Epoch [412/500], Average Validation Loss: 0.4182, Average Validation Accuracy: 0.8163\n",
      "Epoch [413/500], Average Training Loss: 0.4141\n",
      "Epoch [413/500], Average Validation Loss: 0.4182, Average Validation Accuracy: 0.8166\n",
      "Epoch [414/500], Average Training Loss: 0.4143\n",
      "Epoch [414/500], Average Validation Loss: 0.4182, Average Validation Accuracy: 0.8163\n",
      "Epoch [415/500], Average Training Loss: 0.4141\n",
      "Epoch [415/500], Average Validation Loss: 0.4182, Average Validation Accuracy: 0.8164\n",
      "Epoch [416/500], Average Training Loss: 0.4142\n",
      "Epoch [416/500], Average Validation Loss: 0.4181, Average Validation Accuracy: 0.8165\n",
      "Epoch [417/500], Average Training Loss: 0.4141\n",
      "Epoch [417/500], Average Validation Loss: 0.4180, Average Validation Accuracy: 0.8165\n",
      "Epoch [418/500], Average Training Loss: 0.4141\n",
      "Epoch [418/500], Average Validation Loss: 0.4180, Average Validation Accuracy: 0.8168\n",
      "Epoch [419/500], Average Training Loss: 0.4140\n",
      "Epoch [419/500], Average Validation Loss: 0.4180, Average Validation Accuracy: 0.8165\n",
      "Epoch [420/500], Average Training Loss: 0.4140\n",
      "Epoch [420/500], Average Validation Loss: 0.4180, Average Validation Accuracy: 0.8166\n",
      "Epoch [421/500], Average Training Loss: 0.4140\n",
      "Epoch [421/500], Average Validation Loss: 0.4179, Average Validation Accuracy: 0.8164\n",
      "Epoch [422/500], Average Training Loss: 0.4139\n",
      "Epoch [422/500], Average Validation Loss: 0.4179, Average Validation Accuracy: 0.8165\n",
      "Epoch [423/500], Average Training Loss: 0.4139\n",
      "Epoch [423/500], Average Validation Loss: 0.4179, Average Validation Accuracy: 0.8166\n",
      "Epoch [424/500], Average Training Loss: 0.4139\n",
      "Epoch [424/500], Average Validation Loss: 0.4179, Average Validation Accuracy: 0.8162\n",
      "Epoch [425/500], Average Training Loss: 0.4139\n",
      "Epoch [425/500], Average Validation Loss: 0.4178, Average Validation Accuracy: 0.8163\n",
      "Epoch [426/500], Average Training Loss: 0.4138\n",
      "Epoch [426/500], Average Validation Loss: 0.4178, Average Validation Accuracy: 0.8164\n",
      "Epoch [427/500], Average Training Loss: 0.4138\n",
      "Epoch [427/500], Average Validation Loss: 0.4179, Average Validation Accuracy: 0.8168\n",
      "Epoch [428/500], Average Training Loss: 0.4138\n",
      "Epoch [428/500], Average Validation Loss: 0.4178, Average Validation Accuracy: 0.8164\n",
      "Epoch [429/500], Average Training Loss: 0.4138\n",
      "Epoch [429/500], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8164\n",
      "Epoch [430/500], Average Training Loss: 0.4137\n",
      "Epoch [430/500], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8165\n",
      "Epoch [431/500], Average Training Loss: 0.4137\n",
      "Epoch [431/500], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8163\n",
      "Epoch [432/500], Average Training Loss: 0.4137\n",
      "Epoch [432/500], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8160\n",
      "Epoch [433/500], Average Training Loss: 0.4137\n",
      "Epoch [433/500], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8172\n",
      "Epoch [434/500], Average Training Loss: 0.4137\n",
      "Epoch [434/500], Average Validation Loss: 0.4176, Average Validation Accuracy: 0.8162\n",
      "Epoch [435/500], Average Training Loss: 0.4136\n",
      "Epoch [435/500], Average Validation Loss: 0.4176, Average Validation Accuracy: 0.8164\n",
      "Epoch [436/500], Average Training Loss: 0.4137\n",
      "Epoch [436/500], Average Validation Loss: 0.4176, Average Validation Accuracy: 0.8166\n",
      "Epoch [437/500], Average Training Loss: 0.4136\n",
      "Epoch [437/500], Average Validation Loss: 0.4176, Average Validation Accuracy: 0.8167\n",
      "Epoch [438/500], Average Training Loss: 0.4136\n",
      "Epoch [438/500], Average Validation Loss: 0.4175, Average Validation Accuracy: 0.8165\n",
      "Epoch [439/500], Average Training Loss: 0.4136\n",
      "Epoch [439/500], Average Validation Loss: 0.4175, Average Validation Accuracy: 0.8170\n",
      "Epoch [440/500], Average Training Loss: 0.4135\n",
      "Epoch [440/500], Average Validation Loss: 0.4174, Average Validation Accuracy: 0.8164\n",
      "Epoch [441/500], Average Training Loss: 0.4136\n",
      "Epoch [441/500], Average Validation Loss: 0.4174, Average Validation Accuracy: 0.8171\n",
      "Epoch [442/500], Average Training Loss: 0.4135\n",
      "Epoch [442/500], Average Validation Loss: 0.4174, Average Validation Accuracy: 0.8167\n",
      "Epoch [443/500], Average Training Loss: 0.4135\n",
      "Epoch [443/500], Average Validation Loss: 0.4173, Average Validation Accuracy: 0.8169\n",
      "Epoch [444/500], Average Training Loss: 0.4134\n",
      "Epoch [444/500], Average Validation Loss: 0.4174, Average Validation Accuracy: 0.8170\n",
      "Epoch [445/500], Average Training Loss: 0.4134\n",
      "Epoch [445/500], Average Validation Loss: 0.4173, Average Validation Accuracy: 0.8167\n",
      "Epoch [446/500], Average Training Loss: 0.4134\n",
      "Epoch [446/500], Average Validation Loss: 0.4173, Average Validation Accuracy: 0.8169\n",
      "Epoch [447/500], Average Training Loss: 0.4134\n",
      "Epoch [447/500], Average Validation Loss: 0.4173, Average Validation Accuracy: 0.8171\n",
      "Epoch [448/500], Average Training Loss: 0.4133\n",
      "Epoch [448/500], Average Validation Loss: 0.4172, Average Validation Accuracy: 0.8165\n",
      "Epoch [449/500], Average Training Loss: 0.4134\n",
      "Epoch [449/500], Average Validation Loss: 0.4172, Average Validation Accuracy: 0.8169\n",
      "Epoch [450/500], Average Training Loss: 0.4134\n",
      "Epoch [450/500], Average Validation Loss: 0.4172, Average Validation Accuracy: 0.8168\n",
      "Epoch [451/500], Average Training Loss: 0.4133\n",
      "Epoch [451/500], Average Validation Loss: 0.4171, Average Validation Accuracy: 0.8169\n",
      "Epoch [452/500], Average Training Loss: 0.4133\n",
      "Epoch [452/500], Average Validation Loss: 0.4171, Average Validation Accuracy: 0.8165\n",
      "Epoch [453/500], Average Training Loss: 0.4133\n",
      "Epoch [453/500], Average Validation Loss: 0.4171, Average Validation Accuracy: 0.8171\n",
      "Epoch [454/500], Average Training Loss: 0.4133\n",
      "Epoch [454/500], Average Validation Loss: 0.4171, Average Validation Accuracy: 0.8169\n",
      "Epoch [455/500], Average Training Loss: 0.4132\n",
      "Epoch [455/500], Average Validation Loss: 0.4171, Average Validation Accuracy: 0.8169\n",
      "Epoch [456/500], Average Training Loss: 0.4132\n",
      "Epoch [456/500], Average Validation Loss: 0.4171, Average Validation Accuracy: 0.8168\n",
      "Epoch [457/500], Average Training Loss: 0.4132\n",
      "Epoch [457/500], Average Validation Loss: 0.4170, Average Validation Accuracy: 0.8173\n",
      "Epoch [458/500], Average Training Loss: 0.4131\n",
      "Epoch [458/500], Average Validation Loss: 0.4170, Average Validation Accuracy: 0.8169\n",
      "Epoch [459/500], Average Training Loss: 0.4132\n",
      "Epoch [459/500], Average Validation Loss: 0.4170, Average Validation Accuracy: 0.8175\n",
      "Epoch [460/500], Average Training Loss: 0.4131\n",
      "Epoch [460/500], Average Validation Loss: 0.4170, Average Validation Accuracy: 0.8174\n",
      "Epoch [461/500], Average Training Loss: 0.4131\n",
      "Epoch [461/500], Average Validation Loss: 0.4170, Average Validation Accuracy: 0.8175\n",
      "Epoch [462/500], Average Training Loss: 0.4131\n",
      "Epoch [462/500], Average Validation Loss: 0.4169, Average Validation Accuracy: 0.8171\n",
      "Epoch [463/500], Average Training Loss: 0.4130\n",
      "Epoch [463/500], Average Validation Loss: 0.4169, Average Validation Accuracy: 0.8173\n",
      "Epoch [464/500], Average Training Loss: 0.4130\n",
      "Epoch [464/500], Average Validation Loss: 0.4169, Average Validation Accuracy: 0.8177\n",
      "Epoch [465/500], Average Training Loss: 0.4131\n",
      "Epoch [465/500], Average Validation Loss: 0.4169, Average Validation Accuracy: 0.8172\n",
      "Epoch [466/500], Average Training Loss: 0.4130\n",
      "Epoch [466/500], Average Validation Loss: 0.4170, Average Validation Accuracy: 0.8172\n",
      "Epoch [467/500], Average Training Loss: 0.4129\n",
      "Epoch [467/500], Average Validation Loss: 0.4169, Average Validation Accuracy: 0.8175\n",
      "Epoch [468/500], Average Training Loss: 0.4130\n",
      "Epoch [468/500], Average Validation Loss: 0.4168, Average Validation Accuracy: 0.8173\n",
      "Epoch [469/500], Average Training Loss: 0.4130\n",
      "Epoch [469/500], Average Validation Loss: 0.4168, Average Validation Accuracy: 0.8172\n",
      "Epoch [470/500], Average Training Loss: 0.4129\n",
      "Epoch [470/500], Average Validation Loss: 0.4168, Average Validation Accuracy: 0.8176\n",
      "Epoch [471/500], Average Training Loss: 0.4129\n",
      "Epoch [471/500], Average Validation Loss: 0.4167, Average Validation Accuracy: 0.8173\n",
      "Epoch [472/500], Average Training Loss: 0.4129\n",
      "Epoch [472/500], Average Validation Loss: 0.4168, Average Validation Accuracy: 0.8176\n",
      "Epoch [473/500], Average Training Loss: 0.4129\n",
      "Epoch [473/500], Average Validation Loss: 0.4167, Average Validation Accuracy: 0.8176\n",
      "Epoch [474/500], Average Training Loss: 0.4129\n",
      "Epoch [474/500], Average Validation Loss: 0.4167, Average Validation Accuracy: 0.8175\n",
      "Epoch [475/500], Average Training Loss: 0.4129\n",
      "Epoch [475/500], Average Validation Loss: 0.4167, Average Validation Accuracy: 0.8172\n",
      "Epoch [476/500], Average Training Loss: 0.4128\n",
      "Epoch [476/500], Average Validation Loss: 0.4169, Average Validation Accuracy: 0.8175\n",
      "Epoch [477/500], Average Training Loss: 0.4128\n",
      "Epoch [477/500], Average Validation Loss: 0.4166, Average Validation Accuracy: 0.8174\n",
      "Epoch [478/500], Average Training Loss: 0.4128\n",
      "Epoch [478/500], Average Validation Loss: 0.4166, Average Validation Accuracy: 0.8174\n",
      "Epoch [479/500], Average Training Loss: 0.4128\n",
      "Epoch [479/500], Average Validation Loss: 0.4166, Average Validation Accuracy: 0.8174\n",
      "Epoch [480/500], Average Training Loss: 0.4128\n",
      "Epoch [480/500], Average Validation Loss: 0.4166, Average Validation Accuracy: 0.8176\n",
      "Epoch [481/500], Average Training Loss: 0.4127\n",
      "Epoch [481/500], Average Validation Loss: 0.4166, Average Validation Accuracy: 0.8176\n",
      "Epoch [482/500], Average Training Loss: 0.4127\n",
      "Epoch [482/500], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8175\n",
      "Epoch [483/500], Average Training Loss: 0.4127\n",
      "Epoch [483/500], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8175\n",
      "Epoch [484/500], Average Training Loss: 0.4127\n",
      "Epoch [484/500], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8177\n",
      "Epoch [485/500], Average Training Loss: 0.4127\n",
      "Epoch [485/500], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8175\n",
      "Epoch [486/500], Average Training Loss: 0.4126\n",
      "Epoch [486/500], Average Validation Loss: 0.4166, Average Validation Accuracy: 0.8176\n",
      "Epoch [487/500], Average Training Loss: 0.4126\n",
      "Epoch [487/500], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8177\n",
      "Epoch [488/500], Average Training Loss: 0.4126\n",
      "Epoch [488/500], Average Validation Loss: 0.4164, Average Validation Accuracy: 0.8175\n",
      "Epoch [489/500], Average Training Loss: 0.4126\n",
      "Epoch [489/500], Average Validation Loss: 0.4164, Average Validation Accuracy: 0.8174\n",
      "Epoch [490/500], Average Training Loss: 0.4126\n",
      "Epoch [490/500], Average Validation Loss: 0.4164, Average Validation Accuracy: 0.8174\n",
      "Epoch [491/500], Average Training Loss: 0.4126\n",
      "Epoch [491/500], Average Validation Loss: 0.4164, Average Validation Accuracy: 0.8175\n",
      "Epoch [492/500], Average Training Loss: 0.4125\n",
      "Epoch [492/500], Average Validation Loss: 0.4163, Average Validation Accuracy: 0.8176\n",
      "Epoch [493/500], Average Training Loss: 0.4126\n",
      "Epoch [493/500], Average Validation Loss: 0.4164, Average Validation Accuracy: 0.8176\n",
      "Epoch [494/500], Average Training Loss: 0.4126\n",
      "Epoch [494/500], Average Validation Loss: 0.4163, Average Validation Accuracy: 0.8175\n",
      "Epoch [495/500], Average Training Loss: 0.4125\n",
      "Epoch [495/500], Average Validation Loss: 0.4163, Average Validation Accuracy: 0.8180\n",
      "Epoch [496/500], Average Training Loss: 0.4125\n",
      "Epoch [496/500], Average Validation Loss: 0.4163, Average Validation Accuracy: 0.8178\n",
      "Epoch [497/500], Average Training Loss: 0.4125\n",
      "Epoch [497/500], Average Validation Loss: 0.4163, Average Validation Accuracy: 0.8176\n",
      "Epoch [498/500], Average Training Loss: 0.4124\n",
      "Epoch [498/500], Average Validation Loss: 0.4163, Average Validation Accuracy: 0.8177\n",
      "Epoch [499/500], Average Training Loss: 0.4125\n",
      "Epoch [499/500], Average Validation Loss: 0.4162, Average Validation Accuracy: 0.8175\n",
      "Epoch [500/500], Average Training Loss: 0.4124\n",
      "Epoch [500/500], Average Validation Loss: 0.4162, Average Validation Accuracy: 0.8175\n",
      "Best Validation Accuracy: 0.8180 at epoch 495 for trial 0\n",
      "Epoch [1/500], Average Training Loss: 0.6965\n",
      "Epoch [1/500], Average Validation Loss: 0.6971, Average Validation Accuracy: 0.4954\n",
      "Epoch [2/500], Average Training Loss: 0.6963\n",
      "Epoch [2/500], Average Validation Loss: 0.6969, Average Validation Accuracy: 0.4954\n",
      "Epoch [3/500], Average Training Loss: 0.6961\n",
      "Epoch [3/500], Average Validation Loss: 0.6967, Average Validation Accuracy: 0.4954\n",
      "Epoch [4/500], Average Training Loss: 0.6959\n",
      "Epoch [4/500], Average Validation Loss: 0.6964, Average Validation Accuracy: 0.4954\n",
      "Epoch [5/500], Average Training Loss: 0.6957\n",
      "Epoch [5/500], Average Validation Loss: 0.6962, Average Validation Accuracy: 0.4954\n",
      "Epoch [6/500], Average Training Loss: 0.6955\n",
      "Epoch [6/500], Average Validation Loss: 0.6960, Average Validation Accuracy: 0.4954\n",
      "Epoch [7/500], Average Training Loss: 0.6953\n",
      "Epoch [7/500], Average Validation Loss: 0.6958, Average Validation Accuracy: 0.4954\n",
      "Epoch [8/500], Average Training Loss: 0.6951\n",
      "Epoch [8/500], Average Validation Loss: 0.6956, Average Validation Accuracy: 0.4954\n",
      "Epoch [9/500], Average Training Loss: 0.6949\n",
      "Epoch [9/500], Average Validation Loss: 0.6954, Average Validation Accuracy: 0.4954\n",
      "Epoch [10/500], Average Training Loss: 0.6947\n",
      "Epoch [10/500], Average Validation Loss: 0.6952, Average Validation Accuracy: 0.4954\n",
      "Epoch [11/500], Average Training Loss: 0.6945\n",
      "Epoch [11/500], Average Validation Loss: 0.6950, Average Validation Accuracy: 0.4954\n",
      "Epoch [12/500], Average Training Loss: 0.6943\n",
      "Epoch [12/500], Average Validation Loss: 0.6948, Average Validation Accuracy: 0.4954\n",
      "Epoch [13/500], Average Training Loss: 0.6941\n",
      "Epoch [13/500], Average Validation Loss: 0.6946, Average Validation Accuracy: 0.4954\n",
      "Epoch [14/500], Average Training Loss: 0.6939\n",
      "Epoch [14/500], Average Validation Loss: 0.6944, Average Validation Accuracy: 0.4954\n",
      "Epoch [15/500], Average Training Loss: 0.6938\n",
      "Epoch [15/500], Average Validation Loss: 0.6942, Average Validation Accuracy: 0.4954\n",
      "Epoch [16/500], Average Training Loss: 0.6935\n",
      "Epoch [16/500], Average Validation Loss: 0.6940, Average Validation Accuracy: 0.4954\n",
      "Epoch [17/500], Average Training Loss: 0.6934\n",
      "Epoch [17/500], Average Validation Loss: 0.6938, Average Validation Accuracy: 0.4954\n",
      "Epoch [18/500], Average Training Loss: 0.6932\n",
      "Epoch [18/500], Average Validation Loss: 0.6936, Average Validation Accuracy: 0.4954\n",
      "Epoch [19/500], Average Training Loss: 0.6930\n",
      "Epoch [19/500], Average Validation Loss: 0.6934, Average Validation Accuracy: 0.4954\n",
      "Epoch [20/500], Average Training Loss: 0.6928\n",
      "Epoch [20/500], Average Validation Loss: 0.6932, Average Validation Accuracy: 0.4954\n",
      "Epoch [21/500], Average Training Loss: 0.6926\n",
      "Epoch [21/500], Average Validation Loss: 0.6930, Average Validation Accuracy: 0.4954\n",
      "Epoch [22/500], Average Training Loss: 0.6924\n",
      "Epoch [22/500], Average Validation Loss: 0.6928, Average Validation Accuracy: 0.4954\n",
      "Epoch [23/500], Average Training Loss: 0.6923\n",
      "Epoch [23/500], Average Validation Loss: 0.6926, Average Validation Accuracy: 0.4954\n",
      "Epoch [24/500], Average Training Loss: 0.6921\n",
      "Epoch [24/500], Average Validation Loss: 0.6924, Average Validation Accuracy: 0.4954\n",
      "Epoch [25/500], Average Training Loss: 0.6919\n",
      "Epoch [25/500], Average Validation Loss: 0.6922, Average Validation Accuracy: 0.4954\n",
      "Epoch [26/500], Average Training Loss: 0.6917\n",
      "Epoch [26/500], Average Validation Loss: 0.6921, Average Validation Accuracy: 0.4954\n",
      "Epoch [27/500], Average Training Loss: 0.6915\n",
      "Epoch [27/500], Average Validation Loss: 0.6919, Average Validation Accuracy: 0.4954\n",
      "Epoch [28/500], Average Training Loss: 0.6914\n",
      "Epoch [28/500], Average Validation Loss: 0.6917, Average Validation Accuracy: 0.4955\n",
      "Epoch [29/500], Average Training Loss: 0.6912\n",
      "Epoch [29/500], Average Validation Loss: 0.6915, Average Validation Accuracy: 0.4955\n",
      "Epoch [30/500], Average Training Loss: 0.6910\n",
      "Epoch [30/500], Average Validation Loss: 0.6913, Average Validation Accuracy: 0.4955\n",
      "Epoch [31/500], Average Training Loss: 0.6908\n",
      "Epoch [31/500], Average Validation Loss: 0.6911, Average Validation Accuracy: 0.4955\n",
      "Epoch [32/500], Average Training Loss: 0.6907\n",
      "Epoch [32/500], Average Validation Loss: 0.6910, Average Validation Accuracy: 0.4956\n",
      "Epoch [33/500], Average Training Loss: 0.6905\n",
      "Epoch [33/500], Average Validation Loss: 0.6908, Average Validation Accuracy: 0.4956\n",
      "Epoch [34/500], Average Training Loss: 0.6903\n",
      "Epoch [34/500], Average Validation Loss: 0.6906, Average Validation Accuracy: 0.4960\n",
      "Epoch [35/500], Average Training Loss: 0.6901\n",
      "Epoch [35/500], Average Validation Loss: 0.6904, Average Validation Accuracy: 0.4962\n",
      "Epoch [36/500], Average Training Loss: 0.6900\n",
      "Epoch [36/500], Average Validation Loss: 0.6902, Average Validation Accuracy: 0.4969\n",
      "Epoch [37/500], Average Training Loss: 0.6898\n",
      "Epoch [37/500], Average Validation Loss: 0.6900, Average Validation Accuracy: 0.4978\n",
      "Epoch [38/500], Average Training Loss: 0.6896\n",
      "Epoch [38/500], Average Validation Loss: 0.6899, Average Validation Accuracy: 0.4988\n",
      "Epoch [39/500], Average Training Loss: 0.6894\n",
      "Epoch [39/500], Average Validation Loss: 0.6897, Average Validation Accuracy: 0.5000\n",
      "Epoch [40/500], Average Training Loss: 0.6893\n",
      "Epoch [40/500], Average Validation Loss: 0.6895, Average Validation Accuracy: 0.5011\n",
      "Epoch [41/500], Average Training Loss: 0.6891\n",
      "Epoch [41/500], Average Validation Loss: 0.6893, Average Validation Accuracy: 0.5030\n",
      "Epoch [42/500], Average Training Loss: 0.6889\n",
      "Epoch [42/500], Average Validation Loss: 0.6892, Average Validation Accuracy: 0.5054\n",
      "Epoch [43/500], Average Training Loss: 0.6887\n",
      "Epoch [43/500], Average Validation Loss: 0.6890, Average Validation Accuracy: 0.5090\n",
      "Epoch [44/500], Average Training Loss: 0.6886\n",
      "Epoch [44/500], Average Validation Loss: 0.6888, Average Validation Accuracy: 0.5127\n",
      "Epoch [45/500], Average Training Loss: 0.6884\n",
      "Epoch [45/500], Average Validation Loss: 0.6886, Average Validation Accuracy: 0.5160\n",
      "Epoch [46/500], Average Training Loss: 0.6882\n",
      "Epoch [46/500], Average Validation Loss: 0.6884, Average Validation Accuracy: 0.5209\n",
      "Epoch [47/500], Average Training Loss: 0.6880\n",
      "Epoch [47/500], Average Validation Loss: 0.6883, Average Validation Accuracy: 0.5258\n",
      "Epoch [48/500], Average Training Loss: 0.6879\n",
      "Epoch [48/500], Average Validation Loss: 0.6881, Average Validation Accuracy: 0.5315\n",
      "Epoch [49/500], Average Training Loss: 0.6877\n",
      "Epoch [49/500], Average Validation Loss: 0.6879, Average Validation Accuracy: 0.5376\n",
      "Epoch [50/500], Average Training Loss: 0.6875\n",
      "Epoch [50/500], Average Validation Loss: 0.6877, Average Validation Accuracy: 0.5433\n",
      "Epoch [51/500], Average Training Loss: 0.6873\n",
      "Epoch [51/500], Average Validation Loss: 0.6875, Average Validation Accuracy: 0.5493\n",
      "Epoch [52/500], Average Training Loss: 0.6872\n",
      "Epoch [52/500], Average Validation Loss: 0.6874, Average Validation Accuracy: 0.5557\n",
      "Epoch [53/500], Average Training Loss: 0.6870\n",
      "Epoch [53/500], Average Validation Loss: 0.6872, Average Validation Accuracy: 0.5624\n",
      "Epoch [54/500], Average Training Loss: 0.6868\n",
      "Epoch [54/500], Average Validation Loss: 0.6870, Average Validation Accuracy: 0.5693\n",
      "Epoch [55/500], Average Training Loss: 0.6867\n",
      "Epoch [55/500], Average Validation Loss: 0.6868, Average Validation Accuracy: 0.5760\n",
      "Epoch [56/500], Average Training Loss: 0.6865\n",
      "Epoch [56/500], Average Validation Loss: 0.6867, Average Validation Accuracy: 0.5838\n",
      "Epoch [57/500], Average Training Loss: 0.6863\n",
      "Epoch [57/500], Average Validation Loss: 0.6865, Average Validation Accuracy: 0.5919\n",
      "Epoch [58/500], Average Training Loss: 0.6861\n",
      "Epoch [58/500], Average Validation Loss: 0.6863, Average Validation Accuracy: 0.5989\n",
      "Epoch [59/500], Average Training Loss: 0.6860\n",
      "Epoch [59/500], Average Validation Loss: 0.6861, Average Validation Accuracy: 0.6065\n",
      "Epoch [60/500], Average Training Loss: 0.6858\n",
      "Epoch [60/500], Average Validation Loss: 0.6859, Average Validation Accuracy: 0.6141\n",
      "Epoch [61/500], Average Training Loss: 0.6856\n",
      "Epoch [61/500], Average Validation Loss: 0.6858, Average Validation Accuracy: 0.6221\n",
      "Epoch [62/500], Average Training Loss: 0.6854\n",
      "Epoch [62/500], Average Validation Loss: 0.6856, Average Validation Accuracy: 0.6288\n",
      "Epoch [63/500], Average Training Loss: 0.6853\n",
      "Epoch [63/500], Average Validation Loss: 0.6854, Average Validation Accuracy: 0.6350\n",
      "Epoch [64/500], Average Training Loss: 0.6851\n",
      "Epoch [64/500], Average Validation Loss: 0.6852, Average Validation Accuracy: 0.6403\n",
      "Epoch [65/500], Average Training Loss: 0.6849\n",
      "Epoch [65/500], Average Validation Loss: 0.6850, Average Validation Accuracy: 0.6462\n",
      "Epoch [66/500], Average Training Loss: 0.6847\n",
      "Epoch [66/500], Average Validation Loss: 0.6849, Average Validation Accuracy: 0.6528\n",
      "Epoch [67/500], Average Training Loss: 0.6845\n",
      "Epoch [67/500], Average Validation Loss: 0.6847, Average Validation Accuracy: 0.6590\n",
      "Epoch [68/500], Average Training Loss: 0.6844\n",
      "Epoch [68/500], Average Validation Loss: 0.6845, Average Validation Accuracy: 0.6645\n",
      "Epoch [69/500], Average Training Loss: 0.6842\n",
      "Epoch [69/500], Average Validation Loss: 0.6843, Average Validation Accuracy: 0.6697\n",
      "Epoch [70/500], Average Training Loss: 0.6840\n",
      "Epoch [70/500], Average Validation Loss: 0.6841, Average Validation Accuracy: 0.6750\n",
      "Epoch [71/500], Average Training Loss: 0.6838\n",
      "Epoch [71/500], Average Validation Loss: 0.6840, Average Validation Accuracy: 0.6793\n",
      "Epoch [72/500], Average Training Loss: 0.6837\n",
      "Epoch [72/500], Average Validation Loss: 0.6838, Average Validation Accuracy: 0.6851\n",
      "Epoch [73/500], Average Training Loss: 0.6835\n",
      "Epoch [73/500], Average Validation Loss: 0.6836, Average Validation Accuracy: 0.6882\n",
      "Epoch [74/500], Average Training Loss: 0.6833\n",
      "Epoch [74/500], Average Validation Loss: 0.6834, Average Validation Accuracy: 0.6915\n",
      "Epoch [75/500], Average Training Loss: 0.6831\n",
      "Epoch [75/500], Average Validation Loss: 0.6832, Average Validation Accuracy: 0.6962\n",
      "Epoch [76/500], Average Training Loss: 0.6829\n",
      "Epoch [76/500], Average Validation Loss: 0.6830, Average Validation Accuracy: 0.6994\n",
      "Epoch [77/500], Average Training Loss: 0.6827\n",
      "Epoch [77/500], Average Validation Loss: 0.6828, Average Validation Accuracy: 0.7019\n",
      "Epoch [78/500], Average Training Loss: 0.6825\n",
      "Epoch [78/500], Average Validation Loss: 0.6827, Average Validation Accuracy: 0.7064\n",
      "Epoch [79/500], Average Training Loss: 0.6824\n",
      "Epoch [79/500], Average Validation Loss: 0.6825, Average Validation Accuracy: 0.7081\n",
      "Epoch [80/500], Average Training Loss: 0.6822\n",
      "Epoch [80/500], Average Validation Loss: 0.6823, Average Validation Accuracy: 0.7101\n",
      "Epoch [81/500], Average Training Loss: 0.6820\n",
      "Epoch [81/500], Average Validation Loss: 0.6821, Average Validation Accuracy: 0.7130\n",
      "Epoch [82/500], Average Training Loss: 0.6818\n",
      "Epoch [82/500], Average Validation Loss: 0.6819, Average Validation Accuracy: 0.7149\n",
      "Epoch [83/500], Average Training Loss: 0.6816\n",
      "Epoch [83/500], Average Validation Loss: 0.6817, Average Validation Accuracy: 0.7170\n",
      "Epoch [84/500], Average Training Loss: 0.6814\n",
      "Epoch [84/500], Average Validation Loss: 0.6815, Average Validation Accuracy: 0.7190\n",
      "Epoch [85/500], Average Training Loss: 0.6813\n",
      "Epoch [85/500], Average Validation Loss: 0.6813, Average Validation Accuracy: 0.7215\n",
      "Epoch [86/500], Average Training Loss: 0.6811\n",
      "Epoch [86/500], Average Validation Loss: 0.6811, Average Validation Accuracy: 0.7223\n",
      "Epoch [87/500], Average Training Loss: 0.6809\n",
      "Epoch [87/500], Average Validation Loss: 0.6809, Average Validation Accuracy: 0.7229\n",
      "Epoch [88/500], Average Training Loss: 0.6807\n",
      "Epoch [88/500], Average Validation Loss: 0.6807, Average Validation Accuracy: 0.7244\n",
      "Epoch [89/500], Average Training Loss: 0.6805\n",
      "Epoch [89/500], Average Validation Loss: 0.6806, Average Validation Accuracy: 0.7261\n",
      "Epoch [90/500], Average Training Loss: 0.6803\n",
      "Epoch [90/500], Average Validation Loss: 0.6804, Average Validation Accuracy: 0.7279\n",
      "Epoch [91/500], Average Training Loss: 0.6801\n",
      "Epoch [91/500], Average Validation Loss: 0.6802, Average Validation Accuracy: 0.7302\n",
      "Epoch [92/500], Average Training Loss: 0.6799\n",
      "Epoch [92/500], Average Validation Loss: 0.6800, Average Validation Accuracy: 0.7314\n",
      "Epoch [93/500], Average Training Loss: 0.6797\n",
      "Epoch [93/500], Average Validation Loss: 0.6798, Average Validation Accuracy: 0.7331\n",
      "Epoch [94/500], Average Training Loss: 0.6795\n",
      "Epoch [94/500], Average Validation Loss: 0.6796, Average Validation Accuracy: 0.7340\n",
      "Epoch [95/500], Average Training Loss: 0.6793\n",
      "Epoch [95/500], Average Validation Loss: 0.6794, Average Validation Accuracy: 0.7349\n",
      "Epoch [96/500], Average Training Loss: 0.6791\n",
      "Epoch [96/500], Average Validation Loss: 0.6792, Average Validation Accuracy: 0.7364\n",
      "Epoch [97/500], Average Training Loss: 0.6789\n",
      "Epoch [97/500], Average Validation Loss: 0.6790, Average Validation Accuracy: 0.7379\n",
      "Epoch [98/500], Average Training Loss: 0.6787\n",
      "Epoch [98/500], Average Validation Loss: 0.6788, Average Validation Accuracy: 0.7377\n",
      "Epoch [99/500], Average Training Loss: 0.6785\n",
      "Epoch [99/500], Average Validation Loss: 0.6786, Average Validation Accuracy: 0.7386\n",
      "Epoch [100/500], Average Training Loss: 0.6783\n",
      "Epoch [100/500], Average Validation Loss: 0.6783, Average Validation Accuracy: 0.7389\n",
      "Epoch [101/500], Average Training Loss: 0.6781\n",
      "Epoch [101/500], Average Validation Loss: 0.6781, Average Validation Accuracy: 0.7395\n",
      "Epoch [102/500], Average Training Loss: 0.6779\n",
      "Epoch [102/500], Average Validation Loss: 0.6779, Average Validation Accuracy: 0.7404\n",
      "Epoch [103/500], Average Training Loss: 0.6777\n",
      "Epoch [103/500], Average Validation Loss: 0.6777, Average Validation Accuracy: 0.7409\n",
      "Epoch [104/500], Average Training Loss: 0.6775\n",
      "Epoch [104/500], Average Validation Loss: 0.6775, Average Validation Accuracy: 0.7417\n",
      "Epoch [105/500], Average Training Loss: 0.6773\n",
      "Epoch [105/500], Average Validation Loss: 0.6773, Average Validation Accuracy: 0.7418\n",
      "Epoch [106/500], Average Training Loss: 0.6771\n",
      "Epoch [106/500], Average Validation Loss: 0.6771, Average Validation Accuracy: 0.7426\n",
      "Epoch [107/500], Average Training Loss: 0.6769\n",
      "Epoch [107/500], Average Validation Loss: 0.6769, Average Validation Accuracy: 0.7427\n",
      "Epoch [108/500], Average Training Loss: 0.6766\n",
      "Epoch [108/500], Average Validation Loss: 0.6767, Average Validation Accuracy: 0.7432\n",
      "Epoch [109/500], Average Training Loss: 0.6764\n",
      "Epoch [109/500], Average Validation Loss: 0.6764, Average Validation Accuracy: 0.7434\n",
      "Epoch [110/500], Average Training Loss: 0.6762\n",
      "Epoch [110/500], Average Validation Loss: 0.6762, Average Validation Accuracy: 0.7441\n",
      "Epoch [111/500], Average Training Loss: 0.6760\n",
      "Epoch [111/500], Average Validation Loss: 0.6760, Average Validation Accuracy: 0.7439\n",
      "Epoch [112/500], Average Training Loss: 0.6758\n",
      "Epoch [112/500], Average Validation Loss: 0.6758, Average Validation Accuracy: 0.7438\n",
      "Epoch [113/500], Average Training Loss: 0.6756\n",
      "Epoch [113/500], Average Validation Loss: 0.6756, Average Validation Accuracy: 0.7438\n",
      "Epoch [114/500], Average Training Loss: 0.6753\n",
      "Epoch [114/500], Average Validation Loss: 0.6754, Average Validation Accuracy: 0.7441\n",
      "Epoch [115/500], Average Training Loss: 0.6751\n",
      "Epoch [115/500], Average Validation Loss: 0.6751, Average Validation Accuracy: 0.7449\n",
      "Epoch [116/500], Average Training Loss: 0.6749\n",
      "Epoch [116/500], Average Validation Loss: 0.6749, Average Validation Accuracy: 0.7448\n",
      "Epoch [117/500], Average Training Loss: 0.6747\n",
      "Epoch [117/500], Average Validation Loss: 0.6747, Average Validation Accuracy: 0.7451\n",
      "Epoch [118/500], Average Training Loss: 0.6744\n",
      "Epoch [118/500], Average Validation Loss: 0.6744, Average Validation Accuracy: 0.7450\n",
      "Epoch [119/500], Average Training Loss: 0.6742\n",
      "Epoch [119/500], Average Validation Loss: 0.6742, Average Validation Accuracy: 0.7450\n",
      "Epoch [120/500], Average Training Loss: 0.6740\n",
      "Epoch [120/500], Average Validation Loss: 0.6740, Average Validation Accuracy: 0.7456\n",
      "Epoch [121/500], Average Training Loss: 0.6737\n",
      "Epoch [121/500], Average Validation Loss: 0.6738, Average Validation Accuracy: 0.7460\n",
      "Epoch [122/500], Average Training Loss: 0.6735\n",
      "Epoch [122/500], Average Validation Loss: 0.6735, Average Validation Accuracy: 0.7467\n",
      "Epoch [123/500], Average Training Loss: 0.6733\n",
      "Epoch [123/500], Average Validation Loss: 0.6733, Average Validation Accuracy: 0.7468\n",
      "Epoch [124/500], Average Training Loss: 0.6731\n",
      "Epoch [124/500], Average Validation Loss: 0.6731, Average Validation Accuracy: 0.7468\n",
      "Epoch [125/500], Average Training Loss: 0.6728\n",
      "Epoch [125/500], Average Validation Loss: 0.6728, Average Validation Accuracy: 0.7468\n",
      "Epoch [126/500], Average Training Loss: 0.6726\n",
      "Epoch [126/500], Average Validation Loss: 0.6726, Average Validation Accuracy: 0.7470\n",
      "Epoch [127/500], Average Training Loss: 0.6723\n",
      "Epoch [127/500], Average Validation Loss: 0.6723, Average Validation Accuracy: 0.7471\n",
      "Epoch [128/500], Average Training Loss: 0.6721\n",
      "Epoch [128/500], Average Validation Loss: 0.6721, Average Validation Accuracy: 0.7474\n",
      "Epoch [129/500], Average Training Loss: 0.6718\n",
      "Epoch [129/500], Average Validation Loss: 0.6719, Average Validation Accuracy: 0.7480\n",
      "Epoch [130/500], Average Training Loss: 0.6716\n",
      "Epoch [130/500], Average Validation Loss: 0.6716, Average Validation Accuracy: 0.7482\n",
      "Epoch [131/500], Average Training Loss: 0.6714\n",
      "Epoch [131/500], Average Validation Loss: 0.6714, Average Validation Accuracy: 0.7483\n",
      "Epoch [132/500], Average Training Loss: 0.6711\n",
      "Epoch [132/500], Average Validation Loss: 0.6711, Average Validation Accuracy: 0.7487\n",
      "Epoch [133/500], Average Training Loss: 0.6709\n",
      "Epoch [133/500], Average Validation Loss: 0.6709, Average Validation Accuracy: 0.7490\n",
      "Epoch [134/500], Average Training Loss: 0.6706\n",
      "Epoch [134/500], Average Validation Loss: 0.6706, Average Validation Accuracy: 0.7494\n",
      "Epoch [135/500], Average Training Loss: 0.6704\n",
      "Epoch [135/500], Average Validation Loss: 0.6704, Average Validation Accuracy: 0.7498\n",
      "Epoch [136/500], Average Training Loss: 0.6701\n",
      "Epoch [136/500], Average Validation Loss: 0.6701, Average Validation Accuracy: 0.7503\n",
      "Epoch [137/500], Average Training Loss: 0.6699\n",
      "Epoch [137/500], Average Validation Loss: 0.6698, Average Validation Accuracy: 0.7509\n",
      "Epoch [138/500], Average Training Loss: 0.6696\n",
      "Epoch [138/500], Average Validation Loss: 0.6696, Average Validation Accuracy: 0.7512\n",
      "Epoch [139/500], Average Training Loss: 0.6693\n",
      "Epoch [139/500], Average Validation Loss: 0.6693, Average Validation Accuracy: 0.7513\n",
      "Epoch [140/500], Average Training Loss: 0.6691\n",
      "Epoch [140/500], Average Validation Loss: 0.6691, Average Validation Accuracy: 0.7514\n",
      "Epoch [141/500], Average Training Loss: 0.6688\n",
      "Epoch [141/500], Average Validation Loss: 0.6688, Average Validation Accuracy: 0.7516\n",
      "Epoch [142/500], Average Training Loss: 0.6685\n",
      "Epoch [142/500], Average Validation Loss: 0.6685, Average Validation Accuracy: 0.7517\n",
      "Epoch [143/500], Average Training Loss: 0.6683\n",
      "Epoch [143/500], Average Validation Loss: 0.6683, Average Validation Accuracy: 0.7522\n",
      "Epoch [144/500], Average Training Loss: 0.6680\n",
      "Epoch [144/500], Average Validation Loss: 0.6680, Average Validation Accuracy: 0.7526\n",
      "Epoch [145/500], Average Training Loss: 0.6677\n",
      "Epoch [145/500], Average Validation Loss: 0.6677, Average Validation Accuracy: 0.7528\n",
      "Epoch [146/500], Average Training Loss: 0.6675\n",
      "Epoch [146/500], Average Validation Loss: 0.6674, Average Validation Accuracy: 0.7529\n",
      "Epoch [147/500], Average Training Loss: 0.6672\n",
      "Epoch [147/500], Average Validation Loss: 0.6672, Average Validation Accuracy: 0.7532\n",
      "Epoch [148/500], Average Training Loss: 0.6669\n",
      "Epoch [148/500], Average Validation Loss: 0.6669, Average Validation Accuracy: 0.7534\n",
      "Epoch [149/500], Average Training Loss: 0.6666\n",
      "Epoch [149/500], Average Validation Loss: 0.6666, Average Validation Accuracy: 0.7536\n",
      "Epoch [150/500], Average Training Loss: 0.6663\n",
      "Epoch [150/500], Average Validation Loss: 0.6663, Average Validation Accuracy: 0.7536\n",
      "Epoch [151/500], Average Training Loss: 0.6661\n",
      "Epoch [151/500], Average Validation Loss: 0.6660, Average Validation Accuracy: 0.7536\n",
      "Epoch [152/500], Average Training Loss: 0.6658\n",
      "Epoch [152/500], Average Validation Loss: 0.6657, Average Validation Accuracy: 0.7538\n",
      "Epoch [153/500], Average Training Loss: 0.6655\n",
      "Epoch [153/500], Average Validation Loss: 0.6655, Average Validation Accuracy: 0.7538\n",
      "Epoch [154/500], Average Training Loss: 0.6652\n",
      "Epoch [154/500], Average Validation Loss: 0.6652, Average Validation Accuracy: 0.7539\n",
      "Epoch [155/500], Average Training Loss: 0.6649\n",
      "Epoch [155/500], Average Validation Loss: 0.6649, Average Validation Accuracy: 0.7539\n",
      "Epoch [156/500], Average Training Loss: 0.6646\n",
      "Epoch [156/500], Average Validation Loss: 0.6646, Average Validation Accuracy: 0.7539\n",
      "Epoch [157/500], Average Training Loss: 0.6643\n",
      "Epoch [157/500], Average Validation Loss: 0.6643, Average Validation Accuracy: 0.7539\n",
      "Epoch [158/500], Average Training Loss: 0.6640\n",
      "Epoch [158/500], Average Validation Loss: 0.6640, Average Validation Accuracy: 0.7540\n",
      "Epoch [159/500], Average Training Loss: 0.6637\n",
      "Epoch [159/500], Average Validation Loss: 0.6637, Average Validation Accuracy: 0.7539\n",
      "Epoch [160/500], Average Training Loss: 0.6634\n",
      "Epoch [160/500], Average Validation Loss: 0.6634, Average Validation Accuracy: 0.7541\n",
      "Epoch [161/500], Average Training Loss: 0.6631\n",
      "Epoch [161/500], Average Validation Loss: 0.6631, Average Validation Accuracy: 0.7543\n",
      "Epoch [162/500], Average Training Loss: 0.6628\n",
      "Epoch [162/500], Average Validation Loss: 0.6628, Average Validation Accuracy: 0.7542\n",
      "Epoch [163/500], Average Training Loss: 0.6625\n",
      "Epoch [163/500], Average Validation Loss: 0.6624, Average Validation Accuracy: 0.7543\n",
      "Epoch [164/500], Average Training Loss: 0.6622\n",
      "Epoch [164/500], Average Validation Loss: 0.6621, Average Validation Accuracy: 0.7547\n",
      "Epoch [165/500], Average Training Loss: 0.6619\n",
      "Epoch [165/500], Average Validation Loss: 0.6618, Average Validation Accuracy: 0.7548\n",
      "Epoch [166/500], Average Training Loss: 0.6615\n",
      "Epoch [166/500], Average Validation Loss: 0.6615, Average Validation Accuracy: 0.7549\n",
      "Epoch [167/500], Average Training Loss: 0.6612\n",
      "Epoch [167/500], Average Validation Loss: 0.6612, Average Validation Accuracy: 0.7549\n",
      "Epoch [168/500], Average Training Loss: 0.6609\n",
      "Epoch [168/500], Average Validation Loss: 0.6608, Average Validation Accuracy: 0.7548\n",
      "Epoch [169/500], Average Training Loss: 0.6606\n",
      "Epoch [169/500], Average Validation Loss: 0.6605, Average Validation Accuracy: 0.7550\n",
      "Epoch [170/500], Average Training Loss: 0.6602\n",
      "Epoch [170/500], Average Validation Loss: 0.6602, Average Validation Accuracy: 0.7550\n",
      "Epoch [171/500], Average Training Loss: 0.6599\n",
      "Epoch [171/500], Average Validation Loss: 0.6599, Average Validation Accuracy: 0.7550\n",
      "Epoch [172/500], Average Training Loss: 0.6596\n",
      "Epoch [172/500], Average Validation Loss: 0.6595, Average Validation Accuracy: 0.7551\n",
      "Epoch [173/500], Average Training Loss: 0.6592\n",
      "Epoch [173/500], Average Validation Loss: 0.6592, Average Validation Accuracy: 0.7552\n",
      "Epoch [174/500], Average Training Loss: 0.6589\n",
      "Epoch [174/500], Average Validation Loss: 0.6589, Average Validation Accuracy: 0.7551\n",
      "Epoch [175/500], Average Training Loss: 0.6586\n",
      "Epoch [175/500], Average Validation Loss: 0.6585, Average Validation Accuracy: 0.7552\n",
      "Epoch [176/500], Average Training Loss: 0.6582\n",
      "Epoch [176/500], Average Validation Loss: 0.6582, Average Validation Accuracy: 0.7553\n",
      "Epoch [177/500], Average Training Loss: 0.6579\n",
      "Epoch [177/500], Average Validation Loss: 0.6578, Average Validation Accuracy: 0.7551\n",
      "Epoch [178/500], Average Training Loss: 0.6575\n",
      "Epoch [178/500], Average Validation Loss: 0.6575, Average Validation Accuracy: 0.7552\n",
      "Epoch [179/500], Average Training Loss: 0.6572\n",
      "Epoch [179/500], Average Validation Loss: 0.6571, Average Validation Accuracy: 0.7554\n",
      "Epoch [180/500], Average Training Loss: 0.6568\n",
      "Epoch [180/500], Average Validation Loss: 0.6568, Average Validation Accuracy: 0.7554\n",
      "Epoch [181/500], Average Training Loss: 0.6565\n",
      "Epoch [181/500], Average Validation Loss: 0.6564, Average Validation Accuracy: 0.7553\n",
      "Epoch [182/500], Average Training Loss: 0.6561\n",
      "Epoch [182/500], Average Validation Loss: 0.6560, Average Validation Accuracy: 0.7554\n",
      "Epoch [183/500], Average Training Loss: 0.6557\n",
      "Epoch [183/500], Average Validation Loss: 0.6557, Average Validation Accuracy: 0.7555\n",
      "Epoch [184/500], Average Training Loss: 0.6554\n",
      "Epoch [184/500], Average Validation Loss: 0.6553, Average Validation Accuracy: 0.7556\n",
      "Epoch [185/500], Average Training Loss: 0.6550\n",
      "Epoch [185/500], Average Validation Loss: 0.6549, Average Validation Accuracy: 0.7554\n",
      "Epoch [186/500], Average Training Loss: 0.6546\n",
      "Epoch [186/500], Average Validation Loss: 0.6546, Average Validation Accuracy: 0.7555\n",
      "Epoch [187/500], Average Training Loss: 0.6543\n",
      "Epoch [187/500], Average Validation Loss: 0.6542, Average Validation Accuracy: 0.7556\n",
      "Epoch [188/500], Average Training Loss: 0.6539\n",
      "Epoch [188/500], Average Validation Loss: 0.6538, Average Validation Accuracy: 0.7554\n",
      "Epoch [189/500], Average Training Loss: 0.6535\n",
      "Epoch [189/500], Average Validation Loss: 0.6534, Average Validation Accuracy: 0.7553\n",
      "Epoch [190/500], Average Training Loss: 0.6531\n",
      "Epoch [190/500], Average Validation Loss: 0.6531, Average Validation Accuracy: 0.7553\n",
      "Epoch [191/500], Average Training Loss: 0.6527\n",
      "Epoch [191/500], Average Validation Loss: 0.6527, Average Validation Accuracy: 0.7553\n",
      "Epoch [192/500], Average Training Loss: 0.6524\n",
      "Epoch [192/500], Average Validation Loss: 0.6523, Average Validation Accuracy: 0.7555\n",
      "Epoch [193/500], Average Training Loss: 0.6519\n",
      "Epoch [193/500], Average Validation Loss: 0.6519, Average Validation Accuracy: 0.7554\n",
      "Epoch [194/500], Average Training Loss: 0.6515\n",
      "Epoch [194/500], Average Validation Loss: 0.6515, Average Validation Accuracy: 0.7556\n",
      "Epoch [195/500], Average Training Loss: 0.6512\n",
      "Epoch [195/500], Average Validation Loss: 0.6511, Average Validation Accuracy: 0.7557\n",
      "Epoch [196/500], Average Training Loss: 0.6507\n",
      "Epoch [196/500], Average Validation Loss: 0.6507, Average Validation Accuracy: 0.7554\n",
      "Epoch [197/500], Average Training Loss: 0.6503\n",
      "Epoch [197/500], Average Validation Loss: 0.6503, Average Validation Accuracy: 0.7554\n",
      "Epoch [198/500], Average Training Loss: 0.6499\n",
      "Epoch [198/500], Average Validation Loss: 0.6499, Average Validation Accuracy: 0.7554\n",
      "Epoch [199/500], Average Training Loss: 0.6495\n",
      "Epoch [199/500], Average Validation Loss: 0.6495, Average Validation Accuracy: 0.7553\n",
      "Epoch [200/500], Average Training Loss: 0.6491\n",
      "Epoch [200/500], Average Validation Loss: 0.6490, Average Validation Accuracy: 0.7553\n",
      "Epoch [201/500], Average Training Loss: 0.6487\n",
      "Epoch [201/500], Average Validation Loss: 0.6486, Average Validation Accuracy: 0.7553\n",
      "Epoch [202/500], Average Training Loss: 0.6483\n",
      "Epoch [202/500], Average Validation Loss: 0.6482, Average Validation Accuracy: 0.7553\n",
      "Epoch [203/500], Average Training Loss: 0.6478\n",
      "Epoch [203/500], Average Validation Loss: 0.6478, Average Validation Accuracy: 0.7555\n",
      "Epoch [204/500], Average Training Loss: 0.6474\n",
      "Epoch [204/500], Average Validation Loss: 0.6474, Average Validation Accuracy: 0.7557\n",
      "Epoch [205/500], Average Training Loss: 0.6470\n",
      "Epoch [205/500], Average Validation Loss: 0.6469, Average Validation Accuracy: 0.7557\n",
      "Epoch [206/500], Average Training Loss: 0.6466\n",
      "Epoch [206/500], Average Validation Loss: 0.6465, Average Validation Accuracy: 0.7557\n",
      "Epoch [207/500], Average Training Loss: 0.6461\n",
      "Epoch [207/500], Average Validation Loss: 0.6461, Average Validation Accuracy: 0.7559\n",
      "Epoch [208/500], Average Training Loss: 0.6457\n",
      "Epoch [208/500], Average Validation Loss: 0.6456, Average Validation Accuracy: 0.7560\n",
      "Epoch [209/500], Average Training Loss: 0.6452\n",
      "Epoch [209/500], Average Validation Loss: 0.6452, Average Validation Accuracy: 0.7559\n",
      "Epoch [210/500], Average Training Loss: 0.6448\n",
      "Epoch [210/500], Average Validation Loss: 0.6447, Average Validation Accuracy: 0.7560\n",
      "Epoch [211/500], Average Training Loss: 0.6443\n",
      "Epoch [211/500], Average Validation Loss: 0.6443, Average Validation Accuracy: 0.7564\n",
      "Epoch [212/500], Average Training Loss: 0.6439\n",
      "Epoch [212/500], Average Validation Loss: 0.6438, Average Validation Accuracy: 0.7565\n",
      "Epoch [213/500], Average Training Loss: 0.6434\n",
      "Epoch [213/500], Average Validation Loss: 0.6434, Average Validation Accuracy: 0.7566\n",
      "Epoch [214/500], Average Training Loss: 0.6430\n",
      "Epoch [214/500], Average Validation Loss: 0.6429, Average Validation Accuracy: 0.7567\n",
      "Epoch [215/500], Average Training Loss: 0.6425\n",
      "Epoch [215/500], Average Validation Loss: 0.6424, Average Validation Accuracy: 0.7568\n",
      "Epoch [216/500], Average Training Loss: 0.6420\n",
      "Epoch [216/500], Average Validation Loss: 0.6420, Average Validation Accuracy: 0.7569\n",
      "Epoch [217/500], Average Training Loss: 0.6415\n",
      "Epoch [217/500], Average Validation Loss: 0.6415, Average Validation Accuracy: 0.7569\n",
      "Epoch [218/500], Average Training Loss: 0.6411\n",
      "Epoch [218/500], Average Validation Loss: 0.6410, Average Validation Accuracy: 0.7569\n",
      "Epoch [219/500], Average Training Loss: 0.6406\n",
      "Epoch [219/500], Average Validation Loss: 0.6405, Average Validation Accuracy: 0.7569\n",
      "Epoch [220/500], Average Training Loss: 0.6401\n",
      "Epoch [220/500], Average Validation Loss: 0.6400, Average Validation Accuracy: 0.7570\n",
      "Epoch [221/500], Average Training Loss: 0.6396\n",
      "Epoch [221/500], Average Validation Loss: 0.6396, Average Validation Accuracy: 0.7569\n",
      "Epoch [222/500], Average Training Loss: 0.6391\n",
      "Epoch [222/500], Average Validation Loss: 0.6391, Average Validation Accuracy: 0.7569\n",
      "Epoch [223/500], Average Training Loss: 0.6386\n",
      "Epoch [223/500], Average Validation Loss: 0.6386, Average Validation Accuracy: 0.7569\n",
      "Epoch [224/500], Average Training Loss: 0.6382\n",
      "Epoch [224/500], Average Validation Loss: 0.6381, Average Validation Accuracy: 0.7569\n",
      "Epoch [225/500], Average Training Loss: 0.6376\n",
      "Epoch [225/500], Average Validation Loss: 0.6376, Average Validation Accuracy: 0.7571\n",
      "Epoch [226/500], Average Training Loss: 0.6371\n",
      "Epoch [226/500], Average Validation Loss: 0.6371, Average Validation Accuracy: 0.7571\n",
      "Epoch [227/500], Average Training Loss: 0.6366\n",
      "Epoch [227/500], Average Validation Loss: 0.6366, Average Validation Accuracy: 0.7569\n",
      "Epoch [228/500], Average Training Loss: 0.6361\n",
      "Epoch [228/500], Average Validation Loss: 0.6360, Average Validation Accuracy: 0.7569\n",
      "Epoch [229/500], Average Training Loss: 0.6356\n",
      "Epoch [229/500], Average Validation Loss: 0.6355, Average Validation Accuracy: 0.7568\n",
      "Epoch [230/500], Average Training Loss: 0.6351\n",
      "Epoch [230/500], Average Validation Loss: 0.6350, Average Validation Accuracy: 0.7569\n",
      "Epoch [231/500], Average Training Loss: 0.6345\n",
      "Epoch [231/500], Average Validation Loss: 0.6345, Average Validation Accuracy: 0.7568\n",
      "Epoch [232/500], Average Training Loss: 0.6340\n",
      "Epoch [232/500], Average Validation Loss: 0.6340, Average Validation Accuracy: 0.7568\n",
      "Epoch [233/500], Average Training Loss: 0.6335\n",
      "Epoch [233/500], Average Validation Loss: 0.6334, Average Validation Accuracy: 0.7568\n",
      "Epoch [234/500], Average Training Loss: 0.6329\n",
      "Epoch [234/500], Average Validation Loss: 0.6329, Average Validation Accuracy: 0.7567\n",
      "Epoch [235/500], Average Training Loss: 0.6324\n",
      "Epoch [235/500], Average Validation Loss: 0.6323, Average Validation Accuracy: 0.7567\n",
      "Epoch [236/500], Average Training Loss: 0.6319\n",
      "Epoch [236/500], Average Validation Loss: 0.6318, Average Validation Accuracy: 0.7567\n",
      "Epoch [237/500], Average Training Loss: 0.6313\n",
      "Epoch [237/500], Average Validation Loss: 0.6313, Average Validation Accuracy: 0.7568\n",
      "Epoch [238/500], Average Training Loss: 0.6307\n",
      "Epoch [238/500], Average Validation Loss: 0.6307, Average Validation Accuracy: 0.7569\n",
      "Epoch [239/500], Average Training Loss: 0.6302\n",
      "Epoch [239/500], Average Validation Loss: 0.6301, Average Validation Accuracy: 0.7571\n",
      "Epoch [240/500], Average Training Loss: 0.6296\n",
      "Epoch [240/500], Average Validation Loss: 0.6296, Average Validation Accuracy: 0.7572\n",
      "Epoch [241/500], Average Training Loss: 0.6291\n",
      "Epoch [241/500], Average Validation Loss: 0.6290, Average Validation Accuracy: 0.7573\n",
      "Epoch [242/500], Average Training Loss: 0.6285\n",
      "Epoch [242/500], Average Validation Loss: 0.6285, Average Validation Accuracy: 0.7573\n",
      "Epoch [243/500], Average Training Loss: 0.6280\n",
      "Epoch [243/500], Average Validation Loss: 0.6279, Average Validation Accuracy: 0.7573\n",
      "Epoch [244/500], Average Training Loss: 0.6274\n",
      "Epoch [244/500], Average Validation Loss: 0.6273, Average Validation Accuracy: 0.7574\n",
      "Epoch [245/500], Average Training Loss: 0.6268\n",
      "Epoch [245/500], Average Validation Loss: 0.6267, Average Validation Accuracy: 0.7574\n",
      "Epoch [246/500], Average Training Loss: 0.6262\n",
      "Epoch [246/500], Average Validation Loss: 0.6262, Average Validation Accuracy: 0.7573\n",
      "Epoch [247/500], Average Training Loss: 0.6256\n",
      "Epoch [247/500], Average Validation Loss: 0.6256, Average Validation Accuracy: 0.7574\n",
      "Epoch [248/500], Average Training Loss: 0.6251\n",
      "Epoch [248/500], Average Validation Loss: 0.6250, Average Validation Accuracy: 0.7574\n",
      "Epoch [249/500], Average Training Loss: 0.6245\n",
      "Epoch [249/500], Average Validation Loss: 0.6244, Average Validation Accuracy: 0.7572\n",
      "Epoch [250/500], Average Training Loss: 0.6239\n",
      "Epoch [250/500], Average Validation Loss: 0.6238, Average Validation Accuracy: 0.7572\n",
      "Epoch [251/500], Average Training Loss: 0.6232\n",
      "Epoch [251/500], Average Validation Loss: 0.6232, Average Validation Accuracy: 0.7573\n",
      "Epoch [252/500], Average Training Loss: 0.6226\n",
      "Epoch [252/500], Average Validation Loss: 0.6226, Average Validation Accuracy: 0.7574\n",
      "Epoch [253/500], Average Training Loss: 0.6220\n",
      "Epoch [253/500], Average Validation Loss: 0.6220, Average Validation Accuracy: 0.7575\n",
      "Epoch [254/500], Average Training Loss: 0.6214\n",
      "Epoch [254/500], Average Validation Loss: 0.6214, Average Validation Accuracy: 0.7575\n",
      "Epoch [255/500], Average Training Loss: 0.6208\n",
      "Epoch [255/500], Average Validation Loss: 0.6208, Average Validation Accuracy: 0.7577\n",
      "Epoch [256/500], Average Training Loss: 0.6202\n",
      "Epoch [256/500], Average Validation Loss: 0.6201, Average Validation Accuracy: 0.7579\n",
      "Epoch [257/500], Average Training Loss: 0.6195\n",
      "Epoch [257/500], Average Validation Loss: 0.6195, Average Validation Accuracy: 0.7579\n",
      "Epoch [258/500], Average Training Loss: 0.6189\n",
      "Epoch [258/500], Average Validation Loss: 0.6189, Average Validation Accuracy: 0.7579\n",
      "Epoch [259/500], Average Training Loss: 0.6183\n",
      "Epoch [259/500], Average Validation Loss: 0.6183, Average Validation Accuracy: 0.7578\n",
      "Epoch [260/500], Average Training Loss: 0.6176\n",
      "Epoch [260/500], Average Validation Loss: 0.6176, Average Validation Accuracy: 0.7578\n",
      "Epoch [261/500], Average Training Loss: 0.6170\n",
      "Epoch [261/500], Average Validation Loss: 0.6170, Average Validation Accuracy: 0.7579\n",
      "Epoch [262/500], Average Training Loss: 0.6163\n",
      "Epoch [262/500], Average Validation Loss: 0.6163, Average Validation Accuracy: 0.7579\n",
      "Epoch [263/500], Average Training Loss: 0.6157\n",
      "Epoch [263/500], Average Validation Loss: 0.6157, Average Validation Accuracy: 0.7579\n",
      "Epoch [264/500], Average Training Loss: 0.6150\n",
      "Epoch [264/500], Average Validation Loss: 0.6150, Average Validation Accuracy: 0.7579\n",
      "Epoch [265/500], Average Training Loss: 0.6144\n",
      "Epoch [265/500], Average Validation Loss: 0.6144, Average Validation Accuracy: 0.7580\n",
      "Epoch [266/500], Average Training Loss: 0.6138\n",
      "Epoch [266/500], Average Validation Loss: 0.6137, Average Validation Accuracy: 0.7581\n",
      "Epoch [267/500], Average Training Loss: 0.6130\n",
      "Epoch [267/500], Average Validation Loss: 0.6131, Average Validation Accuracy: 0.7582\n",
      "Epoch [268/500], Average Training Loss: 0.6125\n",
      "Epoch [268/500], Average Validation Loss: 0.6124, Average Validation Accuracy: 0.7583\n",
      "Epoch [269/500], Average Training Loss: 0.6117\n",
      "Epoch [269/500], Average Validation Loss: 0.6118, Average Validation Accuracy: 0.7584\n",
      "Epoch [270/500], Average Training Loss: 0.6111\n",
      "Epoch [270/500], Average Validation Loss: 0.6111, Average Validation Accuracy: 0.7584\n",
      "Epoch [271/500], Average Training Loss: 0.6104\n",
      "Epoch [271/500], Average Validation Loss: 0.6104, Average Validation Accuracy: 0.7585\n",
      "Epoch [272/500], Average Training Loss: 0.6098\n",
      "Epoch [272/500], Average Validation Loss: 0.6097, Average Validation Accuracy: 0.7583\n",
      "Epoch [273/500], Average Training Loss: 0.6091\n",
      "Epoch [273/500], Average Validation Loss: 0.6091, Average Validation Accuracy: 0.7585\n",
      "Epoch [274/500], Average Training Loss: 0.6084\n",
      "Epoch [274/500], Average Validation Loss: 0.6084, Average Validation Accuracy: 0.7587\n",
      "Epoch [275/500], Average Training Loss: 0.6077\n",
      "Epoch [275/500], Average Validation Loss: 0.6077, Average Validation Accuracy: 0.7588\n",
      "Epoch [276/500], Average Training Loss: 0.6069\n",
      "Epoch [276/500], Average Validation Loss: 0.6070, Average Validation Accuracy: 0.7589\n",
      "Epoch [277/500], Average Training Loss: 0.6063\n",
      "Epoch [277/500], Average Validation Loss: 0.6063, Average Validation Accuracy: 0.7589\n",
      "Epoch [278/500], Average Training Loss: 0.6055\n",
      "Epoch [278/500], Average Validation Loss: 0.6056, Average Validation Accuracy: 0.7588\n",
      "Epoch [279/500], Average Training Loss: 0.6049\n",
      "Epoch [279/500], Average Validation Loss: 0.6049, Average Validation Accuracy: 0.7586\n",
      "Epoch [280/500], Average Training Loss: 0.6041\n",
      "Epoch [280/500], Average Validation Loss: 0.6042, Average Validation Accuracy: 0.7587\n",
      "Epoch [281/500], Average Training Loss: 0.6034\n",
      "Epoch [281/500], Average Validation Loss: 0.6035, Average Validation Accuracy: 0.7588\n",
      "Epoch [282/500], Average Training Loss: 0.6028\n",
      "Epoch [282/500], Average Validation Loss: 0.6028, Average Validation Accuracy: 0.7588\n",
      "Epoch [283/500], Average Training Loss: 0.6020\n",
      "Epoch [283/500], Average Validation Loss: 0.6021, Average Validation Accuracy: 0.7591\n",
      "Epoch [284/500], Average Training Loss: 0.6013\n",
      "Epoch [284/500], Average Validation Loss: 0.6014, Average Validation Accuracy: 0.7591\n",
      "Epoch [285/500], Average Training Loss: 0.6006\n",
      "Epoch [285/500], Average Validation Loss: 0.6006, Average Validation Accuracy: 0.7591\n",
      "Epoch [286/500], Average Training Loss: 0.5999\n",
      "Epoch [286/500], Average Validation Loss: 0.5999, Average Validation Accuracy: 0.7591\n",
      "Epoch [287/500], Average Training Loss: 0.5992\n",
      "Epoch [287/500], Average Validation Loss: 0.5992, Average Validation Accuracy: 0.7592\n",
      "Epoch [288/500], Average Training Loss: 0.5984\n",
      "Epoch [288/500], Average Validation Loss: 0.5985, Average Validation Accuracy: 0.7592\n",
      "Epoch [289/500], Average Training Loss: 0.5977\n",
      "Epoch [289/500], Average Validation Loss: 0.5977, Average Validation Accuracy: 0.7593\n",
      "Epoch [290/500], Average Training Loss: 0.5970\n",
      "Epoch [290/500], Average Validation Loss: 0.5970, Average Validation Accuracy: 0.7593\n",
      "Epoch [291/500], Average Training Loss: 0.5962\n",
      "Epoch [291/500], Average Validation Loss: 0.5963, Average Validation Accuracy: 0.7594\n",
      "Epoch [292/500], Average Training Loss: 0.5955\n",
      "Epoch [292/500], Average Validation Loss: 0.5955, Average Validation Accuracy: 0.7595\n",
      "Epoch [293/500], Average Training Loss: 0.5947\n",
      "Epoch [293/500], Average Validation Loss: 0.5948, Average Validation Accuracy: 0.7598\n",
      "Epoch [294/500], Average Training Loss: 0.5940\n",
      "Epoch [294/500], Average Validation Loss: 0.5941, Average Validation Accuracy: 0.7599\n",
      "Epoch [295/500], Average Training Loss: 0.5933\n",
      "Epoch [295/500], Average Validation Loss: 0.5933, Average Validation Accuracy: 0.7600\n",
      "Epoch [296/500], Average Training Loss: 0.5925\n",
      "Epoch [296/500], Average Validation Loss: 0.5926, Average Validation Accuracy: 0.7600\n",
      "Epoch [297/500], Average Training Loss: 0.5917\n",
      "Epoch [297/500], Average Validation Loss: 0.5918, Average Validation Accuracy: 0.7599\n",
      "Epoch [298/500], Average Training Loss: 0.5910\n",
      "Epoch [298/500], Average Validation Loss: 0.5911, Average Validation Accuracy: 0.7599\n",
      "Epoch [299/500], Average Training Loss: 0.5902\n",
      "Epoch [299/500], Average Validation Loss: 0.5903, Average Validation Accuracy: 0.7599\n",
      "Epoch [300/500], Average Training Loss: 0.5895\n",
      "Epoch [300/500], Average Validation Loss: 0.5896, Average Validation Accuracy: 0.7600\n",
      "Epoch [301/500], Average Training Loss: 0.5887\n",
      "Epoch [301/500], Average Validation Loss: 0.5888, Average Validation Accuracy: 0.7600\n",
      "Epoch [302/500], Average Training Loss: 0.5879\n",
      "Epoch [302/500], Average Validation Loss: 0.5881, Average Validation Accuracy: 0.7601\n",
      "Epoch [303/500], Average Training Loss: 0.5873\n",
      "Epoch [303/500], Average Validation Loss: 0.5873, Average Validation Accuracy: 0.7601\n",
      "Epoch [304/500], Average Training Loss: 0.5864\n",
      "Epoch [304/500], Average Validation Loss: 0.5865, Average Validation Accuracy: 0.7602\n",
      "Epoch [305/500], Average Training Loss: 0.5856\n",
      "Epoch [305/500], Average Validation Loss: 0.5858, Average Validation Accuracy: 0.7602\n",
      "Epoch [306/500], Average Training Loss: 0.5849\n",
      "Epoch [306/500], Average Validation Loss: 0.5850, Average Validation Accuracy: 0.7603\n",
      "Epoch [307/500], Average Training Loss: 0.5841\n",
      "Epoch [307/500], Average Validation Loss: 0.5843, Average Validation Accuracy: 0.7604\n",
      "Epoch [308/500], Average Training Loss: 0.5834\n",
      "Epoch [308/500], Average Validation Loss: 0.5835, Average Validation Accuracy: 0.7604\n",
      "Epoch [309/500], Average Training Loss: 0.5825\n",
      "Epoch [309/500], Average Validation Loss: 0.5827, Average Validation Accuracy: 0.7604\n",
      "Epoch [310/500], Average Training Loss: 0.5818\n",
      "Epoch [310/500], Average Validation Loss: 0.5820, Average Validation Accuracy: 0.7606\n",
      "Epoch [311/500], Average Training Loss: 0.5810\n",
      "Epoch [311/500], Average Validation Loss: 0.5812, Average Validation Accuracy: 0.7607\n",
      "Epoch [312/500], Average Training Loss: 0.5802\n",
      "Epoch [312/500], Average Validation Loss: 0.5804, Average Validation Accuracy: 0.7606\n",
      "Epoch [313/500], Average Training Loss: 0.5795\n",
      "Epoch [313/500], Average Validation Loss: 0.5796, Average Validation Accuracy: 0.7608\n",
      "Epoch [314/500], Average Training Loss: 0.5786\n",
      "Epoch [314/500], Average Validation Loss: 0.5789, Average Validation Accuracy: 0.7608\n",
      "Epoch [315/500], Average Training Loss: 0.5780\n",
      "Epoch [315/500], Average Validation Loss: 0.5781, Average Validation Accuracy: 0.7608\n",
      "Epoch [316/500], Average Training Loss: 0.5771\n",
      "Epoch [316/500], Average Validation Loss: 0.5773, Average Validation Accuracy: 0.7609\n",
      "Epoch [317/500], Average Training Loss: 0.5763\n",
      "Epoch [317/500], Average Validation Loss: 0.5766, Average Validation Accuracy: 0.7610\n",
      "Epoch [318/500], Average Training Loss: 0.5756\n",
      "Epoch [318/500], Average Validation Loss: 0.5758, Average Validation Accuracy: 0.7610\n",
      "Epoch [319/500], Average Training Loss: 0.5749\n",
      "Epoch [319/500], Average Validation Loss: 0.5750, Average Validation Accuracy: 0.7610\n",
      "Epoch [320/500], Average Training Loss: 0.5740\n",
      "Epoch [320/500], Average Validation Loss: 0.5742, Average Validation Accuracy: 0.7611\n",
      "Epoch [321/500], Average Training Loss: 0.5733\n",
      "Epoch [321/500], Average Validation Loss: 0.5735, Average Validation Accuracy: 0.7613\n",
      "Epoch [322/500], Average Training Loss: 0.5724\n",
      "Epoch [322/500], Average Validation Loss: 0.5727, Average Validation Accuracy: 0.7613\n",
      "Epoch [323/500], Average Training Loss: 0.5717\n",
      "Epoch [323/500], Average Validation Loss: 0.5719, Average Validation Accuracy: 0.7614\n",
      "Epoch [324/500], Average Training Loss: 0.5709\n",
      "Epoch [324/500], Average Validation Loss: 0.5711, Average Validation Accuracy: 0.7618\n",
      "Epoch [325/500], Average Training Loss: 0.5702\n",
      "Epoch [325/500], Average Validation Loss: 0.5704, Average Validation Accuracy: 0.7618\n",
      "Epoch [326/500], Average Training Loss: 0.5693\n",
      "Epoch [326/500], Average Validation Loss: 0.5696, Average Validation Accuracy: 0.7619\n",
      "Epoch [327/500], Average Training Loss: 0.5685\n",
      "Epoch [327/500], Average Validation Loss: 0.5688, Average Validation Accuracy: 0.7619\n",
      "Epoch [328/500], Average Training Loss: 0.5677\n",
      "Epoch [328/500], Average Validation Loss: 0.5680, Average Validation Accuracy: 0.7621\n",
      "Epoch [329/500], Average Training Loss: 0.5671\n",
      "Epoch [329/500], Average Validation Loss: 0.5673, Average Validation Accuracy: 0.7622\n",
      "Epoch [330/500], Average Training Loss: 0.5662\n",
      "Epoch [330/500], Average Validation Loss: 0.5665, Average Validation Accuracy: 0.7622\n",
      "Epoch [331/500], Average Training Loss: 0.5654\n",
      "Epoch [331/500], Average Validation Loss: 0.5657, Average Validation Accuracy: 0.7624\n",
      "Epoch [332/500], Average Training Loss: 0.5646\n",
      "Epoch [332/500], Average Validation Loss: 0.5649, Average Validation Accuracy: 0.7624\n",
      "Epoch [333/500], Average Training Loss: 0.5638\n",
      "Epoch [333/500], Average Validation Loss: 0.5642, Average Validation Accuracy: 0.7625\n",
      "Epoch [334/500], Average Training Loss: 0.5630\n",
      "Epoch [334/500], Average Validation Loss: 0.5634, Average Validation Accuracy: 0.7625\n",
      "Epoch [335/500], Average Training Loss: 0.5622\n",
      "Epoch [335/500], Average Validation Loss: 0.5626, Average Validation Accuracy: 0.7625\n",
      "Epoch [336/500], Average Training Loss: 0.5615\n",
      "Epoch [336/500], Average Validation Loss: 0.5619, Average Validation Accuracy: 0.7625\n",
      "Epoch [337/500], Average Training Loss: 0.5607\n",
      "Epoch [337/500], Average Validation Loss: 0.5611, Average Validation Accuracy: 0.7627\n",
      "Epoch [338/500], Average Training Loss: 0.5600\n",
      "Epoch [338/500], Average Validation Loss: 0.5603, Average Validation Accuracy: 0.7628\n",
      "Epoch [339/500], Average Training Loss: 0.5593\n",
      "Epoch [339/500], Average Validation Loss: 0.5596, Average Validation Accuracy: 0.7628\n",
      "Epoch [340/500], Average Training Loss: 0.5584\n",
      "Epoch [340/500], Average Validation Loss: 0.5588, Average Validation Accuracy: 0.7628\n",
      "Epoch [341/500], Average Training Loss: 0.5577\n",
      "Epoch [341/500], Average Validation Loss: 0.5581, Average Validation Accuracy: 0.7630\n",
      "Epoch [342/500], Average Training Loss: 0.5569\n",
      "Epoch [342/500], Average Validation Loss: 0.5573, Average Validation Accuracy: 0.7633\n",
      "Epoch [343/500], Average Training Loss: 0.5562\n",
      "Epoch [343/500], Average Validation Loss: 0.5565, Average Validation Accuracy: 0.7635\n",
      "Epoch [344/500], Average Training Loss: 0.5553\n",
      "Epoch [344/500], Average Validation Loss: 0.5558, Average Validation Accuracy: 0.7636\n",
      "Epoch [345/500], Average Training Loss: 0.5546\n",
      "Epoch [345/500], Average Validation Loss: 0.5550, Average Validation Accuracy: 0.7636\n",
      "Epoch [346/500], Average Training Loss: 0.5538\n",
      "Epoch [346/500], Average Validation Loss: 0.5543, Average Validation Accuracy: 0.7638\n",
      "Epoch [347/500], Average Training Loss: 0.5530\n",
      "Epoch [347/500], Average Validation Loss: 0.5535, Average Validation Accuracy: 0.7640\n",
      "Epoch [348/500], Average Training Loss: 0.5525\n",
      "Epoch [348/500], Average Validation Loss: 0.5528, Average Validation Accuracy: 0.7641\n",
      "Epoch [349/500], Average Training Loss: 0.5515\n",
      "Epoch [349/500], Average Validation Loss: 0.5520, Average Validation Accuracy: 0.7641\n",
      "Epoch [350/500], Average Training Loss: 0.5508\n",
      "Epoch [350/500], Average Validation Loss: 0.5513, Average Validation Accuracy: 0.7643\n",
      "Epoch [351/500], Average Training Loss: 0.5501\n",
      "Epoch [351/500], Average Validation Loss: 0.5506, Average Validation Accuracy: 0.7643\n",
      "Epoch [352/500], Average Training Loss: 0.5493\n",
      "Epoch [352/500], Average Validation Loss: 0.5498, Average Validation Accuracy: 0.7644\n",
      "Epoch [353/500], Average Training Loss: 0.5486\n",
      "Epoch [353/500], Average Validation Loss: 0.5491, Average Validation Accuracy: 0.7643\n",
      "Epoch [354/500], Average Training Loss: 0.5478\n",
      "Epoch [354/500], Average Validation Loss: 0.5484, Average Validation Accuracy: 0.7643\n",
      "Epoch [355/500], Average Training Loss: 0.5471\n",
      "Epoch [355/500], Average Validation Loss: 0.5476, Average Validation Accuracy: 0.7643\n",
      "Epoch [356/500], Average Training Loss: 0.5465\n",
      "Epoch [356/500], Average Validation Loss: 0.5469, Average Validation Accuracy: 0.7643\n",
      "Epoch [357/500], Average Training Loss: 0.5456\n",
      "Epoch [357/500], Average Validation Loss: 0.5462, Average Validation Accuracy: 0.7643\n",
      "Epoch [358/500], Average Training Loss: 0.5449\n",
      "Epoch [358/500], Average Validation Loss: 0.5455, Average Validation Accuracy: 0.7645\n",
      "Epoch [359/500], Average Training Loss: 0.5443\n",
      "Epoch [359/500], Average Validation Loss: 0.5447, Average Validation Accuracy: 0.7645\n",
      "Epoch [360/500], Average Training Loss: 0.5434\n",
      "Epoch [360/500], Average Validation Loss: 0.5440, Average Validation Accuracy: 0.7647\n",
      "Epoch [361/500], Average Training Loss: 0.5427\n",
      "Epoch [361/500], Average Validation Loss: 0.5433, Average Validation Accuracy: 0.7648\n",
      "Epoch [362/500], Average Training Loss: 0.5419\n",
      "Epoch [362/500], Average Validation Loss: 0.5426, Average Validation Accuracy: 0.7648\n",
      "Epoch [363/500], Average Training Loss: 0.5413\n",
      "Epoch [363/500], Average Validation Loss: 0.5419, Average Validation Accuracy: 0.7649\n",
      "Epoch [364/500], Average Training Loss: 0.5406\n",
      "Epoch [364/500], Average Validation Loss: 0.5412, Average Validation Accuracy: 0.7650\n",
      "Epoch [365/500], Average Training Loss: 0.5399\n",
      "Epoch [365/500], Average Validation Loss: 0.5405, Average Validation Accuracy: 0.7651\n",
      "Epoch [366/500], Average Training Loss: 0.5393\n",
      "Epoch [366/500], Average Validation Loss: 0.5398, Average Validation Accuracy: 0.7651\n",
      "Epoch [367/500], Average Training Loss: 0.5385\n",
      "Epoch [367/500], Average Validation Loss: 0.5391, Average Validation Accuracy: 0.7652\n",
      "Epoch [368/500], Average Training Loss: 0.5377\n",
      "Epoch [368/500], Average Validation Loss: 0.5384, Average Validation Accuracy: 0.7655\n",
      "Epoch [369/500], Average Training Loss: 0.5370\n",
      "Epoch [369/500], Average Validation Loss: 0.5378, Average Validation Accuracy: 0.7657\n",
      "Epoch [370/500], Average Training Loss: 0.5364\n",
      "Epoch [370/500], Average Validation Loss: 0.5371, Average Validation Accuracy: 0.7660\n",
      "Epoch [371/500], Average Training Loss: 0.5358\n",
      "Epoch [371/500], Average Validation Loss: 0.5364, Average Validation Accuracy: 0.7661\n",
      "Epoch [372/500], Average Training Loss: 0.5351\n",
      "Epoch [372/500], Average Validation Loss: 0.5357, Average Validation Accuracy: 0.7661\n",
      "Epoch [373/500], Average Training Loss: 0.5343\n",
      "Epoch [373/500], Average Validation Loss: 0.5351, Average Validation Accuracy: 0.7663\n",
      "Epoch [374/500], Average Training Loss: 0.5336\n",
      "Epoch [374/500], Average Validation Loss: 0.5344, Average Validation Accuracy: 0.7663\n",
      "Epoch [375/500], Average Training Loss: 0.5330\n",
      "Epoch [375/500], Average Validation Loss: 0.5337, Average Validation Accuracy: 0.7663\n",
      "Epoch [376/500], Average Training Loss: 0.5323\n",
      "Epoch [376/500], Average Validation Loss: 0.5331, Average Validation Accuracy: 0.7662\n",
      "Epoch [377/500], Average Training Loss: 0.5318\n",
      "Epoch [377/500], Average Validation Loss: 0.5324, Average Validation Accuracy: 0.7664\n",
      "Epoch [378/500], Average Training Loss: 0.5310\n",
      "Epoch [378/500], Average Validation Loss: 0.5318, Average Validation Accuracy: 0.7668\n",
      "Epoch [379/500], Average Training Loss: 0.5303\n",
      "Epoch [379/500], Average Validation Loss: 0.5311, Average Validation Accuracy: 0.7669\n",
      "Epoch [380/500], Average Training Loss: 0.5296\n",
      "Epoch [380/500], Average Validation Loss: 0.5305, Average Validation Accuracy: 0.7669\n",
      "Epoch [381/500], Average Training Loss: 0.5291\n",
      "Epoch [381/500], Average Validation Loss: 0.5298, Average Validation Accuracy: 0.7671\n",
      "Epoch [382/500], Average Training Loss: 0.5285\n",
      "Epoch [382/500], Average Validation Loss: 0.5292, Average Validation Accuracy: 0.7673\n",
      "Epoch [383/500], Average Training Loss: 0.5277\n",
      "Epoch [383/500], Average Validation Loss: 0.5286, Average Validation Accuracy: 0.7674\n",
      "Epoch [384/500], Average Training Loss: 0.5271\n",
      "Epoch [384/500], Average Validation Loss: 0.5280, Average Validation Accuracy: 0.7679\n",
      "Epoch [385/500], Average Training Loss: 0.5265\n",
      "Epoch [385/500], Average Validation Loss: 0.5273, Average Validation Accuracy: 0.7680\n",
      "Epoch [386/500], Average Training Loss: 0.5258\n",
      "Epoch [386/500], Average Validation Loss: 0.5267, Average Validation Accuracy: 0.7682\n",
      "Epoch [387/500], Average Training Loss: 0.5252\n",
      "Epoch [387/500], Average Validation Loss: 0.5261, Average Validation Accuracy: 0.7682\n",
      "Epoch [388/500], Average Training Loss: 0.5247\n",
      "Epoch [388/500], Average Validation Loss: 0.5255, Average Validation Accuracy: 0.7685\n",
      "Epoch [389/500], Average Training Loss: 0.5241\n",
      "Epoch [389/500], Average Validation Loss: 0.5249, Average Validation Accuracy: 0.7687\n",
      "Epoch [390/500], Average Training Loss: 0.5234\n",
      "Epoch [390/500], Average Validation Loss: 0.5243, Average Validation Accuracy: 0.7688\n",
      "Epoch [391/500], Average Training Loss: 0.5228\n",
      "Epoch [391/500], Average Validation Loss: 0.5237, Average Validation Accuracy: 0.7690\n",
      "Epoch [392/500], Average Training Loss: 0.5223\n",
      "Epoch [392/500], Average Validation Loss: 0.5231, Average Validation Accuracy: 0.7692\n",
      "Epoch [393/500], Average Training Loss: 0.5215\n",
      "Epoch [393/500], Average Validation Loss: 0.5225, Average Validation Accuracy: 0.7692\n",
      "Epoch [394/500], Average Training Loss: 0.5209\n",
      "Epoch [394/500], Average Validation Loss: 0.5219, Average Validation Accuracy: 0.7694\n",
      "Epoch [395/500], Average Training Loss: 0.5205\n",
      "Epoch [395/500], Average Validation Loss: 0.5214, Average Validation Accuracy: 0.7695\n",
      "Epoch [396/500], Average Training Loss: 0.5198\n",
      "Epoch [396/500], Average Validation Loss: 0.5208, Average Validation Accuracy: 0.7695\n",
      "Epoch [397/500], Average Training Loss: 0.5191\n",
      "Epoch [397/500], Average Validation Loss: 0.5202, Average Validation Accuracy: 0.7698\n",
      "Epoch [398/500], Average Training Loss: 0.5186\n",
      "Epoch [398/500], Average Validation Loss: 0.5197, Average Validation Accuracy: 0.7696\n",
      "Epoch [399/500], Average Training Loss: 0.5181\n",
      "Epoch [399/500], Average Validation Loss: 0.5191, Average Validation Accuracy: 0.7698\n",
      "Epoch [400/500], Average Training Loss: 0.5175\n",
      "Epoch [400/500], Average Validation Loss: 0.5185, Average Validation Accuracy: 0.7698\n",
      "Epoch [401/500], Average Training Loss: 0.5169\n",
      "Epoch [401/500], Average Validation Loss: 0.5180, Average Validation Accuracy: 0.7702\n",
      "Epoch [402/500], Average Training Loss: 0.5163\n",
      "Epoch [402/500], Average Validation Loss: 0.5175, Average Validation Accuracy: 0.7703\n",
      "Epoch [403/500], Average Training Loss: 0.5158\n",
      "Epoch [403/500], Average Validation Loss: 0.5169, Average Validation Accuracy: 0.7704\n",
      "Epoch [404/500], Average Training Loss: 0.5153\n",
      "Epoch [404/500], Average Validation Loss: 0.5164, Average Validation Accuracy: 0.7705\n",
      "Epoch [405/500], Average Training Loss: 0.5147\n",
      "Epoch [405/500], Average Validation Loss: 0.5158, Average Validation Accuracy: 0.7705\n",
      "Epoch [406/500], Average Training Loss: 0.5142\n",
      "Epoch [406/500], Average Validation Loss: 0.5153, Average Validation Accuracy: 0.7707\n",
      "Epoch [407/500], Average Training Loss: 0.5136\n",
      "Epoch [407/500], Average Validation Loss: 0.5148, Average Validation Accuracy: 0.7710\n",
      "Epoch [408/500], Average Training Loss: 0.5133\n",
      "Epoch [408/500], Average Validation Loss: 0.5143, Average Validation Accuracy: 0.7709\n",
      "Epoch [409/500], Average Training Loss: 0.5125\n",
      "Epoch [409/500], Average Validation Loss: 0.5137, Average Validation Accuracy: 0.7710\n",
      "Epoch [410/500], Average Training Loss: 0.5120\n",
      "Epoch [410/500], Average Validation Loss: 0.5132, Average Validation Accuracy: 0.7710\n",
      "Epoch [411/500], Average Training Loss: 0.5116\n",
      "Epoch [411/500], Average Validation Loss: 0.5127, Average Validation Accuracy: 0.7712\n",
      "Epoch [412/500], Average Training Loss: 0.5111\n",
      "Epoch [412/500], Average Validation Loss: 0.5122, Average Validation Accuracy: 0.7713\n",
      "Epoch [413/500], Average Training Loss: 0.5106\n",
      "Epoch [413/500], Average Validation Loss: 0.5117, Average Validation Accuracy: 0.7716\n",
      "Epoch [414/500], Average Training Loss: 0.5101\n",
      "Epoch [414/500], Average Validation Loss: 0.5112, Average Validation Accuracy: 0.7718\n",
      "Epoch [415/500], Average Training Loss: 0.5096\n",
      "Epoch [415/500], Average Validation Loss: 0.5107, Average Validation Accuracy: 0.7719\n",
      "Epoch [416/500], Average Training Loss: 0.5091\n",
      "Epoch [416/500], Average Validation Loss: 0.5103, Average Validation Accuracy: 0.7721\n",
      "Epoch [417/500], Average Training Loss: 0.5085\n",
      "Epoch [417/500], Average Validation Loss: 0.5098, Average Validation Accuracy: 0.7724\n",
      "Epoch [418/500], Average Training Loss: 0.5079\n",
      "Epoch [418/500], Average Validation Loss: 0.5093, Average Validation Accuracy: 0.7727\n",
      "Epoch [419/500], Average Training Loss: 0.5075\n",
      "Epoch [419/500], Average Validation Loss: 0.5088, Average Validation Accuracy: 0.7726\n",
      "Epoch [420/500], Average Training Loss: 0.5071\n",
      "Epoch [420/500], Average Validation Loss: 0.5084, Average Validation Accuracy: 0.7730\n",
      "Epoch [421/500], Average Training Loss: 0.5066\n",
      "Epoch [421/500], Average Validation Loss: 0.5079, Average Validation Accuracy: 0.7730\n",
      "Epoch [422/500], Average Training Loss: 0.5059\n",
      "Epoch [422/500], Average Validation Loss: 0.5074, Average Validation Accuracy: 0.7731\n",
      "Epoch [423/500], Average Training Loss: 0.5055\n",
      "Epoch [423/500], Average Validation Loss: 0.5070, Average Validation Accuracy: 0.7733\n",
      "Epoch [424/500], Average Training Loss: 0.5052\n",
      "Epoch [424/500], Average Validation Loss: 0.5065, Average Validation Accuracy: 0.7733\n",
      "Epoch [425/500], Average Training Loss: 0.5046\n",
      "Epoch [425/500], Average Validation Loss: 0.5061, Average Validation Accuracy: 0.7733\n",
      "Epoch [426/500], Average Training Loss: 0.5043\n",
      "Epoch [426/500], Average Validation Loss: 0.5056, Average Validation Accuracy: 0.7734\n",
      "Epoch [427/500], Average Training Loss: 0.5038\n",
      "Epoch [427/500], Average Validation Loss: 0.5052, Average Validation Accuracy: 0.7734\n",
      "Epoch [428/500], Average Training Loss: 0.5033\n",
      "Epoch [428/500], Average Validation Loss: 0.5048, Average Validation Accuracy: 0.7734\n",
      "Epoch [429/500], Average Training Loss: 0.5030\n",
      "Epoch [429/500], Average Validation Loss: 0.5043, Average Validation Accuracy: 0.7733\n",
      "Epoch [430/500], Average Training Loss: 0.5024\n",
      "Epoch [430/500], Average Validation Loss: 0.5039, Average Validation Accuracy: 0.7736\n",
      "Epoch [431/500], Average Training Loss: 0.5022\n",
      "Epoch [431/500], Average Validation Loss: 0.5035, Average Validation Accuracy: 0.7739\n",
      "Epoch [432/500], Average Training Loss: 0.5018\n",
      "Epoch [432/500], Average Validation Loss: 0.5031, Average Validation Accuracy: 0.7739\n",
      "Epoch [433/500], Average Training Loss: 0.5013\n",
      "Epoch [433/500], Average Validation Loss: 0.5027, Average Validation Accuracy: 0.7741\n",
      "Epoch [434/500], Average Training Loss: 0.5009\n",
      "Epoch [434/500], Average Validation Loss: 0.5022, Average Validation Accuracy: 0.7742\n",
      "Epoch [435/500], Average Training Loss: 0.5005\n",
      "Epoch [435/500], Average Validation Loss: 0.5018, Average Validation Accuracy: 0.7739\n",
      "Epoch [436/500], Average Training Loss: 0.4999\n",
      "Epoch [436/500], Average Validation Loss: 0.5014, Average Validation Accuracy: 0.7743\n",
      "Epoch [437/500], Average Training Loss: 0.4995\n",
      "Epoch [437/500], Average Validation Loss: 0.5010, Average Validation Accuracy: 0.7743\n",
      "Epoch [438/500], Average Training Loss: 0.4990\n",
      "Epoch [438/500], Average Validation Loss: 0.5006, Average Validation Accuracy: 0.7743\n",
      "Epoch [439/500], Average Training Loss: 0.4988\n",
      "Epoch [439/500], Average Validation Loss: 0.5003, Average Validation Accuracy: 0.7744\n",
      "Epoch [440/500], Average Training Loss: 0.4982\n",
      "Epoch [440/500], Average Validation Loss: 0.4999, Average Validation Accuracy: 0.7745\n",
      "Epoch [441/500], Average Training Loss: 0.4979\n",
      "Epoch [441/500], Average Validation Loss: 0.4995, Average Validation Accuracy: 0.7745\n",
      "Epoch [442/500], Average Training Loss: 0.4972\n",
      "Epoch [442/500], Average Validation Loss: 0.4991, Average Validation Accuracy: 0.7745\n",
      "Epoch [443/500], Average Training Loss: 0.4971\n",
      "Epoch [443/500], Average Validation Loss: 0.4987, Average Validation Accuracy: 0.7748\n",
      "Epoch [444/500], Average Training Loss: 0.4966\n",
      "Epoch [444/500], Average Validation Loss: 0.4984, Average Validation Accuracy: 0.7751\n",
      "Epoch [445/500], Average Training Loss: 0.4966\n",
      "Epoch [445/500], Average Validation Loss: 0.4980, Average Validation Accuracy: 0.7753\n",
      "Epoch [446/500], Average Training Loss: 0.4959\n",
      "Epoch [446/500], Average Validation Loss: 0.4976, Average Validation Accuracy: 0.7755\n",
      "Epoch [447/500], Average Training Loss: 0.4956\n",
      "Epoch [447/500], Average Validation Loss: 0.4973, Average Validation Accuracy: 0.7755\n",
      "Epoch [448/500], Average Training Loss: 0.4954\n",
      "Epoch [448/500], Average Validation Loss: 0.4969, Average Validation Accuracy: 0.7756\n",
      "Epoch [449/500], Average Training Loss: 0.4947\n",
      "Epoch [449/500], Average Validation Loss: 0.4965, Average Validation Accuracy: 0.7759\n",
      "Epoch [450/500], Average Training Loss: 0.4944\n",
      "Epoch [450/500], Average Validation Loss: 0.4962, Average Validation Accuracy: 0.7760\n",
      "Epoch [451/500], Average Training Loss: 0.4941\n",
      "Epoch [451/500], Average Validation Loss: 0.4958, Average Validation Accuracy: 0.7762\n",
      "Epoch [452/500], Average Training Loss: 0.4937\n",
      "Epoch [452/500], Average Validation Loss: 0.4955, Average Validation Accuracy: 0.7763\n",
      "Epoch [453/500], Average Training Loss: 0.4935\n",
      "Epoch [453/500], Average Validation Loss: 0.4952, Average Validation Accuracy: 0.7765\n",
      "Epoch [454/500], Average Training Loss: 0.4929\n",
      "Epoch [454/500], Average Validation Loss: 0.4948, Average Validation Accuracy: 0.7766\n",
      "Epoch [455/500], Average Training Loss: 0.4928\n",
      "Epoch [455/500], Average Validation Loss: 0.4945, Average Validation Accuracy: 0.7766\n",
      "Epoch [456/500], Average Training Loss: 0.4924\n",
      "Epoch [456/500], Average Validation Loss: 0.4942, Average Validation Accuracy: 0.7770\n",
      "Epoch [457/500], Average Training Loss: 0.4921\n",
      "Epoch [457/500], Average Validation Loss: 0.4938, Average Validation Accuracy: 0.7772\n",
      "Epoch [458/500], Average Training Loss: 0.4917\n",
      "Epoch [458/500], Average Validation Loss: 0.4935, Average Validation Accuracy: 0.7771\n",
      "Epoch [459/500], Average Training Loss: 0.4914\n",
      "Epoch [459/500], Average Validation Loss: 0.4932, Average Validation Accuracy: 0.7772\n",
      "Epoch [460/500], Average Training Loss: 0.4909\n",
      "Epoch [460/500], Average Validation Loss: 0.4929, Average Validation Accuracy: 0.7772\n",
      "Epoch [461/500], Average Training Loss: 0.4907\n",
      "Epoch [461/500], Average Validation Loss: 0.4926, Average Validation Accuracy: 0.7772\n",
      "Epoch [462/500], Average Training Loss: 0.4902\n",
      "Epoch [462/500], Average Validation Loss: 0.4923, Average Validation Accuracy: 0.7774\n",
      "Epoch [463/500], Average Training Loss: 0.4903\n",
      "Epoch [463/500], Average Validation Loss: 0.4919, Average Validation Accuracy: 0.7776\n",
      "Epoch [464/500], Average Training Loss: 0.4899\n",
      "Epoch [464/500], Average Validation Loss: 0.4916, Average Validation Accuracy: 0.7778\n",
      "Epoch [465/500], Average Training Loss: 0.4896\n",
      "Epoch [465/500], Average Validation Loss: 0.4913, Average Validation Accuracy: 0.7777\n",
      "Epoch [466/500], Average Training Loss: 0.4892\n",
      "Epoch [466/500], Average Validation Loss: 0.4910, Average Validation Accuracy: 0.7781\n",
      "Epoch [467/500], Average Training Loss: 0.4889\n",
      "Epoch [467/500], Average Validation Loss: 0.4908, Average Validation Accuracy: 0.7782\n",
      "Epoch [468/500], Average Training Loss: 0.4886\n",
      "Epoch [468/500], Average Validation Loss: 0.4905, Average Validation Accuracy: 0.7783\n",
      "Epoch [469/500], Average Training Loss: 0.4883\n",
      "Epoch [469/500], Average Validation Loss: 0.4902, Average Validation Accuracy: 0.7785\n",
      "Epoch [470/500], Average Training Loss: 0.4879\n",
      "Epoch [470/500], Average Validation Loss: 0.4899, Average Validation Accuracy: 0.7788\n",
      "Epoch [471/500], Average Training Loss: 0.4878\n",
      "Epoch [471/500], Average Validation Loss: 0.4896, Average Validation Accuracy: 0.7792\n",
      "Epoch [472/500], Average Training Loss: 0.4874\n",
      "Epoch [472/500], Average Validation Loss: 0.4893, Average Validation Accuracy: 0.7792\n",
      "Epoch [473/500], Average Training Loss: 0.4871\n",
      "Epoch [473/500], Average Validation Loss: 0.4890, Average Validation Accuracy: 0.7794\n",
      "Epoch [474/500], Average Training Loss: 0.4870\n",
      "Epoch [474/500], Average Validation Loss: 0.4888, Average Validation Accuracy: 0.7796\n",
      "Epoch [475/500], Average Training Loss: 0.4867\n",
      "Epoch [475/500], Average Validation Loss: 0.4885, Average Validation Accuracy: 0.7796\n",
      "Epoch [476/500], Average Training Loss: 0.4862\n",
      "Epoch [476/500], Average Validation Loss: 0.4882, Average Validation Accuracy: 0.7798\n",
      "Epoch [477/500], Average Training Loss: 0.4861\n",
      "Epoch [477/500], Average Validation Loss: 0.4880, Average Validation Accuracy: 0.7799\n",
      "Epoch [478/500], Average Training Loss: 0.4855\n",
      "Epoch [478/500], Average Validation Loss: 0.4877, Average Validation Accuracy: 0.7801\n",
      "Epoch [479/500], Average Training Loss: 0.4853\n",
      "Epoch [479/500], Average Validation Loss: 0.4874, Average Validation Accuracy: 0.7801\n",
      "Epoch [480/500], Average Training Loss: 0.4850\n",
      "Epoch [480/500], Average Validation Loss: 0.4872, Average Validation Accuracy: 0.7800\n",
      "Epoch [481/500], Average Training Loss: 0.4849\n",
      "Epoch [481/500], Average Validation Loss: 0.4869, Average Validation Accuracy: 0.7802\n",
      "Epoch [482/500], Average Training Loss: 0.4844\n",
      "Epoch [482/500], Average Validation Loss: 0.4867, Average Validation Accuracy: 0.7804\n",
      "Epoch [483/500], Average Training Loss: 0.4842\n",
      "Epoch [483/500], Average Validation Loss: 0.4864, Average Validation Accuracy: 0.7805\n",
      "Epoch [484/500], Average Training Loss: 0.4840\n",
      "Epoch [484/500], Average Validation Loss: 0.4862, Average Validation Accuracy: 0.7803\n",
      "Epoch [485/500], Average Training Loss: 0.4838\n",
      "Epoch [485/500], Average Validation Loss: 0.4859, Average Validation Accuracy: 0.7803\n",
      "Epoch [486/500], Average Training Loss: 0.4836\n",
      "Epoch [486/500], Average Validation Loss: 0.4857, Average Validation Accuracy: 0.7804\n",
      "Epoch [487/500], Average Training Loss: 0.4834\n",
      "Epoch [487/500], Average Validation Loss: 0.4855, Average Validation Accuracy: 0.7804\n",
      "Epoch [488/500], Average Training Loss: 0.4831\n",
      "Epoch [488/500], Average Validation Loss: 0.4852, Average Validation Accuracy: 0.7804\n",
      "Epoch [489/500], Average Training Loss: 0.4829\n",
      "Epoch [489/500], Average Validation Loss: 0.4850, Average Validation Accuracy: 0.7806\n",
      "Epoch [490/500], Average Training Loss: 0.4826\n",
      "Epoch [490/500], Average Validation Loss: 0.4848, Average Validation Accuracy: 0.7806\n",
      "Epoch [491/500], Average Training Loss: 0.4824\n",
      "Epoch [491/500], Average Validation Loss: 0.4845, Average Validation Accuracy: 0.7808\n",
      "Epoch [492/500], Average Training Loss: 0.4820\n",
      "Epoch [492/500], Average Validation Loss: 0.4843, Average Validation Accuracy: 0.7809\n",
      "Epoch [493/500], Average Training Loss: 0.4820\n",
      "Epoch [493/500], Average Validation Loss: 0.4841, Average Validation Accuracy: 0.7809\n",
      "Epoch [494/500], Average Training Loss: 0.4816\n",
      "Epoch [494/500], Average Validation Loss: 0.4839, Average Validation Accuracy: 0.7811\n",
      "Epoch [495/500], Average Training Loss: 0.4811\n",
      "Epoch [495/500], Average Validation Loss: 0.4836, Average Validation Accuracy: 0.7811\n",
      "Epoch [496/500], Average Training Loss: 0.4811\n",
      "Epoch [496/500], Average Validation Loss: 0.4834, Average Validation Accuracy: 0.7812\n",
      "Epoch [497/500], Average Training Loss: 0.4811\n",
      "Epoch [497/500], Average Validation Loss: 0.4832, Average Validation Accuracy: 0.7814\n",
      "Epoch [498/500], Average Training Loss: 0.4808\n",
      "Epoch [498/500], Average Validation Loss: 0.4830, Average Validation Accuracy: 0.7814\n",
      "Epoch [499/500], Average Training Loss: 0.4804\n",
      "Epoch [499/500], Average Validation Loss: 0.4828, Average Validation Accuracy: 0.7816\n",
      "Epoch [500/500], Average Training Loss: 0.4804\n",
      "Epoch [500/500], Average Validation Loss: 0.4826, Average Validation Accuracy: 0.7820\n",
      "Best Validation Accuracy: 0.7820 at epoch 500 for trial 1\n",
      "Epoch [1/50], Average Training Loss: 0.5291\n",
      "Epoch [1/50], Average Validation Loss: 0.4530, Average Validation Accuracy: 0.7958\n",
      "Epoch [2/50], Average Training Loss: 0.4443\n",
      "Epoch [2/50], Average Validation Loss: 0.4434, Average Validation Accuracy: 0.8028\n",
      "Epoch [3/50], Average Training Loss: 0.4376\n",
      "Epoch [3/50], Average Validation Loss: 0.4386, Average Validation Accuracy: 0.8058\n",
      "Epoch [4/50], Average Training Loss: 0.4339\n",
      "Epoch [4/50], Average Validation Loss: 0.4358, Average Validation Accuracy: 0.8082\n",
      "Epoch [5/50], Average Training Loss: 0.4320\n",
      "Epoch [5/50], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8095\n",
      "Epoch [6/50], Average Training Loss: 0.4307\n",
      "Epoch [6/50], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8114\n",
      "Epoch [7/50], Average Training Loss: 0.4301\n",
      "Epoch [7/50], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8109\n",
      "Epoch [8/50], Average Training Loss: 0.4296\n",
      "Epoch [8/50], Average Validation Loss: 0.4324, Average Validation Accuracy: 0.8114\n",
      "Epoch [9/50], Average Training Loss: 0.4293\n",
      "Epoch [9/50], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8116\n",
      "Epoch [10/50], Average Training Loss: 0.4290\n",
      "Epoch [10/50], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8122\n",
      "Epoch [11/50], Average Training Loss: 0.4284\n",
      "Epoch [11/50], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8124\n",
      "Epoch [12/50], Average Training Loss: 0.4280\n",
      "Epoch [12/50], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8104\n",
      "Epoch [13/50], Average Training Loss: 0.4277\n",
      "Epoch [13/50], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8118\n",
      "Epoch [14/50], Average Training Loss: 0.4273\n",
      "Epoch [14/50], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8123\n",
      "Epoch [15/50], Average Training Loss: 0.4266\n",
      "Epoch [15/50], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8130\n",
      "Epoch [16/50], Average Training Loss: 0.4262\n",
      "Epoch [16/50], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8126\n",
      "Epoch [17/50], Average Training Loss: 0.4257\n",
      "Epoch [17/50], Average Validation Loss: 0.4284, Average Validation Accuracy: 0.8122\n",
      "Epoch [18/50], Average Training Loss: 0.4253\n",
      "Epoch [18/50], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8136\n",
      "Epoch [19/50], Average Training Loss: 0.4248\n",
      "Epoch [19/50], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8134\n",
      "Epoch [20/50], Average Training Loss: 0.4241\n",
      "Epoch [20/50], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8119\n",
      "Epoch [21/50], Average Training Loss: 0.4237\n",
      "Epoch [21/50], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8119\n",
      "Epoch [22/50], Average Training Loss: 0.4229\n",
      "Epoch [22/50], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8125\n",
      "Epoch [23/50], Average Training Loss: 0.4223\n",
      "Epoch [23/50], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8138\n",
      "Epoch [24/50], Average Training Loss: 0.4218\n",
      "Epoch [24/50], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8132\n",
      "Epoch [25/50], Average Training Loss: 0.4212\n",
      "Epoch [25/50], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8134\n",
      "Epoch [26/50], Average Training Loss: 0.4207\n",
      "Epoch [26/50], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8127\n",
      "Epoch [27/50], Average Training Loss: 0.4202\n",
      "Epoch [27/50], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8136\n",
      "Epoch [28/50], Average Training Loss: 0.4202\n",
      "Epoch [28/50], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8133\n",
      "Epoch [29/50], Average Training Loss: 0.4196\n",
      "Epoch [29/50], Average Validation Loss: 0.4230, Average Validation Accuracy: 0.8141\n",
      "Epoch [30/50], Average Training Loss: 0.4194\n",
      "Epoch [30/50], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8135\n",
      "Epoch [31/50], Average Training Loss: 0.4191\n",
      "Epoch [31/50], Average Validation Loss: 0.4230, Average Validation Accuracy: 0.8143\n",
      "Epoch [32/50], Average Training Loss: 0.4188\n",
      "Epoch [32/50], Average Validation Loss: 0.4224, Average Validation Accuracy: 0.8141\n",
      "Epoch [33/50], Average Training Loss: 0.4184\n",
      "Epoch [33/50], Average Validation Loss: 0.4225, Average Validation Accuracy: 0.8142\n",
      "Epoch [34/50], Average Training Loss: 0.4182\n",
      "Epoch [34/50], Average Validation Loss: 0.4220, Average Validation Accuracy: 0.8145\n",
      "Epoch [35/50], Average Training Loss: 0.4177\n",
      "Epoch [35/50], Average Validation Loss: 0.4220, Average Validation Accuracy: 0.8144\n",
      "Epoch [36/50], Average Training Loss: 0.4176\n",
      "Epoch [36/50], Average Validation Loss: 0.4214, Average Validation Accuracy: 0.8139\n",
      "Epoch [37/50], Average Training Loss: 0.4173\n",
      "Epoch [37/50], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8146\n",
      "Epoch [38/50], Average Training Loss: 0.4170\n",
      "Epoch [38/50], Average Validation Loss: 0.4213, Average Validation Accuracy: 0.8148\n",
      "Epoch [39/50], Average Training Loss: 0.4168\n",
      "Epoch [39/50], Average Validation Loss: 0.4208, Average Validation Accuracy: 0.8141\n",
      "Epoch [40/50], Average Training Loss: 0.4165\n",
      "Epoch [40/50], Average Validation Loss: 0.4205, Average Validation Accuracy: 0.8149\n",
      "Epoch [41/50], Average Training Loss: 0.4161\n",
      "Epoch [41/50], Average Validation Loss: 0.4200, Average Validation Accuracy: 0.8155\n",
      "Epoch [42/50], Average Training Loss: 0.4159\n",
      "Epoch [42/50], Average Validation Loss: 0.4197, Average Validation Accuracy: 0.8159\n",
      "Epoch [43/50], Average Training Loss: 0.4158\n",
      "Epoch [43/50], Average Validation Loss: 0.4193, Average Validation Accuracy: 0.8161\n",
      "Epoch [44/50], Average Training Loss: 0.4151\n",
      "Epoch [44/50], Average Validation Loss: 0.4190, Average Validation Accuracy: 0.8156\n",
      "Epoch [45/50], Average Training Loss: 0.4151\n",
      "Epoch [45/50], Average Validation Loss: 0.4188, Average Validation Accuracy: 0.8153\n",
      "Epoch [46/50], Average Training Loss: 0.4149\n",
      "Epoch [46/50], Average Validation Loss: 0.4185, Average Validation Accuracy: 0.8166\n",
      "Epoch [47/50], Average Training Loss: 0.4146\n",
      "Epoch [47/50], Average Validation Loss: 0.4185, Average Validation Accuracy: 0.8165\n",
      "Epoch [48/50], Average Training Loss: 0.4143\n",
      "Epoch [48/50], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8166\n",
      "Epoch [49/50], Average Training Loss: 0.4141\n",
      "Epoch [49/50], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8172\n",
      "Epoch [50/50], Average Training Loss: 0.4140\n",
      "Epoch [50/50], Average Validation Loss: 0.4173, Average Validation Accuracy: 0.8177\n",
      "Best Validation Accuracy: 0.8177 at epoch 50 for trial 2\n",
      "Epoch [1/50], Average Training Loss: 0.4485\n",
      "Epoch [1/50], Average Validation Loss: 0.4481, Average Validation Accuracy: 0.7994\n",
      "Epoch [2/50], Average Training Loss: 0.4317\n",
      "Epoch [2/50], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8113\n",
      "Epoch [3/50], Average Training Loss: 0.4268\n",
      "Epoch [3/50], Average Validation Loss: 0.4525, Average Validation Accuracy: 0.7948\n",
      "Epoch [4/50], Average Training Loss: 0.4238\n",
      "Epoch [4/50], Average Validation Loss: 0.4385, Average Validation Accuracy: 0.8040\n",
      "Epoch [5/50], Average Training Loss: 0.4213\n",
      "Epoch [5/50], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8104\n",
      "Epoch [6/50], Average Training Loss: 0.4186\n",
      "Epoch [6/50], Average Validation Loss: 0.4429, Average Validation Accuracy: 0.8031\n",
      "Epoch [7/50], Average Training Loss: 0.4166\n",
      "Epoch [7/50], Average Validation Loss: 0.4189, Average Validation Accuracy: 0.8180\n",
      "Epoch [8/50], Average Training Loss: 0.4154\n",
      "Epoch [8/50], Average Validation Loss: 0.4184, Average Validation Accuracy: 0.8165\n",
      "Epoch [9/50], Average Training Loss: 0.4138\n",
      "Epoch [9/50], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8115\n",
      "Epoch [10/50], Average Training Loss: 0.4136\n",
      "Epoch [10/50], Average Validation Loss: 0.4178, Average Validation Accuracy: 0.8162\n",
      "Epoch [11/50], Average Training Loss: 0.4122\n",
      "Epoch [11/50], Average Validation Loss: 0.4158, Average Validation Accuracy: 0.8196\n",
      "Epoch [12/50], Average Training Loss: 0.4114\n",
      "Epoch [12/50], Average Validation Loss: 0.4157, Average Validation Accuracy: 0.8181\n",
      "Epoch [13/50], Average Training Loss: 0.4105\n",
      "Epoch [13/50], Average Validation Loss: 0.4139, Average Validation Accuracy: 0.8196\n",
      "Epoch [14/50], Average Training Loss: 0.4101\n",
      "Epoch [14/50], Average Validation Loss: 0.4206, Average Validation Accuracy: 0.8149\n",
      "Epoch [15/50], Average Training Loss: 0.4093\n",
      "Epoch [15/50], Average Validation Loss: 0.4157, Average Validation Accuracy: 0.8155\n",
      "Epoch [16/50], Average Training Loss: 0.4089\n",
      "Epoch [16/50], Average Validation Loss: 0.4124, Average Validation Accuracy: 0.8213\n",
      "Epoch [17/50], Average Training Loss: 0.4089\n",
      "Epoch [17/50], Average Validation Loss: 0.4188, Average Validation Accuracy: 0.8137\n",
      "Epoch [18/50], Average Training Loss: 0.4076\n",
      "Epoch [18/50], Average Validation Loss: 0.4140, Average Validation Accuracy: 0.8200\n",
      "Epoch [19/50], Average Training Loss: 0.4074\n",
      "Epoch [19/50], Average Validation Loss: 0.4180, Average Validation Accuracy: 0.8167\n",
      "Epoch [20/50], Average Training Loss: 0.4066\n",
      "Epoch [20/50], Average Validation Loss: 0.4113, Average Validation Accuracy: 0.8205\n",
      "Epoch [21/50], Average Training Loss: 0.4063\n",
      "Epoch [21/50], Average Validation Loss: 0.4131, Average Validation Accuracy: 0.8192\n",
      "Epoch [22/50], Average Training Loss: 0.4057\n",
      "Epoch [22/50], Average Validation Loss: 0.4164, Average Validation Accuracy: 0.8168\n",
      "Epoch [23/50], Average Training Loss: 0.4050\n",
      "Epoch [23/50], Average Validation Loss: 0.4100, Average Validation Accuracy: 0.8224\n",
      "Epoch [24/50], Average Training Loss: 0.4043\n",
      "Epoch [24/50], Average Validation Loss: 0.4108, Average Validation Accuracy: 0.8223\n",
      "Epoch [25/50], Average Training Loss: 0.4038\n",
      "Epoch [25/50], Average Validation Loss: 0.4099, Average Validation Accuracy: 0.8191\n",
      "Epoch [26/50], Average Training Loss: 0.4033\n",
      "Epoch [26/50], Average Validation Loss: 0.4132, Average Validation Accuracy: 0.8198\n",
      "Epoch [27/50], Average Training Loss: 0.4032\n",
      "Epoch [27/50], Average Validation Loss: 0.4087, Average Validation Accuracy: 0.8216\n",
      "Epoch [28/50], Average Training Loss: 0.4026\n",
      "Epoch [28/50], Average Validation Loss: 0.4093, Average Validation Accuracy: 0.8225\n",
      "Epoch [29/50], Average Training Loss: 0.4024\n",
      "Epoch [29/50], Average Validation Loss: 0.4062, Average Validation Accuracy: 0.8232\n",
      "Epoch [30/50], Average Training Loss: 0.4018\n",
      "Epoch [30/50], Average Validation Loss: 0.4129, Average Validation Accuracy: 0.8183\n",
      "Epoch [31/50], Average Training Loss: 0.4013\n",
      "Epoch [31/50], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8238\n",
      "Epoch [32/50], Average Training Loss: 0.4012\n",
      "Epoch [32/50], Average Validation Loss: 0.4126, Average Validation Accuracy: 0.8187\n",
      "Epoch [33/50], Average Training Loss: 0.4005\n",
      "Epoch [33/50], Average Validation Loss: 0.4136, Average Validation Accuracy: 0.8176\n",
      "Epoch [34/50], Average Training Loss: 0.4006\n",
      "Epoch [34/50], Average Validation Loss: 0.4062, Average Validation Accuracy: 0.8243\n",
      "Epoch [35/50], Average Training Loss: 0.3997\n",
      "Epoch [35/50], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8233\n",
      "Epoch [36/50], Average Training Loss: 0.3998\n",
      "Epoch [36/50], Average Validation Loss: 0.4064, Average Validation Accuracy: 0.8244\n",
      "Epoch [37/50], Average Training Loss: 0.3996\n",
      "Epoch [37/50], Average Validation Loss: 0.4102, Average Validation Accuracy: 0.8212\n",
      "Epoch [38/50], Average Training Loss: 0.3994\n",
      "Epoch [38/50], Average Validation Loss: 0.4121, Average Validation Accuracy: 0.8175\n",
      "Epoch [39/50], Average Training Loss: 0.3990\n",
      "Epoch [39/50], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8229\n",
      "Epoch [40/50], Average Training Loss: 0.3990\n",
      "Epoch [40/50], Average Validation Loss: 0.4072, Average Validation Accuracy: 0.8212\n",
      "Epoch [41/50], Average Training Loss: 0.3987\n",
      "Epoch [41/50], Average Validation Loss: 0.4047, Average Validation Accuracy: 0.8239\n",
      "Epoch [42/50], Average Training Loss: 0.3979\n",
      "Epoch [42/50], Average Validation Loss: 0.4050, Average Validation Accuracy: 0.8236\n",
      "Epoch [43/50], Average Training Loss: 0.3977\n",
      "Epoch [43/50], Average Validation Loss: 0.4087, Average Validation Accuracy: 0.8246\n",
      "Epoch [44/50], Average Training Loss: 0.3976\n",
      "Epoch [44/50], Average Validation Loss: 0.4076, Average Validation Accuracy: 0.8229\n",
      "Epoch [45/50], Average Training Loss: 0.3969\n",
      "Epoch [45/50], Average Validation Loss: 0.4100, Average Validation Accuracy: 0.8216\n",
      "Epoch [46/50], Average Training Loss: 0.3971\n",
      "Epoch [46/50], Average Validation Loss: 0.4060, Average Validation Accuracy: 0.8243\n",
      "Epoch [47/50], Average Training Loss: 0.3972\n",
      "Epoch [47/50], Average Validation Loss: 0.4064, Average Validation Accuracy: 0.8238\n",
      "Epoch [48/50], Average Training Loss: 0.3961\n",
      "Epoch [48/50], Average Validation Loss: 0.4107, Average Validation Accuracy: 0.8245\n",
      "Epoch [49/50], Average Training Loss: 0.3963\n",
      "Epoch [49/50], Average Validation Loss: 0.4121, Average Validation Accuracy: 0.8218\n",
      "Epoch [50/50], Average Training Loss: 0.3958\n",
      "Epoch [50/50], Average Validation Loss: 0.4058, Average Validation Accuracy: 0.8247\n",
      "Best Validation Accuracy: 0.8247 at epoch 50 for trial 3\n",
      "Epoch [1/500], Average Training Loss: 0.6992\n",
      "Epoch [1/500], Average Validation Loss: 0.6986, Average Validation Accuracy: 0.4954\n",
      "Epoch [2/500], Average Training Loss: 0.6963\n",
      "Epoch [2/500], Average Validation Loss: 0.6958, Average Validation Accuracy: 0.4954\n",
      "Epoch [3/500], Average Training Loss: 0.6938\n",
      "Epoch [3/500], Average Validation Loss: 0.6934, Average Validation Accuracy: 0.4954\n",
      "Epoch [4/500], Average Training Loss: 0.6916\n",
      "Epoch [4/500], Average Validation Loss: 0.6911, Average Validation Accuracy: 0.4955\n",
      "Epoch [5/500], Average Training Loss: 0.6895\n",
      "Epoch [5/500], Average Validation Loss: 0.6890, Average Validation Accuracy: 0.4977\n",
      "Epoch [6/500], Average Training Loss: 0.6875\n",
      "Epoch [6/500], Average Validation Loss: 0.6870, Average Validation Accuracy: 0.5065\n",
      "Epoch [7/500], Average Training Loss: 0.6856\n",
      "Epoch [7/500], Average Validation Loss: 0.6850, Average Validation Accuracy: 0.5288\n",
      "Epoch [8/500], Average Training Loss: 0.6837\n",
      "Epoch [8/500], Average Validation Loss: 0.6830, Average Validation Accuracy: 0.5707\n",
      "Epoch [9/500], Average Training Loss: 0.6817\n",
      "Epoch [9/500], Average Validation Loss: 0.6809, Average Validation Accuracy: 0.6172\n",
      "Epoch [10/500], Average Training Loss: 0.6797\n",
      "Epoch [10/500], Average Validation Loss: 0.6788, Average Validation Accuracy: 0.6616\n",
      "Epoch [11/500], Average Training Loss: 0.6776\n",
      "Epoch [11/500], Average Validation Loss: 0.6766, Average Validation Accuracy: 0.6894\n",
      "Epoch [12/500], Average Training Loss: 0.6754\n",
      "Epoch [12/500], Average Validation Loss: 0.6743, Average Validation Accuracy: 0.7086\n",
      "Epoch [13/500], Average Training Loss: 0.6730\n",
      "Epoch [13/500], Average Validation Loss: 0.6719, Average Validation Accuracy: 0.7207\n",
      "Epoch [14/500], Average Training Loss: 0.6705\n",
      "Epoch [14/500], Average Validation Loss: 0.6693, Average Validation Accuracy: 0.7278\n",
      "Epoch [15/500], Average Training Loss: 0.6679\n",
      "Epoch [15/500], Average Validation Loss: 0.6665, Average Validation Accuracy: 0.7338\n",
      "Epoch [16/500], Average Training Loss: 0.6650\n",
      "Epoch [16/500], Average Validation Loss: 0.6635, Average Validation Accuracy: 0.7377\n",
      "Epoch [17/500], Average Training Loss: 0.6619\n",
      "Epoch [17/500], Average Validation Loss: 0.6602, Average Validation Accuracy: 0.7419\n",
      "Epoch [18/500], Average Training Loss: 0.6585\n",
      "Epoch [18/500], Average Validation Loss: 0.6567, Average Validation Accuracy: 0.7452\n",
      "Epoch [19/500], Average Training Loss: 0.6549\n",
      "Epoch [19/500], Average Validation Loss: 0.6529, Average Validation Accuracy: 0.7469\n",
      "Epoch [20/500], Average Training Loss: 0.6509\n",
      "Epoch [20/500], Average Validation Loss: 0.6487, Average Validation Accuracy: 0.7503\n",
      "Epoch [21/500], Average Training Loss: 0.6466\n",
      "Epoch [21/500], Average Validation Loss: 0.6442, Average Validation Accuracy: 0.7527\n",
      "Epoch [22/500], Average Training Loss: 0.6420\n",
      "Epoch [22/500], Average Validation Loss: 0.6394, Average Validation Accuracy: 0.7544\n",
      "Epoch [23/500], Average Training Loss: 0.6369\n",
      "Epoch [23/500], Average Validation Loss: 0.6341, Average Validation Accuracy: 0.7564\n",
      "Epoch [24/500], Average Training Loss: 0.6314\n",
      "Epoch [24/500], Average Validation Loss: 0.6284, Average Validation Accuracy: 0.7579\n",
      "Epoch [25/500], Average Training Loss: 0.6255\n",
      "Epoch [25/500], Average Validation Loss: 0.6223, Average Validation Accuracy: 0.7590\n",
      "Epoch [26/500], Average Training Loss: 0.6191\n",
      "Epoch [26/500], Average Validation Loss: 0.6157, Average Validation Accuracy: 0.7598\n",
      "Epoch [27/500], Average Training Loss: 0.6124\n",
      "Epoch [27/500], Average Validation Loss: 0.6087, Average Validation Accuracy: 0.7613\n",
      "Epoch [28/500], Average Training Loss: 0.6052\n",
      "Epoch [28/500], Average Validation Loss: 0.6013, Average Validation Accuracy: 0.7622\n",
      "Epoch [29/500], Average Training Loss: 0.5976\n",
      "Epoch [29/500], Average Validation Loss: 0.5935, Average Validation Accuracy: 0.7634\n",
      "Epoch [30/500], Average Training Loss: 0.5896\n",
      "Epoch [30/500], Average Validation Loss: 0.5854, Average Validation Accuracy: 0.7642\n",
      "Epoch [31/500], Average Training Loss: 0.5813\n",
      "Epoch [31/500], Average Validation Loss: 0.5770, Average Validation Accuracy: 0.7651\n",
      "Epoch [32/500], Average Training Loss: 0.5729\n",
      "Epoch [32/500], Average Validation Loss: 0.5685, Average Validation Accuracy: 0.7666\n",
      "Epoch [33/500], Average Training Loss: 0.5644\n",
      "Epoch [33/500], Average Validation Loss: 0.5600, Average Validation Accuracy: 0.7682\n",
      "Epoch [34/500], Average Training Loss: 0.5559\n",
      "Epoch [34/500], Average Validation Loss: 0.5516, Average Validation Accuracy: 0.7689\n",
      "Epoch [35/500], Average Training Loss: 0.5474\n",
      "Epoch [35/500], Average Validation Loss: 0.5433, Average Validation Accuracy: 0.7704\n",
      "Epoch [36/500], Average Training Loss: 0.5393\n",
      "Epoch [36/500], Average Validation Loss: 0.5353, Average Validation Accuracy: 0.7716\n",
      "Epoch [37/500], Average Training Loss: 0.5313\n",
      "Epoch [37/500], Average Validation Loss: 0.5277, Average Validation Accuracy: 0.7729\n",
      "Epoch [38/500], Average Training Loss: 0.5239\n",
      "Epoch [38/500], Average Validation Loss: 0.5205, Average Validation Accuracy: 0.7746\n",
      "Epoch [39/500], Average Training Loss: 0.5169\n",
      "Epoch [39/500], Average Validation Loss: 0.5138, Average Validation Accuracy: 0.7756\n",
      "Epoch [40/500], Average Training Loss: 0.5103\n",
      "Epoch [40/500], Average Validation Loss: 0.5076, Average Validation Accuracy: 0.7775\n",
      "Epoch [41/500], Average Training Loss: 0.5044\n",
      "Epoch [41/500], Average Validation Loss: 0.5020, Average Validation Accuracy: 0.7786\n",
      "Epoch [42/500], Average Training Loss: 0.4989\n",
      "Epoch [42/500], Average Validation Loss: 0.4968, Average Validation Accuracy: 0.7805\n",
      "Epoch [43/500], Average Training Loss: 0.4940\n",
      "Epoch [43/500], Average Validation Loss: 0.4922, Average Validation Accuracy: 0.7822\n",
      "Epoch [44/500], Average Training Loss: 0.4895\n",
      "Epoch [44/500], Average Validation Loss: 0.4881, Average Validation Accuracy: 0.7826\n",
      "Epoch [45/500], Average Training Loss: 0.4856\n",
      "Epoch [45/500], Average Validation Loss: 0.4844, Average Validation Accuracy: 0.7836\n",
      "Epoch [46/500], Average Training Loss: 0.4817\n",
      "Epoch [46/500], Average Validation Loss: 0.4810, Average Validation Accuracy: 0.7853\n",
      "Epoch [47/500], Average Training Loss: 0.4785\n",
      "Epoch [47/500], Average Validation Loss: 0.4781, Average Validation Accuracy: 0.7859\n",
      "Epoch [48/500], Average Training Loss: 0.4757\n",
      "Epoch [48/500], Average Validation Loss: 0.4755, Average Validation Accuracy: 0.7872\n",
      "Epoch [49/500], Average Training Loss: 0.4733\n",
      "Epoch [49/500], Average Validation Loss: 0.4732, Average Validation Accuracy: 0.7880\n",
      "Epoch [50/500], Average Training Loss: 0.4707\n",
      "Epoch [50/500], Average Validation Loss: 0.4712, Average Validation Accuracy: 0.7886\n",
      "Epoch [51/500], Average Training Loss: 0.4688\n",
      "Epoch [51/500], Average Validation Loss: 0.4693, Average Validation Accuracy: 0.7899\n",
      "Epoch [52/500], Average Training Loss: 0.4671\n",
      "Epoch [52/500], Average Validation Loss: 0.4677, Average Validation Accuracy: 0.7912\n",
      "Epoch [53/500], Average Training Loss: 0.4655\n",
      "Epoch [53/500], Average Validation Loss: 0.4663, Average Validation Accuracy: 0.7920\n",
      "Epoch [54/500], Average Training Loss: 0.4641\n",
      "Epoch [54/500], Average Validation Loss: 0.4650, Average Validation Accuracy: 0.7923\n",
      "Epoch [55/500], Average Training Loss: 0.4630\n",
      "Epoch [55/500], Average Validation Loss: 0.4639, Average Validation Accuracy: 0.7930\n",
      "Epoch [56/500], Average Training Loss: 0.4615\n",
      "Epoch [56/500], Average Validation Loss: 0.4629, Average Validation Accuracy: 0.7925\n",
      "Epoch [57/500], Average Training Loss: 0.4605\n",
      "Epoch [57/500], Average Validation Loss: 0.4620, Average Validation Accuracy: 0.7929\n",
      "Epoch [58/500], Average Training Loss: 0.4597\n",
      "Epoch [58/500], Average Validation Loss: 0.4612, Average Validation Accuracy: 0.7931\n",
      "Epoch [59/500], Average Training Loss: 0.4586\n",
      "Epoch [59/500], Average Validation Loss: 0.4605, Average Validation Accuracy: 0.7936\n",
      "Epoch [60/500], Average Training Loss: 0.4578\n",
      "Epoch [60/500], Average Validation Loss: 0.4598, Average Validation Accuracy: 0.7945\n",
      "Epoch [61/500], Average Training Loss: 0.4573\n",
      "Epoch [61/500], Average Validation Loss: 0.4592, Average Validation Accuracy: 0.7945\n",
      "Epoch [62/500], Average Training Loss: 0.4565\n",
      "Epoch [62/500], Average Validation Loss: 0.4586, Average Validation Accuracy: 0.7947\n",
      "Epoch [63/500], Average Training Loss: 0.4560\n",
      "Epoch [63/500], Average Validation Loss: 0.4582, Average Validation Accuracy: 0.7946\n",
      "Epoch [64/500], Average Training Loss: 0.4556\n",
      "Epoch [64/500], Average Validation Loss: 0.4577, Average Validation Accuracy: 0.7946\n",
      "Epoch [65/500], Average Training Loss: 0.4553\n",
      "Epoch [65/500], Average Validation Loss: 0.4573, Average Validation Accuracy: 0.7944\n",
      "Epoch [66/500], Average Training Loss: 0.4546\n",
      "Epoch [66/500], Average Validation Loss: 0.4569, Average Validation Accuracy: 0.7943\n",
      "Epoch [67/500], Average Training Loss: 0.4540\n",
      "Epoch [67/500], Average Validation Loss: 0.4565, Average Validation Accuracy: 0.7944\n",
      "Epoch [68/500], Average Training Loss: 0.4537\n",
      "Epoch [68/500], Average Validation Loss: 0.4561, Average Validation Accuracy: 0.7947\n",
      "Epoch [69/500], Average Training Loss: 0.4531\n",
      "Epoch [69/500], Average Validation Loss: 0.4558, Average Validation Accuracy: 0.7946\n",
      "Epoch [70/500], Average Training Loss: 0.4528\n",
      "Epoch [70/500], Average Validation Loss: 0.4555, Average Validation Accuracy: 0.7950\n",
      "Epoch [71/500], Average Training Loss: 0.4524\n",
      "Epoch [71/500], Average Validation Loss: 0.4552, Average Validation Accuracy: 0.7951\n",
      "Epoch [72/500], Average Training Loss: 0.4523\n",
      "Epoch [72/500], Average Validation Loss: 0.4549, Average Validation Accuracy: 0.7949\n",
      "Epoch [73/500], Average Training Loss: 0.4520\n",
      "Epoch [73/500], Average Validation Loss: 0.4547, Average Validation Accuracy: 0.7947\n",
      "Epoch [74/500], Average Training Loss: 0.4513\n",
      "Epoch [74/500], Average Validation Loss: 0.4544, Average Validation Accuracy: 0.7950\n",
      "Epoch [75/500], Average Training Loss: 0.4515\n",
      "Epoch [75/500], Average Validation Loss: 0.4542, Average Validation Accuracy: 0.7951\n",
      "Epoch [76/500], Average Training Loss: 0.4511\n",
      "Epoch [76/500], Average Validation Loss: 0.4540, Average Validation Accuracy: 0.7950\n",
      "Epoch [77/500], Average Training Loss: 0.4508\n",
      "Epoch [77/500], Average Validation Loss: 0.4537, Average Validation Accuracy: 0.7951\n",
      "Epoch [78/500], Average Training Loss: 0.4504\n",
      "Epoch [78/500], Average Validation Loss: 0.4535, Average Validation Accuracy: 0.7953\n",
      "Epoch [79/500], Average Training Loss: 0.4506\n",
      "Epoch [79/500], Average Validation Loss: 0.4533, Average Validation Accuracy: 0.7956\n",
      "Epoch [80/500], Average Training Loss: 0.4501\n",
      "Epoch [80/500], Average Validation Loss: 0.4531, Average Validation Accuracy: 0.7959\n",
      "Epoch [81/500], Average Training Loss: 0.4499\n",
      "Epoch [81/500], Average Validation Loss: 0.4529, Average Validation Accuracy: 0.7964\n",
      "Epoch [82/500], Average Training Loss: 0.4497\n",
      "Epoch [82/500], Average Validation Loss: 0.4527, Average Validation Accuracy: 0.7964\n",
      "Epoch [83/500], Average Training Loss: 0.4492\n",
      "Epoch [83/500], Average Validation Loss: 0.4525, Average Validation Accuracy: 0.7966\n",
      "Epoch [84/500], Average Training Loss: 0.4489\n",
      "Epoch [84/500], Average Validation Loss: 0.4523, Average Validation Accuracy: 0.7966\n",
      "Epoch [85/500], Average Training Loss: 0.4488\n",
      "Epoch [85/500], Average Validation Loss: 0.4522, Average Validation Accuracy: 0.7970\n",
      "Epoch [86/500], Average Training Loss: 0.4486\n",
      "Epoch [86/500], Average Validation Loss: 0.4520, Average Validation Accuracy: 0.7973\n",
      "Epoch [87/500], Average Training Loss: 0.4481\n",
      "Epoch [87/500], Average Validation Loss: 0.4518, Average Validation Accuracy: 0.7969\n",
      "Epoch [88/500], Average Training Loss: 0.4481\n",
      "Epoch [88/500], Average Validation Loss: 0.4516, Average Validation Accuracy: 0.7976\n",
      "Epoch [89/500], Average Training Loss: 0.4483\n",
      "Epoch [89/500], Average Validation Loss: 0.4515, Average Validation Accuracy: 0.7976\n",
      "Epoch [90/500], Average Training Loss: 0.4478\n",
      "Epoch [90/500], Average Validation Loss: 0.4513, Average Validation Accuracy: 0.7974\n",
      "Epoch [91/500], Average Training Loss: 0.4475\n",
      "Epoch [91/500], Average Validation Loss: 0.4512, Average Validation Accuracy: 0.7973\n",
      "Epoch [92/500], Average Training Loss: 0.4475\n",
      "Epoch [92/500], Average Validation Loss: 0.4510, Average Validation Accuracy: 0.7974\n",
      "Epoch [93/500], Average Training Loss: 0.4474\n",
      "Epoch [93/500], Average Validation Loss: 0.4509, Average Validation Accuracy: 0.7975\n",
      "Epoch [94/500], Average Training Loss: 0.4471\n",
      "Epoch [94/500], Average Validation Loss: 0.4507, Average Validation Accuracy: 0.7976\n",
      "Epoch [95/500], Average Training Loss: 0.4472\n",
      "Epoch [95/500], Average Validation Loss: 0.4506, Average Validation Accuracy: 0.7977\n",
      "Epoch [96/500], Average Training Loss: 0.4469\n",
      "Epoch [96/500], Average Validation Loss: 0.4504, Average Validation Accuracy: 0.7978\n",
      "Epoch [97/500], Average Training Loss: 0.4467\n",
      "Epoch [97/500], Average Validation Loss: 0.4503, Average Validation Accuracy: 0.7981\n",
      "Epoch [98/500], Average Training Loss: 0.4466\n",
      "Epoch [98/500], Average Validation Loss: 0.4501, Average Validation Accuracy: 0.7982\n",
      "Epoch [99/500], Average Training Loss: 0.4464\n",
      "Epoch [99/500], Average Validation Loss: 0.4500, Average Validation Accuracy: 0.7984\n",
      "Epoch [100/500], Average Training Loss: 0.4463\n",
      "Epoch [100/500], Average Validation Loss: 0.4499, Average Validation Accuracy: 0.7985\n",
      "Epoch [101/500], Average Training Loss: 0.4461\n",
      "Epoch [101/500], Average Validation Loss: 0.4497, Average Validation Accuracy: 0.7988\n",
      "Epoch [102/500], Average Training Loss: 0.4461\n",
      "Epoch [102/500], Average Validation Loss: 0.4496, Average Validation Accuracy: 0.7990\n",
      "Epoch [103/500], Average Training Loss: 0.4460\n",
      "Epoch [103/500], Average Validation Loss: 0.4495, Average Validation Accuracy: 0.7987\n",
      "Epoch [104/500], Average Training Loss: 0.4460\n",
      "Epoch [104/500], Average Validation Loss: 0.4493, Average Validation Accuracy: 0.7987\n",
      "Epoch [105/500], Average Training Loss: 0.4455\n",
      "Epoch [105/500], Average Validation Loss: 0.4492, Average Validation Accuracy: 0.7991\n",
      "Epoch [106/500], Average Training Loss: 0.4454\n",
      "Epoch [106/500], Average Validation Loss: 0.4491, Average Validation Accuracy: 0.7992\n",
      "Epoch [107/500], Average Training Loss: 0.4454\n",
      "Epoch [107/500], Average Validation Loss: 0.4489, Average Validation Accuracy: 0.7990\n",
      "Epoch [108/500], Average Training Loss: 0.4451\n",
      "Epoch [108/500], Average Validation Loss: 0.4488, Average Validation Accuracy: 0.7989\n",
      "Epoch [109/500], Average Training Loss: 0.4453\n",
      "Epoch [109/500], Average Validation Loss: 0.4487, Average Validation Accuracy: 0.7992\n",
      "Epoch [110/500], Average Training Loss: 0.4451\n",
      "Epoch [110/500], Average Validation Loss: 0.4486, Average Validation Accuracy: 0.7987\n",
      "Epoch [111/500], Average Training Loss: 0.4446\n",
      "Epoch [111/500], Average Validation Loss: 0.4485, Average Validation Accuracy: 0.7986\n",
      "Epoch [112/500], Average Training Loss: 0.4447\n",
      "Epoch [112/500], Average Validation Loss: 0.4483, Average Validation Accuracy: 0.7992\n",
      "Epoch [113/500], Average Training Loss: 0.4445\n",
      "Epoch [113/500], Average Validation Loss: 0.4482, Average Validation Accuracy: 0.7992\n",
      "Epoch [114/500], Average Training Loss: 0.4442\n",
      "Epoch [114/500], Average Validation Loss: 0.4481, Average Validation Accuracy: 0.7994\n",
      "Epoch [115/500], Average Training Loss: 0.4441\n",
      "Epoch [115/500], Average Validation Loss: 0.4480, Average Validation Accuracy: 0.7995\n",
      "Epoch [116/500], Average Training Loss: 0.4442\n",
      "Epoch [116/500], Average Validation Loss: 0.4479, Average Validation Accuracy: 0.7995\n",
      "Epoch [117/500], Average Training Loss: 0.4438\n",
      "Epoch [117/500], Average Validation Loss: 0.4477, Average Validation Accuracy: 0.7997\n",
      "Epoch [118/500], Average Training Loss: 0.4437\n",
      "Epoch [118/500], Average Validation Loss: 0.4476, Average Validation Accuracy: 0.7997\n",
      "Epoch [119/500], Average Training Loss: 0.4435\n",
      "Epoch [119/500], Average Validation Loss: 0.4475, Average Validation Accuracy: 0.8000\n",
      "Epoch [120/500], Average Training Loss: 0.4435\n",
      "Epoch [120/500], Average Validation Loss: 0.4474, Average Validation Accuracy: 0.7997\n",
      "Epoch [121/500], Average Training Loss: 0.4437\n",
      "Epoch [121/500], Average Validation Loss: 0.4473, Average Validation Accuracy: 0.7997\n",
      "Epoch [122/500], Average Training Loss: 0.4431\n",
      "Epoch [122/500], Average Validation Loss: 0.4472, Average Validation Accuracy: 0.7996\n",
      "Epoch [123/500], Average Training Loss: 0.4432\n",
      "Epoch [123/500], Average Validation Loss: 0.4471, Average Validation Accuracy: 0.7999\n",
      "Epoch [124/500], Average Training Loss: 0.4431\n",
      "Epoch [124/500], Average Validation Loss: 0.4470, Average Validation Accuracy: 0.8000\n",
      "Epoch [125/500], Average Training Loss: 0.4429\n",
      "Epoch [125/500], Average Validation Loss: 0.4468, Average Validation Accuracy: 0.7998\n",
      "Epoch [126/500], Average Training Loss: 0.4430\n",
      "Epoch [126/500], Average Validation Loss: 0.4467, Average Validation Accuracy: 0.8004\n",
      "Epoch [127/500], Average Training Loss: 0.4427\n",
      "Epoch [127/500], Average Validation Loss: 0.4466, Average Validation Accuracy: 0.8003\n",
      "Epoch [128/500], Average Training Loss: 0.4427\n",
      "Epoch [128/500], Average Validation Loss: 0.4465, Average Validation Accuracy: 0.8003\n",
      "Epoch [129/500], Average Training Loss: 0.4426\n",
      "Epoch [129/500], Average Validation Loss: 0.4464, Average Validation Accuracy: 0.8002\n",
      "Epoch [130/500], Average Training Loss: 0.4425\n",
      "Epoch [130/500], Average Validation Loss: 0.4463, Average Validation Accuracy: 0.8004\n",
      "Epoch [131/500], Average Training Loss: 0.4426\n",
      "Epoch [131/500], Average Validation Loss: 0.4462, Average Validation Accuracy: 0.8008\n",
      "Epoch [132/500], Average Training Loss: 0.4421\n",
      "Epoch [132/500], Average Validation Loss: 0.4461, Average Validation Accuracy: 0.8010\n",
      "Epoch [133/500], Average Training Loss: 0.4420\n",
      "Epoch [133/500], Average Validation Loss: 0.4460, Average Validation Accuracy: 0.8010\n",
      "Epoch [134/500], Average Training Loss: 0.4419\n",
      "Epoch [134/500], Average Validation Loss: 0.4459, Average Validation Accuracy: 0.8013\n",
      "Epoch [135/500], Average Training Loss: 0.4419\n",
      "Epoch [135/500], Average Validation Loss: 0.4458, Average Validation Accuracy: 0.8012\n",
      "Epoch [136/500], Average Training Loss: 0.4419\n",
      "Epoch [136/500], Average Validation Loss: 0.4457, Average Validation Accuracy: 0.8014\n",
      "Epoch [137/500], Average Training Loss: 0.4418\n",
      "Epoch [137/500], Average Validation Loss: 0.4456, Average Validation Accuracy: 0.8013\n",
      "Epoch [138/500], Average Training Loss: 0.4415\n",
      "Epoch [138/500], Average Validation Loss: 0.4455, Average Validation Accuracy: 0.8013\n",
      "Epoch [139/500], Average Training Loss: 0.4414\n",
      "Epoch [139/500], Average Validation Loss: 0.4454, Average Validation Accuracy: 0.8014\n",
      "Epoch [140/500], Average Training Loss: 0.4414\n",
      "Epoch [140/500], Average Validation Loss: 0.4453, Average Validation Accuracy: 0.8014\n",
      "Epoch [141/500], Average Training Loss: 0.4413\n",
      "Epoch [141/500], Average Validation Loss: 0.4452, Average Validation Accuracy: 0.8012\n",
      "Epoch [142/500], Average Training Loss: 0.4415\n",
      "Epoch [142/500], Average Validation Loss: 0.4451, Average Validation Accuracy: 0.8014\n",
      "Epoch [143/500], Average Training Loss: 0.4410\n",
      "Epoch [143/500], Average Validation Loss: 0.4450, Average Validation Accuracy: 0.8015\n",
      "Epoch [144/500], Average Training Loss: 0.4411\n",
      "Epoch [144/500], Average Validation Loss: 0.4449, Average Validation Accuracy: 0.8016\n",
      "Epoch [145/500], Average Training Loss: 0.4410\n",
      "Epoch [145/500], Average Validation Loss: 0.4448, Average Validation Accuracy: 0.8016\n",
      "Epoch [146/500], Average Training Loss: 0.4412\n",
      "Epoch [146/500], Average Validation Loss: 0.4447, Average Validation Accuracy: 0.8016\n",
      "Epoch [147/500], Average Training Loss: 0.4410\n",
      "Epoch [147/500], Average Validation Loss: 0.4446, Average Validation Accuracy: 0.8019\n",
      "Epoch [148/500], Average Training Loss: 0.4408\n",
      "Epoch [148/500], Average Validation Loss: 0.4446, Average Validation Accuracy: 0.8016\n",
      "Epoch [149/500], Average Training Loss: 0.4404\n",
      "Epoch [149/500], Average Validation Loss: 0.4445, Average Validation Accuracy: 0.8020\n",
      "Epoch [150/500], Average Training Loss: 0.4403\n",
      "Epoch [150/500], Average Validation Loss: 0.4444, Average Validation Accuracy: 0.8020\n",
      "Epoch [151/500], Average Training Loss: 0.4404\n",
      "Epoch [151/500], Average Validation Loss: 0.4443, Average Validation Accuracy: 0.8021\n",
      "Epoch [152/500], Average Training Loss: 0.4401\n",
      "Epoch [152/500], Average Validation Loss: 0.4442, Average Validation Accuracy: 0.8021\n",
      "Epoch [153/500], Average Training Loss: 0.4404\n",
      "Epoch [153/500], Average Validation Loss: 0.4441, Average Validation Accuracy: 0.8021\n",
      "Epoch [154/500], Average Training Loss: 0.4401\n",
      "Epoch [154/500], Average Validation Loss: 0.4440, Average Validation Accuracy: 0.8022\n",
      "Epoch [155/500], Average Training Loss: 0.4400\n",
      "Epoch [155/500], Average Validation Loss: 0.4439, Average Validation Accuracy: 0.8023\n",
      "Epoch [156/500], Average Training Loss: 0.4400\n",
      "Epoch [156/500], Average Validation Loss: 0.4438, Average Validation Accuracy: 0.8023\n",
      "Epoch [157/500], Average Training Loss: 0.4398\n",
      "Epoch [157/500], Average Validation Loss: 0.4438, Average Validation Accuracy: 0.8024\n",
      "Epoch [158/500], Average Training Loss: 0.4401\n",
      "Epoch [158/500], Average Validation Loss: 0.4437, Average Validation Accuracy: 0.8026\n",
      "Epoch [159/500], Average Training Loss: 0.4400\n",
      "Epoch [159/500], Average Validation Loss: 0.4436, Average Validation Accuracy: 0.8026\n",
      "Epoch [160/500], Average Training Loss: 0.4397\n",
      "Epoch [160/500], Average Validation Loss: 0.4435, Average Validation Accuracy: 0.8025\n",
      "Epoch [161/500], Average Training Loss: 0.4394\n",
      "Epoch [161/500], Average Validation Loss: 0.4434, Average Validation Accuracy: 0.8027\n",
      "Epoch [162/500], Average Training Loss: 0.4394\n",
      "Epoch [162/500], Average Validation Loss: 0.4433, Average Validation Accuracy: 0.8028\n",
      "Epoch [163/500], Average Training Loss: 0.4397\n",
      "Epoch [163/500], Average Validation Loss: 0.4432, Average Validation Accuracy: 0.8028\n",
      "Epoch [164/500], Average Training Loss: 0.4393\n",
      "Epoch [164/500], Average Validation Loss: 0.4432, Average Validation Accuracy: 0.8030\n",
      "Epoch [165/500], Average Training Loss: 0.4392\n",
      "Epoch [165/500], Average Validation Loss: 0.4431, Average Validation Accuracy: 0.8031\n",
      "Epoch [166/500], Average Training Loss: 0.4391\n",
      "Epoch [166/500], Average Validation Loss: 0.4430, Average Validation Accuracy: 0.8031\n",
      "Epoch [167/500], Average Training Loss: 0.4390\n",
      "Epoch [167/500], Average Validation Loss: 0.4429, Average Validation Accuracy: 0.8031\n",
      "Epoch [168/500], Average Training Loss: 0.4391\n",
      "Epoch [168/500], Average Validation Loss: 0.4428, Average Validation Accuracy: 0.8034\n",
      "Epoch [169/500], Average Training Loss: 0.4390\n",
      "Epoch [169/500], Average Validation Loss: 0.4428, Average Validation Accuracy: 0.8033\n",
      "Epoch [170/500], Average Training Loss: 0.4388\n",
      "Epoch [170/500], Average Validation Loss: 0.4427, Average Validation Accuracy: 0.8033\n",
      "Epoch [171/500], Average Training Loss: 0.4392\n",
      "Epoch [171/500], Average Validation Loss: 0.4426, Average Validation Accuracy: 0.8034\n",
      "Epoch [172/500], Average Training Loss: 0.4386\n",
      "Epoch [172/500], Average Validation Loss: 0.4425, Average Validation Accuracy: 0.8033\n",
      "Epoch [173/500], Average Training Loss: 0.4385\n",
      "Epoch [173/500], Average Validation Loss: 0.4424, Average Validation Accuracy: 0.8033\n",
      "Epoch [174/500], Average Training Loss: 0.4387\n",
      "Epoch [174/500], Average Validation Loss: 0.4424, Average Validation Accuracy: 0.8037\n",
      "Epoch [175/500], Average Training Loss: 0.4386\n",
      "Epoch [175/500], Average Validation Loss: 0.4423, Average Validation Accuracy: 0.8034\n",
      "Epoch [176/500], Average Training Loss: 0.4383\n",
      "Epoch [176/500], Average Validation Loss: 0.4422, Average Validation Accuracy: 0.8035\n",
      "Epoch [177/500], Average Training Loss: 0.4384\n",
      "Epoch [177/500], Average Validation Loss: 0.4422, Average Validation Accuracy: 0.8036\n",
      "Epoch [178/500], Average Training Loss: 0.4383\n",
      "Epoch [178/500], Average Validation Loss: 0.4421, Average Validation Accuracy: 0.8037\n",
      "Epoch [179/500], Average Training Loss: 0.4383\n",
      "Epoch [179/500], Average Validation Loss: 0.4420, Average Validation Accuracy: 0.8035\n",
      "Epoch [180/500], Average Training Loss: 0.4382\n",
      "Epoch [180/500], Average Validation Loss: 0.4419, Average Validation Accuracy: 0.8035\n",
      "Epoch [181/500], Average Training Loss: 0.4380\n",
      "Epoch [181/500], Average Validation Loss: 0.4419, Average Validation Accuracy: 0.8037\n",
      "Epoch [182/500], Average Training Loss: 0.4380\n",
      "Epoch [182/500], Average Validation Loss: 0.4418, Average Validation Accuracy: 0.8037\n",
      "Epoch [183/500], Average Training Loss: 0.4382\n",
      "Epoch [183/500], Average Validation Loss: 0.4417, Average Validation Accuracy: 0.8036\n",
      "Epoch [184/500], Average Training Loss: 0.4378\n",
      "Epoch [184/500], Average Validation Loss: 0.4416, Average Validation Accuracy: 0.8038\n",
      "Epoch [185/500], Average Training Loss: 0.4380\n",
      "Epoch [185/500], Average Validation Loss: 0.4416, Average Validation Accuracy: 0.8037\n",
      "Epoch [186/500], Average Training Loss: 0.4377\n",
      "Epoch [186/500], Average Validation Loss: 0.4415, Average Validation Accuracy: 0.8039\n",
      "Epoch [187/500], Average Training Loss: 0.4377\n",
      "Epoch [187/500], Average Validation Loss: 0.4414, Average Validation Accuracy: 0.8037\n",
      "Epoch [188/500], Average Training Loss: 0.4376\n",
      "Epoch [188/500], Average Validation Loss: 0.4413, Average Validation Accuracy: 0.8038\n",
      "Epoch [189/500], Average Training Loss: 0.4373\n",
      "Epoch [189/500], Average Validation Loss: 0.4413, Average Validation Accuracy: 0.8036\n",
      "Epoch [190/500], Average Training Loss: 0.4374\n",
      "Epoch [190/500], Average Validation Loss: 0.4412, Average Validation Accuracy: 0.8040\n",
      "Epoch [191/500], Average Training Loss: 0.4373\n",
      "Epoch [191/500], Average Validation Loss: 0.4411, Average Validation Accuracy: 0.8039\n",
      "Epoch [192/500], Average Training Loss: 0.4373\n",
      "Epoch [192/500], Average Validation Loss: 0.4411, Average Validation Accuracy: 0.8038\n",
      "Epoch [193/500], Average Training Loss: 0.4371\n",
      "Epoch [193/500], Average Validation Loss: 0.4410, Average Validation Accuracy: 0.8042\n",
      "Epoch [194/500], Average Training Loss: 0.4372\n",
      "Epoch [194/500], Average Validation Loss: 0.4409, Average Validation Accuracy: 0.8040\n",
      "Epoch [195/500], Average Training Loss: 0.4369\n",
      "Epoch [195/500], Average Validation Loss: 0.4409, Average Validation Accuracy: 0.8039\n",
      "Epoch [196/500], Average Training Loss: 0.4369\n",
      "Epoch [196/500], Average Validation Loss: 0.4408, Average Validation Accuracy: 0.8039\n",
      "Epoch [197/500], Average Training Loss: 0.4371\n",
      "Epoch [197/500], Average Validation Loss: 0.4407, Average Validation Accuracy: 0.8041\n",
      "Epoch [198/500], Average Training Loss: 0.4368\n",
      "Epoch [198/500], Average Validation Loss: 0.4407, Average Validation Accuracy: 0.8045\n",
      "Epoch [199/500], Average Training Loss: 0.4367\n",
      "Epoch [199/500], Average Validation Loss: 0.4406, Average Validation Accuracy: 0.8038\n",
      "Epoch [200/500], Average Training Loss: 0.4367\n",
      "Epoch [200/500], Average Validation Loss: 0.4405, Average Validation Accuracy: 0.8041\n",
      "Epoch [201/500], Average Training Loss: 0.4365\n",
      "Epoch [201/500], Average Validation Loss: 0.4405, Average Validation Accuracy: 0.8045\n",
      "Epoch [202/500], Average Training Loss: 0.4366\n",
      "Epoch [202/500], Average Validation Loss: 0.4404, Average Validation Accuracy: 0.8046\n",
      "Epoch [203/500], Average Training Loss: 0.4368\n",
      "Epoch [203/500], Average Validation Loss: 0.4403, Average Validation Accuracy: 0.8047\n",
      "Epoch [204/500], Average Training Loss: 0.4367\n",
      "Epoch [204/500], Average Validation Loss: 0.4403, Average Validation Accuracy: 0.8037\n",
      "Epoch [205/500], Average Training Loss: 0.4365\n",
      "Epoch [205/500], Average Validation Loss: 0.4402, Average Validation Accuracy: 0.8044\n",
      "Epoch [206/500], Average Training Loss: 0.4363\n",
      "Epoch [206/500], Average Validation Loss: 0.4402, Average Validation Accuracy: 0.8043\n",
      "Epoch [207/500], Average Training Loss: 0.4361\n",
      "Epoch [207/500], Average Validation Loss: 0.4401, Average Validation Accuracy: 0.8044\n",
      "Epoch [208/500], Average Training Loss: 0.4365\n",
      "Epoch [208/500], Average Validation Loss: 0.4400, Average Validation Accuracy: 0.8043\n",
      "Epoch [209/500], Average Training Loss: 0.4360\n",
      "Epoch [209/500], Average Validation Loss: 0.4400, Average Validation Accuracy: 0.8047\n",
      "Epoch [210/500], Average Training Loss: 0.4360\n",
      "Epoch [210/500], Average Validation Loss: 0.4399, Average Validation Accuracy: 0.8046\n",
      "Epoch [211/500], Average Training Loss: 0.4361\n",
      "Epoch [211/500], Average Validation Loss: 0.4399, Average Validation Accuracy: 0.8053\n",
      "Epoch [212/500], Average Training Loss: 0.4362\n",
      "Epoch [212/500], Average Validation Loss: 0.4398, Average Validation Accuracy: 0.8048\n",
      "Epoch [213/500], Average Training Loss: 0.4359\n",
      "Epoch [213/500], Average Validation Loss: 0.4398, Average Validation Accuracy: 0.8044\n",
      "Epoch [214/500], Average Training Loss: 0.4361\n",
      "Epoch [214/500], Average Validation Loss: 0.4397, Average Validation Accuracy: 0.8052\n",
      "Epoch [215/500], Average Training Loss: 0.4359\n",
      "Epoch [215/500], Average Validation Loss: 0.4396, Average Validation Accuracy: 0.8046\n",
      "Epoch [216/500], Average Training Loss: 0.4361\n",
      "Epoch [216/500], Average Validation Loss: 0.4396, Average Validation Accuracy: 0.8046\n",
      "Epoch [217/500], Average Training Loss: 0.4359\n",
      "Epoch [217/500], Average Validation Loss: 0.4395, Average Validation Accuracy: 0.8049\n",
      "Epoch [218/500], Average Training Loss: 0.4354\n",
      "Epoch [218/500], Average Validation Loss: 0.4395, Average Validation Accuracy: 0.8045\n",
      "Epoch [219/500], Average Training Loss: 0.4354\n",
      "Epoch [219/500], Average Validation Loss: 0.4394, Average Validation Accuracy: 0.8051\n",
      "Epoch [220/500], Average Training Loss: 0.4355\n",
      "Epoch [220/500], Average Validation Loss: 0.4393, Average Validation Accuracy: 0.8052\n",
      "Epoch [221/500], Average Training Loss: 0.4355\n",
      "Epoch [221/500], Average Validation Loss: 0.4393, Average Validation Accuracy: 0.8052\n",
      "Epoch [222/500], Average Training Loss: 0.4356\n",
      "Epoch [222/500], Average Validation Loss: 0.4392, Average Validation Accuracy: 0.8053\n",
      "Epoch [223/500], Average Training Loss: 0.4356\n",
      "Epoch [223/500], Average Validation Loss: 0.4392, Average Validation Accuracy: 0.8051\n",
      "Epoch [224/500], Average Training Loss: 0.4354\n",
      "Epoch [224/500], Average Validation Loss: 0.4391, Average Validation Accuracy: 0.8055\n",
      "Epoch [225/500], Average Training Loss: 0.4353\n",
      "Epoch [225/500], Average Validation Loss: 0.4391, Average Validation Accuracy: 0.8054\n",
      "Epoch [226/500], Average Training Loss: 0.4355\n",
      "Epoch [226/500], Average Validation Loss: 0.4390, Average Validation Accuracy: 0.8052\n",
      "Epoch [227/500], Average Training Loss: 0.4354\n",
      "Epoch [227/500], Average Validation Loss: 0.4390, Average Validation Accuracy: 0.8057\n",
      "Epoch [228/500], Average Training Loss: 0.4351\n",
      "Epoch [228/500], Average Validation Loss: 0.4389, Average Validation Accuracy: 0.8053\n",
      "Epoch [229/500], Average Training Loss: 0.4352\n",
      "Epoch [229/500], Average Validation Loss: 0.4389, Average Validation Accuracy: 0.8054\n",
      "Epoch [230/500], Average Training Loss: 0.4351\n",
      "Epoch [230/500], Average Validation Loss: 0.4388, Average Validation Accuracy: 0.8054\n",
      "Epoch [231/500], Average Training Loss: 0.4349\n",
      "Epoch [231/500], Average Validation Loss: 0.4388, Average Validation Accuracy: 0.8054\n",
      "Epoch [232/500], Average Training Loss: 0.4348\n",
      "Epoch [232/500], Average Validation Loss: 0.4387, Average Validation Accuracy: 0.8053\n",
      "Epoch [233/500], Average Training Loss: 0.4347\n",
      "Epoch [233/500], Average Validation Loss: 0.4387, Average Validation Accuracy: 0.8054\n",
      "Epoch [234/500], Average Training Loss: 0.4351\n",
      "Epoch [234/500], Average Validation Loss: 0.4386, Average Validation Accuracy: 0.8053\n",
      "Epoch [235/500], Average Training Loss: 0.4350\n",
      "Epoch [235/500], Average Validation Loss: 0.4386, Average Validation Accuracy: 0.8056\n",
      "Epoch [236/500], Average Training Loss: 0.4347\n",
      "Epoch [236/500], Average Validation Loss: 0.4385, Average Validation Accuracy: 0.8054\n",
      "Epoch [237/500], Average Training Loss: 0.4349\n",
      "Epoch [237/500], Average Validation Loss: 0.4385, Average Validation Accuracy: 0.8054\n",
      "Epoch [238/500], Average Training Loss: 0.4347\n",
      "Epoch [238/500], Average Validation Loss: 0.4384, Average Validation Accuracy: 0.8056\n",
      "Epoch [239/500], Average Training Loss: 0.4346\n",
      "Epoch [239/500], Average Validation Loss: 0.4384, Average Validation Accuracy: 0.8057\n",
      "Epoch [240/500], Average Training Loss: 0.4347\n",
      "Epoch [240/500], Average Validation Loss: 0.4383, Average Validation Accuracy: 0.8055\n",
      "Epoch [241/500], Average Training Loss: 0.4344\n",
      "Epoch [241/500], Average Validation Loss: 0.4383, Average Validation Accuracy: 0.8057\n",
      "Epoch [242/500], Average Training Loss: 0.4343\n",
      "Epoch [242/500], Average Validation Loss: 0.4382, Average Validation Accuracy: 0.8056\n",
      "Epoch [243/500], Average Training Loss: 0.4345\n",
      "Epoch [243/500], Average Validation Loss: 0.4382, Average Validation Accuracy: 0.8058\n",
      "Epoch [244/500], Average Training Loss: 0.4343\n",
      "Epoch [244/500], Average Validation Loss: 0.4381, Average Validation Accuracy: 0.8060\n",
      "Epoch [245/500], Average Training Loss: 0.4344\n",
      "Epoch [245/500], Average Validation Loss: 0.4381, Average Validation Accuracy: 0.8059\n",
      "Epoch [246/500], Average Training Loss: 0.4345\n",
      "Epoch [246/500], Average Validation Loss: 0.4381, Average Validation Accuracy: 0.8053\n",
      "Epoch [247/500], Average Training Loss: 0.4343\n",
      "Epoch [247/500], Average Validation Loss: 0.4380, Average Validation Accuracy: 0.8054\n",
      "Epoch [248/500], Average Training Loss: 0.4343\n",
      "Epoch [248/500], Average Validation Loss: 0.4379, Average Validation Accuracy: 0.8058\n",
      "Epoch [249/500], Average Training Loss: 0.4342\n",
      "Epoch [249/500], Average Validation Loss: 0.4379, Average Validation Accuracy: 0.8061\n",
      "Epoch [250/500], Average Training Loss: 0.4342\n",
      "Epoch [250/500], Average Validation Loss: 0.4379, Average Validation Accuracy: 0.8054\n",
      "Epoch [251/500], Average Training Loss: 0.4340\n",
      "Epoch [251/500], Average Validation Loss: 0.4378, Average Validation Accuracy: 0.8060\n",
      "Epoch [252/500], Average Training Loss: 0.4342\n",
      "Epoch [252/500], Average Validation Loss: 0.4378, Average Validation Accuracy: 0.8057\n",
      "Epoch [253/500], Average Training Loss: 0.4341\n",
      "Epoch [253/500], Average Validation Loss: 0.4377, Average Validation Accuracy: 0.8056\n",
      "Epoch [254/500], Average Training Loss: 0.4340\n",
      "Epoch [254/500], Average Validation Loss: 0.4377, Average Validation Accuracy: 0.8060\n",
      "Epoch [255/500], Average Training Loss: 0.4339\n",
      "Epoch [255/500], Average Validation Loss: 0.4376, Average Validation Accuracy: 0.8061\n",
      "Epoch [256/500], Average Training Loss: 0.4339\n",
      "Epoch [256/500], Average Validation Loss: 0.4376, Average Validation Accuracy: 0.8059\n",
      "Epoch [257/500], Average Training Loss: 0.4338\n",
      "Epoch [257/500], Average Validation Loss: 0.4375, Average Validation Accuracy: 0.8061\n",
      "Epoch [258/500], Average Training Loss: 0.4335\n",
      "Epoch [258/500], Average Validation Loss: 0.4375, Average Validation Accuracy: 0.8062\n",
      "Epoch [259/500], Average Training Loss: 0.4338\n",
      "Epoch [259/500], Average Validation Loss: 0.4375, Average Validation Accuracy: 0.8062\n",
      "Epoch [260/500], Average Training Loss: 0.4336\n",
      "Epoch [260/500], Average Validation Loss: 0.4375, Average Validation Accuracy: 0.8064\n",
      "Epoch [261/500], Average Training Loss: 0.4336\n",
      "Epoch [261/500], Average Validation Loss: 0.4374, Average Validation Accuracy: 0.8063\n",
      "Epoch [262/500], Average Training Loss: 0.4337\n",
      "Epoch [262/500], Average Validation Loss: 0.4373, Average Validation Accuracy: 0.8059\n",
      "Epoch [263/500], Average Training Loss: 0.4336\n",
      "Epoch [263/500], Average Validation Loss: 0.4373, Average Validation Accuracy: 0.8063\n",
      "Epoch [264/500], Average Training Loss: 0.4335\n",
      "Epoch [264/500], Average Validation Loss: 0.4373, Average Validation Accuracy: 0.8061\n",
      "Epoch [265/500], Average Training Loss: 0.4333\n",
      "Epoch [265/500], Average Validation Loss: 0.4372, Average Validation Accuracy: 0.8066\n",
      "Epoch [266/500], Average Training Loss: 0.4334\n",
      "Epoch [266/500], Average Validation Loss: 0.4372, Average Validation Accuracy: 0.8062\n",
      "Epoch [267/500], Average Training Loss: 0.4334\n",
      "Epoch [267/500], Average Validation Loss: 0.4371, Average Validation Accuracy: 0.8065\n",
      "Epoch [268/500], Average Training Loss: 0.4335\n",
      "Epoch [268/500], Average Validation Loss: 0.4371, Average Validation Accuracy: 0.8060\n",
      "Epoch [269/500], Average Training Loss: 0.4332\n",
      "Epoch [269/500], Average Validation Loss: 0.4371, Average Validation Accuracy: 0.8065\n",
      "Epoch [270/500], Average Training Loss: 0.4333\n",
      "Epoch [270/500], Average Validation Loss: 0.4370, Average Validation Accuracy: 0.8065\n",
      "Epoch [271/500], Average Training Loss: 0.4332\n",
      "Epoch [271/500], Average Validation Loss: 0.4370, Average Validation Accuracy: 0.8066\n",
      "Epoch [272/500], Average Training Loss: 0.4332\n",
      "Epoch [272/500], Average Validation Loss: 0.4370, Average Validation Accuracy: 0.8069\n",
      "Epoch [273/500], Average Training Loss: 0.4331\n",
      "Epoch [273/500], Average Validation Loss: 0.4369, Average Validation Accuracy: 0.8068\n",
      "Epoch [274/500], Average Training Loss: 0.4330\n",
      "Epoch [274/500], Average Validation Loss: 0.4369, Average Validation Accuracy: 0.8066\n",
      "Epoch [275/500], Average Training Loss: 0.4330\n",
      "Epoch [275/500], Average Validation Loss: 0.4369, Average Validation Accuracy: 0.8069\n",
      "Epoch [276/500], Average Training Loss: 0.4331\n",
      "Epoch [276/500], Average Validation Loss: 0.4368, Average Validation Accuracy: 0.8069\n",
      "Epoch [277/500], Average Training Loss: 0.4331\n",
      "Epoch [277/500], Average Validation Loss: 0.4368, Average Validation Accuracy: 0.8072\n",
      "Epoch [278/500], Average Training Loss: 0.4331\n",
      "Epoch [278/500], Average Validation Loss: 0.4367, Average Validation Accuracy: 0.8071\n",
      "Epoch [279/500], Average Training Loss: 0.4331\n",
      "Epoch [279/500], Average Validation Loss: 0.4367, Average Validation Accuracy: 0.8069\n",
      "Epoch [280/500], Average Training Loss: 0.4331\n",
      "Epoch [280/500], Average Validation Loss: 0.4367, Average Validation Accuracy: 0.8073\n",
      "Epoch [281/500], Average Training Loss: 0.4331\n",
      "Epoch [281/500], Average Validation Loss: 0.4367, Average Validation Accuracy: 0.8074\n",
      "Epoch [282/500], Average Training Loss: 0.4330\n",
      "Epoch [282/500], Average Validation Loss: 0.4366, Average Validation Accuracy: 0.8069\n",
      "Epoch [283/500], Average Training Loss: 0.4329\n",
      "Epoch [283/500], Average Validation Loss: 0.4366, Average Validation Accuracy: 0.8075\n",
      "Epoch [284/500], Average Training Loss: 0.4330\n",
      "Epoch [284/500], Average Validation Loss: 0.4366, Average Validation Accuracy: 0.8073\n",
      "Epoch [285/500], Average Training Loss: 0.4326\n",
      "Epoch [285/500], Average Validation Loss: 0.4365, Average Validation Accuracy: 0.8076\n",
      "Epoch [286/500], Average Training Loss: 0.4329\n",
      "Epoch [286/500], Average Validation Loss: 0.4365, Average Validation Accuracy: 0.8073\n",
      "Epoch [287/500], Average Training Loss: 0.4326\n",
      "Epoch [287/500], Average Validation Loss: 0.4364, Average Validation Accuracy: 0.8075\n",
      "Epoch [288/500], Average Training Loss: 0.4329\n",
      "Epoch [288/500], Average Validation Loss: 0.4364, Average Validation Accuracy: 0.8075\n",
      "Epoch [289/500], Average Training Loss: 0.4328\n",
      "Epoch [289/500], Average Validation Loss: 0.4364, Average Validation Accuracy: 0.8077\n",
      "Epoch [290/500], Average Training Loss: 0.4326\n",
      "Epoch [290/500], Average Validation Loss: 0.4363, Average Validation Accuracy: 0.8076\n",
      "Epoch [291/500], Average Training Loss: 0.4327\n",
      "Epoch [291/500], Average Validation Loss: 0.4363, Average Validation Accuracy: 0.8078\n",
      "Epoch [292/500], Average Training Loss: 0.4324\n",
      "Epoch [292/500], Average Validation Loss: 0.4363, Average Validation Accuracy: 0.8079\n",
      "Epoch [293/500], Average Training Loss: 0.4328\n",
      "Epoch [293/500], Average Validation Loss: 0.4363, Average Validation Accuracy: 0.8079\n",
      "Epoch [294/500], Average Training Loss: 0.4327\n",
      "Epoch [294/500], Average Validation Loss: 0.4362, Average Validation Accuracy: 0.8075\n",
      "Epoch [295/500], Average Training Loss: 0.4323\n",
      "Epoch [295/500], Average Validation Loss: 0.4362, Average Validation Accuracy: 0.8078\n",
      "Epoch [296/500], Average Training Loss: 0.4325\n",
      "Epoch [296/500], Average Validation Loss: 0.4362, Average Validation Accuracy: 0.8075\n",
      "Epoch [297/500], Average Training Loss: 0.4328\n",
      "Epoch [297/500], Average Validation Loss: 0.4361, Average Validation Accuracy: 0.8078\n",
      "Epoch [298/500], Average Training Loss: 0.4329\n",
      "Epoch [298/500], Average Validation Loss: 0.4361, Average Validation Accuracy: 0.8079\n",
      "Epoch [299/500], Average Training Loss: 0.4326\n",
      "Epoch [299/500], Average Validation Loss: 0.4361, Average Validation Accuracy: 0.8079\n",
      "Epoch [300/500], Average Training Loss: 0.4322\n",
      "Epoch [300/500], Average Validation Loss: 0.4360, Average Validation Accuracy: 0.8081\n",
      "Epoch [301/500], Average Training Loss: 0.4323\n",
      "Epoch [301/500], Average Validation Loss: 0.4360, Average Validation Accuracy: 0.8083\n",
      "Epoch [302/500], Average Training Loss: 0.4325\n",
      "Epoch [302/500], Average Validation Loss: 0.4360, Average Validation Accuracy: 0.8082\n",
      "Epoch [303/500], Average Training Loss: 0.4322\n",
      "Epoch [303/500], Average Validation Loss: 0.4359, Average Validation Accuracy: 0.8084\n",
      "Epoch [304/500], Average Training Loss: 0.4322\n",
      "Epoch [304/500], Average Validation Loss: 0.4359, Average Validation Accuracy: 0.8082\n",
      "Epoch [305/500], Average Training Loss: 0.4325\n",
      "Epoch [305/500], Average Validation Loss: 0.4359, Average Validation Accuracy: 0.8081\n",
      "Epoch [306/500], Average Training Loss: 0.4322\n",
      "Epoch [306/500], Average Validation Loss: 0.4359, Average Validation Accuracy: 0.8085\n",
      "Epoch [307/500], Average Training Loss: 0.4323\n",
      "Epoch [307/500], Average Validation Loss: 0.4359, Average Validation Accuracy: 0.8077\n",
      "Epoch [308/500], Average Training Loss: 0.4325\n",
      "Epoch [308/500], Average Validation Loss: 0.4358, Average Validation Accuracy: 0.8085\n",
      "Epoch [309/500], Average Training Loss: 0.4322\n",
      "Epoch [309/500], Average Validation Loss: 0.4358, Average Validation Accuracy: 0.8082\n",
      "Epoch [310/500], Average Training Loss: 0.4320\n",
      "Epoch [310/500], Average Validation Loss: 0.4358, Average Validation Accuracy: 0.8081\n",
      "Epoch [311/500], Average Training Loss: 0.4322\n",
      "Epoch [311/500], Average Validation Loss: 0.4357, Average Validation Accuracy: 0.8089\n",
      "Epoch [312/500], Average Training Loss: 0.4319\n",
      "Epoch [312/500], Average Validation Loss: 0.4357, Average Validation Accuracy: 0.8090\n",
      "Epoch [313/500], Average Training Loss: 0.4321\n",
      "Epoch [313/500], Average Validation Loss: 0.4357, Average Validation Accuracy: 0.8086\n",
      "Epoch [314/500], Average Training Loss: 0.4319\n",
      "Epoch [314/500], Average Validation Loss: 0.4357, Average Validation Accuracy: 0.8086\n",
      "Epoch [315/500], Average Training Loss: 0.4320\n",
      "Epoch [315/500], Average Validation Loss: 0.4356, Average Validation Accuracy: 0.8087\n",
      "Epoch [316/500], Average Training Loss: 0.4321\n",
      "Epoch [316/500], Average Validation Loss: 0.4356, Average Validation Accuracy: 0.8089\n",
      "Epoch [317/500], Average Training Loss: 0.4319\n",
      "Epoch [317/500], Average Validation Loss: 0.4356, Average Validation Accuracy: 0.8086\n",
      "Epoch [318/500], Average Training Loss: 0.4323\n",
      "Epoch [318/500], Average Validation Loss: 0.4355, Average Validation Accuracy: 0.8087\n",
      "Epoch [319/500], Average Training Loss: 0.4320\n",
      "Epoch [319/500], Average Validation Loss: 0.4355, Average Validation Accuracy: 0.8085\n",
      "Epoch [320/500], Average Training Loss: 0.4320\n",
      "Epoch [320/500], Average Validation Loss: 0.4355, Average Validation Accuracy: 0.8087\n",
      "Epoch [321/500], Average Training Loss: 0.4319\n",
      "Epoch [321/500], Average Validation Loss: 0.4355, Average Validation Accuracy: 0.8084\n",
      "Epoch [322/500], Average Training Loss: 0.4317\n",
      "Epoch [322/500], Average Validation Loss: 0.4354, Average Validation Accuracy: 0.8085\n",
      "Epoch [323/500], Average Training Loss: 0.4319\n",
      "Epoch [323/500], Average Validation Loss: 0.4354, Average Validation Accuracy: 0.8082\n",
      "Epoch [324/500], Average Training Loss: 0.4319\n",
      "Epoch [324/500], Average Validation Loss: 0.4354, Average Validation Accuracy: 0.8084\n",
      "Epoch [325/500], Average Training Loss: 0.4315\n",
      "Epoch [325/500], Average Validation Loss: 0.4354, Average Validation Accuracy: 0.8088\n",
      "Epoch [326/500], Average Training Loss: 0.4317\n",
      "Epoch [326/500], Average Validation Loss: 0.4354, Average Validation Accuracy: 0.8087\n",
      "Epoch [327/500], Average Training Loss: 0.4317\n",
      "Epoch [327/500], Average Validation Loss: 0.4353, Average Validation Accuracy: 0.8088\n",
      "Epoch [328/500], Average Training Loss: 0.4319\n",
      "Epoch [328/500], Average Validation Loss: 0.4353, Average Validation Accuracy: 0.8088\n",
      "Epoch [329/500], Average Training Loss: 0.4317\n",
      "Epoch [329/500], Average Validation Loss: 0.4353, Average Validation Accuracy: 0.8090\n",
      "Epoch [330/500], Average Training Loss: 0.4316\n",
      "Epoch [330/500], Average Validation Loss: 0.4353, Average Validation Accuracy: 0.8088\n",
      "Epoch [331/500], Average Training Loss: 0.4316\n",
      "Epoch [331/500], Average Validation Loss: 0.4352, Average Validation Accuracy: 0.8091\n",
      "Epoch [332/500], Average Training Loss: 0.4316\n",
      "Epoch [332/500], Average Validation Loss: 0.4352, Average Validation Accuracy: 0.8086\n",
      "Epoch [333/500], Average Training Loss: 0.4317\n",
      "Epoch [333/500], Average Validation Loss: 0.4352, Average Validation Accuracy: 0.8090\n",
      "Epoch [334/500], Average Training Loss: 0.4313\n",
      "Epoch [334/500], Average Validation Loss: 0.4352, Average Validation Accuracy: 0.8087\n",
      "Epoch [335/500], Average Training Loss: 0.4313\n",
      "Epoch [335/500], Average Validation Loss: 0.4352, Average Validation Accuracy: 0.8086\n",
      "Epoch [336/500], Average Training Loss: 0.4314\n",
      "Epoch [336/500], Average Validation Loss: 0.4352, Average Validation Accuracy: 0.8089\n",
      "Epoch [337/500], Average Training Loss: 0.4315\n",
      "Epoch [337/500], Average Validation Loss: 0.4352, Average Validation Accuracy: 0.8088\n",
      "Epoch [338/500], Average Training Loss: 0.4315\n",
      "Epoch [338/500], Average Validation Loss: 0.4351, Average Validation Accuracy: 0.8087\n",
      "Epoch [339/500], Average Training Loss: 0.4314\n",
      "Epoch [339/500], Average Validation Loss: 0.4351, Average Validation Accuracy: 0.8088\n",
      "Epoch [340/500], Average Training Loss: 0.4314\n",
      "Epoch [340/500], Average Validation Loss: 0.4350, Average Validation Accuracy: 0.8091\n",
      "Epoch [341/500], Average Training Loss: 0.4315\n",
      "Epoch [341/500], Average Validation Loss: 0.4350, Average Validation Accuracy: 0.8087\n",
      "Epoch [342/500], Average Training Loss: 0.4314\n",
      "Epoch [342/500], Average Validation Loss: 0.4350, Average Validation Accuracy: 0.8092\n",
      "Epoch [343/500], Average Training Loss: 0.4315\n",
      "Epoch [343/500], Average Validation Loss: 0.4350, Average Validation Accuracy: 0.8091\n",
      "Epoch [344/500], Average Training Loss: 0.4315\n",
      "Epoch [344/500], Average Validation Loss: 0.4350, Average Validation Accuracy: 0.8092\n",
      "Epoch [345/500], Average Training Loss: 0.4312\n",
      "Epoch [345/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8091\n",
      "Epoch [346/500], Average Training Loss: 0.4312\n",
      "Epoch [346/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8094\n",
      "Epoch [347/500], Average Training Loss: 0.4313\n",
      "Epoch [347/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8092\n",
      "Epoch [348/500], Average Training Loss: 0.4311\n",
      "Epoch [348/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8094\n",
      "Epoch [349/500], Average Training Loss: 0.4311\n",
      "Epoch [349/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8091\n",
      "Epoch [350/500], Average Training Loss: 0.4313\n",
      "Epoch [350/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8087\n",
      "Epoch [351/500], Average Training Loss: 0.4314\n",
      "Epoch [351/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8096\n",
      "Epoch [352/500], Average Training Loss: 0.4313\n",
      "Epoch [352/500], Average Validation Loss: 0.4348, Average Validation Accuracy: 0.8090\n",
      "Epoch [353/500], Average Training Loss: 0.4313\n",
      "Epoch [353/500], Average Validation Loss: 0.4348, Average Validation Accuracy: 0.8087\n",
      "Epoch [354/500], Average Training Loss: 0.4311\n",
      "Epoch [354/500], Average Validation Loss: 0.4348, Average Validation Accuracy: 0.8092\n",
      "Epoch [355/500], Average Training Loss: 0.4311\n",
      "Epoch [355/500], Average Validation Loss: 0.4348, Average Validation Accuracy: 0.8086\n",
      "Epoch [356/500], Average Training Loss: 0.4313\n",
      "Epoch [356/500], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8095\n",
      "Epoch [357/500], Average Training Loss: 0.4313\n",
      "Epoch [357/500], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8089\n",
      "Epoch [358/500], Average Training Loss: 0.4314\n",
      "Epoch [358/500], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8085\n",
      "Epoch [359/500], Average Training Loss: 0.4311\n",
      "Epoch [359/500], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8089\n",
      "Epoch [360/500], Average Training Loss: 0.4310\n",
      "Epoch [360/500], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8095\n",
      "Epoch [361/500], Average Training Loss: 0.4312\n",
      "Epoch [361/500], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8088\n",
      "Epoch [362/500], Average Training Loss: 0.4312\n",
      "Epoch [362/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8088\n",
      "Epoch [363/500], Average Training Loss: 0.4311\n",
      "Epoch [363/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8091\n",
      "Epoch [364/500], Average Training Loss: 0.4312\n",
      "Epoch [364/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8091\n",
      "Epoch [365/500], Average Training Loss: 0.4311\n",
      "Epoch [365/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8092\n",
      "Epoch [366/500], Average Training Loss: 0.4311\n",
      "Epoch [366/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8091\n",
      "Epoch [367/500], Average Training Loss: 0.4313\n",
      "Epoch [367/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8094\n",
      "Epoch [368/500], Average Training Loss: 0.4311\n",
      "Epoch [368/500], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8092\n",
      "Epoch [369/500], Average Training Loss: 0.4312\n",
      "Epoch [369/500], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8092\n",
      "Epoch [370/500], Average Training Loss: 0.4309\n",
      "Epoch [370/500], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8091\n",
      "Epoch [371/500], Average Training Loss: 0.4310\n",
      "Epoch [371/500], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8095\n",
      "Epoch [372/500], Average Training Loss: 0.4309\n",
      "Epoch [372/500], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8095\n",
      "Epoch [373/500], Average Training Loss: 0.4308\n",
      "Epoch [373/500], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8095\n",
      "Epoch [374/500], Average Training Loss: 0.4308\n",
      "Epoch [374/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8093\n",
      "Epoch [375/500], Average Training Loss: 0.4308\n",
      "Epoch [375/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8098\n",
      "Epoch [376/500], Average Training Loss: 0.4310\n",
      "Epoch [376/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8097\n",
      "Epoch [377/500], Average Training Loss: 0.4309\n",
      "Epoch [377/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8097\n",
      "Epoch [378/500], Average Training Loss: 0.4309\n",
      "Epoch [378/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8095\n",
      "Epoch [379/500], Average Training Loss: 0.4310\n",
      "Epoch [379/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8105\n",
      "Epoch [380/500], Average Training Loss: 0.4307\n",
      "Epoch [380/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8095\n",
      "Epoch [381/500], Average Training Loss: 0.4308\n",
      "Epoch [381/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8094\n",
      "Epoch [382/500], Average Training Loss: 0.4307\n",
      "Epoch [382/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8094\n",
      "Epoch [383/500], Average Training Loss: 0.4308\n",
      "Epoch [383/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8097\n",
      "Epoch [384/500], Average Training Loss: 0.4305\n",
      "Epoch [384/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8099\n",
      "Epoch [385/500], Average Training Loss: 0.4307\n",
      "Epoch [385/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8096\n",
      "Epoch [386/500], Average Training Loss: 0.4309\n",
      "Epoch [386/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8105\n",
      "Epoch [387/500], Average Training Loss: 0.4311\n",
      "Epoch [387/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8098\n",
      "Epoch [388/500], Average Training Loss: 0.4309\n",
      "Epoch [388/500], Average Validation Loss: 0.4342, Average Validation Accuracy: 0.8098\n",
      "Epoch [389/500], Average Training Loss: 0.4304\n",
      "Epoch [389/500], Average Validation Loss: 0.4342, Average Validation Accuracy: 0.8100\n",
      "Epoch [390/500], Average Training Loss: 0.4307\n",
      "Epoch [390/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8095\n",
      "Epoch [391/500], Average Training Loss: 0.4306\n",
      "Epoch [391/500], Average Validation Loss: 0.4342, Average Validation Accuracy: 0.8097\n",
      "Epoch [392/500], Average Training Loss: 0.4306\n",
      "Epoch [392/500], Average Validation Loss: 0.4342, Average Validation Accuracy: 0.8104\n",
      "Epoch [393/500], Average Training Loss: 0.4306\n",
      "Epoch [393/500], Average Validation Loss: 0.4342, Average Validation Accuracy: 0.8099\n",
      "Epoch [394/500], Average Training Loss: 0.4305\n",
      "Epoch [394/500], Average Validation Loss: 0.4342, Average Validation Accuracy: 0.8104\n",
      "Epoch [395/500], Average Training Loss: 0.4305\n",
      "Epoch [395/500], Average Validation Loss: 0.4342, Average Validation Accuracy: 0.8097\n",
      "Epoch [396/500], Average Training Loss: 0.4307\n",
      "Epoch [396/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8105\n",
      "Epoch [397/500], Average Training Loss: 0.4306\n",
      "Epoch [397/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8098\n",
      "Epoch [398/500], Average Training Loss: 0.4305\n",
      "Epoch [398/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8098\n",
      "Epoch [399/500], Average Training Loss: 0.4304\n",
      "Epoch [399/500], Average Validation Loss: 0.4342, Average Validation Accuracy: 0.8098\n",
      "Epoch [400/500], Average Training Loss: 0.4306\n",
      "Epoch [400/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8105\n",
      "Epoch [401/500], Average Training Loss: 0.4306\n",
      "Epoch [401/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8108\n",
      "Epoch [402/500], Average Training Loss: 0.4304\n",
      "Epoch [402/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8108\n",
      "Epoch [403/500], Average Training Loss: 0.4304\n",
      "Epoch [403/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8103\n",
      "Epoch [404/500], Average Training Loss: 0.4303\n",
      "Epoch [404/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8109\n",
      "Epoch [405/500], Average Training Loss: 0.4304\n",
      "Epoch [405/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8109\n",
      "Epoch [406/500], Average Training Loss: 0.4305\n",
      "Epoch [406/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8109\n",
      "Epoch [407/500], Average Training Loss: 0.4303\n",
      "Epoch [407/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8109\n",
      "Epoch [408/500], Average Training Loss: 0.4306\n",
      "Epoch [408/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8104\n",
      "Epoch [409/500], Average Training Loss: 0.4307\n",
      "Epoch [409/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8101\n",
      "Epoch [410/500], Average Training Loss: 0.4303\n",
      "Epoch [410/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8098\n",
      "Epoch [411/500], Average Training Loss: 0.4305\n",
      "Epoch [411/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8109\n",
      "Epoch [412/500], Average Training Loss: 0.4304\n",
      "Epoch [412/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8100\n",
      "Epoch [413/500], Average Training Loss: 0.4304\n",
      "Epoch [413/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8101\n",
      "Epoch [414/500], Average Training Loss: 0.4303\n",
      "Epoch [414/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8109\n",
      "Epoch [415/500], Average Training Loss: 0.4302\n",
      "Epoch [415/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8100\n",
      "Epoch [416/500], Average Training Loss: 0.4304\n",
      "Epoch [416/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8109\n",
      "Epoch [417/500], Average Training Loss: 0.4303\n",
      "Epoch [417/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8103\n",
      "Epoch [418/500], Average Training Loss: 0.4301\n",
      "Epoch [418/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8112\n",
      "Epoch [419/500], Average Training Loss: 0.4302\n",
      "Epoch [419/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8103\n",
      "Epoch [420/500], Average Training Loss: 0.4304\n",
      "Epoch [420/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8111\n",
      "Epoch [421/500], Average Training Loss: 0.4304\n",
      "Epoch [421/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8110\n",
      "Epoch [422/500], Average Training Loss: 0.4304\n",
      "Epoch [422/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8100\n",
      "Epoch [423/500], Average Training Loss: 0.4301\n",
      "Epoch [423/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8101\n",
      "Epoch [424/500], Average Training Loss: 0.4302\n",
      "Epoch [424/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8101\n",
      "Epoch [425/500], Average Training Loss: 0.4302\n",
      "Epoch [425/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8111\n",
      "Epoch [426/500], Average Training Loss: 0.4299\n",
      "Epoch [426/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8110\n",
      "Epoch [427/500], Average Training Loss: 0.4300\n",
      "Epoch [427/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8112\n",
      "Epoch [428/500], Average Training Loss: 0.4303\n",
      "Epoch [428/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8112\n",
      "Epoch [429/500], Average Training Loss: 0.4303\n",
      "Epoch [429/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8107\n",
      "Epoch [430/500], Average Training Loss: 0.4304\n",
      "Epoch [430/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8109\n",
      "Epoch [431/500], Average Training Loss: 0.4301\n",
      "Epoch [431/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8113\n",
      "Epoch [432/500], Average Training Loss: 0.4302\n",
      "Epoch [432/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8111\n",
      "Epoch [433/500], Average Training Loss: 0.4304\n",
      "Epoch [433/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8106\n",
      "Epoch [434/500], Average Training Loss: 0.4301\n",
      "Epoch [434/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8108\n",
      "Epoch [435/500], Average Training Loss: 0.4302\n",
      "Epoch [435/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8106\n",
      "Epoch [436/500], Average Training Loss: 0.4301\n",
      "Epoch [436/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8119\n",
      "Epoch [437/500], Average Training Loss: 0.4302\n",
      "Epoch [437/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8104\n",
      "Epoch [438/500], Average Training Loss: 0.4303\n",
      "Epoch [438/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8112\n",
      "Epoch [439/500], Average Training Loss: 0.4303\n",
      "Epoch [439/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8110\n",
      "Epoch [440/500], Average Training Loss: 0.4300\n",
      "Epoch [440/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8112\n",
      "Epoch [441/500], Average Training Loss: 0.4300\n",
      "Epoch [441/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8114\n",
      "Epoch [442/500], Average Training Loss: 0.4302\n",
      "Epoch [442/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8114\n",
      "Epoch [443/500], Average Training Loss: 0.4301\n",
      "Epoch [443/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8106\n",
      "Epoch [444/500], Average Training Loss: 0.4301\n",
      "Epoch [444/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8110\n",
      "Epoch [445/500], Average Training Loss: 0.4302\n",
      "Epoch [445/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8118\n",
      "Epoch [446/500], Average Training Loss: 0.4301\n",
      "Epoch [446/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8111\n",
      "Epoch [447/500], Average Training Loss: 0.4302\n",
      "Epoch [447/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8111\n",
      "Epoch [448/500], Average Training Loss: 0.4301\n",
      "Epoch [448/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8116\n",
      "Epoch [449/500], Average Training Loss: 0.4302\n",
      "Epoch [449/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8117\n",
      "Epoch [450/500], Average Training Loss: 0.4301\n",
      "Epoch [450/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8117\n",
      "Epoch [451/500], Average Training Loss: 0.4302\n",
      "Epoch [451/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8117\n",
      "Epoch [452/500], Average Training Loss: 0.4300\n",
      "Epoch [452/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8111\n",
      "Epoch [453/500], Average Training Loss: 0.4304\n",
      "Epoch [453/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8107\n",
      "Epoch [454/500], Average Training Loss: 0.4301\n",
      "Epoch [454/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8116\n",
      "Epoch [455/500], Average Training Loss: 0.4298\n",
      "Epoch [455/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8113\n",
      "Epoch [456/500], Average Training Loss: 0.4298\n",
      "Epoch [456/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8115\n",
      "Epoch [457/500], Average Training Loss: 0.4301\n",
      "Epoch [457/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8111\n",
      "Epoch [458/500], Average Training Loss: 0.4300\n",
      "Epoch [458/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8111\n",
      "Epoch [459/500], Average Training Loss: 0.4300\n",
      "Epoch [459/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8119\n",
      "Epoch [460/500], Average Training Loss: 0.4304\n",
      "Epoch [460/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8113\n",
      "Epoch [461/500], Average Training Loss: 0.4301\n",
      "Epoch [461/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8115\n",
      "Epoch [462/500], Average Training Loss: 0.4300\n",
      "Epoch [462/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8111\n",
      "Epoch [463/500], Average Training Loss: 0.4302\n",
      "Epoch [463/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8114\n",
      "Epoch [464/500], Average Training Loss: 0.4302\n",
      "Epoch [464/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8120\n",
      "Epoch [465/500], Average Training Loss: 0.4299\n",
      "Epoch [465/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8117\n",
      "Epoch [466/500], Average Training Loss: 0.4302\n",
      "Epoch [466/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8118\n",
      "Epoch [467/500], Average Training Loss: 0.4298\n",
      "Epoch [467/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8111\n",
      "Epoch [468/500], Average Training Loss: 0.4302\n",
      "Epoch [468/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8117\n",
      "Epoch [469/500], Average Training Loss: 0.4298\n",
      "Epoch [469/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8112\n",
      "Epoch [470/500], Average Training Loss: 0.4301\n",
      "Epoch [470/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8112\n",
      "Epoch [471/500], Average Training Loss: 0.4300\n",
      "Epoch [471/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8121\n",
      "Epoch [472/500], Average Training Loss: 0.4298\n",
      "Epoch [472/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8121\n",
      "Epoch [473/500], Average Training Loss: 0.4298\n",
      "Epoch [473/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8108\n",
      "Epoch [474/500], Average Training Loss: 0.4300\n",
      "Epoch [474/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8112\n",
      "Epoch [475/500], Average Training Loss: 0.4299\n",
      "Epoch [475/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8116\n",
      "Epoch [476/500], Average Training Loss: 0.4301\n",
      "Epoch [476/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8114\n",
      "Epoch [477/500], Average Training Loss: 0.4297\n",
      "Epoch [477/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8121\n",
      "Epoch [478/500], Average Training Loss: 0.4297\n",
      "Epoch [478/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8121\n",
      "Epoch [479/500], Average Training Loss: 0.4298\n",
      "Epoch [479/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8123\n",
      "Epoch [480/500], Average Training Loss: 0.4298\n",
      "Epoch [480/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8112\n",
      "Epoch [481/500], Average Training Loss: 0.4298\n",
      "Epoch [481/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8108\n",
      "Epoch [482/500], Average Training Loss: 0.4298\n",
      "Epoch [482/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8117\n",
      "Epoch [483/500], Average Training Loss: 0.4298\n",
      "Epoch [483/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8116\n",
      "Epoch [484/500], Average Training Loss: 0.4297\n",
      "Epoch [484/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8116\n",
      "Epoch [485/500], Average Training Loss: 0.4298\n",
      "Epoch [485/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8108\n",
      "Epoch [486/500], Average Training Loss: 0.4301\n",
      "Epoch [486/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8118\n",
      "Epoch [487/500], Average Training Loss: 0.4297\n",
      "Epoch [487/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8121\n",
      "Epoch [488/500], Average Training Loss: 0.4296\n",
      "Epoch [488/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8118\n",
      "Epoch [489/500], Average Training Loss: 0.4300\n",
      "Epoch [489/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8108\n",
      "Epoch [490/500], Average Training Loss: 0.4297\n",
      "Epoch [490/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8121\n",
      "Epoch [491/500], Average Training Loss: 0.4295\n",
      "Epoch [491/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8117\n",
      "Epoch [492/500], Average Training Loss: 0.4296\n",
      "Epoch [492/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8121\n",
      "Epoch [493/500], Average Training Loss: 0.4295\n",
      "Epoch [493/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8115\n",
      "Epoch [494/500], Average Training Loss: 0.4295\n",
      "Epoch [494/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8118\n",
      "Epoch [495/500], Average Training Loss: 0.4296\n",
      "Epoch [495/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8117\n",
      "Epoch [496/500], Average Training Loss: 0.4295\n",
      "Epoch [496/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8107\n",
      "Epoch [497/500], Average Training Loss: 0.4297\n",
      "Epoch [497/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8119\n",
      "Epoch [498/500], Average Training Loss: 0.4295\n",
      "Epoch [498/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8109\n",
      "Epoch [499/500], Average Training Loss: 0.4295\n",
      "Epoch [499/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8121\n",
      "Epoch [500/500], Average Training Loss: 0.4298\n",
      "Epoch [500/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8120\n",
      "Best Validation Accuracy: 0.8123 at epoch 479 for trial 4\n",
      "Epoch [1/500], Average Training Loss: 0.4402\n",
      "Epoch [1/500], Average Validation Loss: 0.4286, Average Validation Accuracy: 0.8109\n",
      "Epoch [2/500], Average Training Loss: 0.4259\n",
      "Epoch [2/500], Average Validation Loss: 0.4297, Average Validation Accuracy: 0.8131\n",
      "Epoch [3/500], Average Training Loss: 0.4203\n",
      "Epoch [3/500], Average Validation Loss: 0.4208, Average Validation Accuracy: 0.8171\n",
      "Epoch [4/500], Average Training Loss: 0.4164\n",
      "Epoch [4/500], Average Validation Loss: 0.4192, Average Validation Accuracy: 0.8138\n",
      "Epoch [5/500], Average Training Loss: 0.4133\n",
      "Epoch [5/500], Average Validation Loss: 0.4156, Average Validation Accuracy: 0.8191\n",
      "Epoch [6/500], Average Training Loss: 0.4126\n",
      "Epoch [6/500], Average Validation Loss: 0.4163, Average Validation Accuracy: 0.8166\n",
      "Epoch [7/500], Average Training Loss: 0.4117\n",
      "Epoch [7/500], Average Validation Loss: 0.4162, Average Validation Accuracy: 0.8162\n",
      "Epoch [8/500], Average Training Loss: 0.4111\n",
      "Epoch [8/500], Average Validation Loss: 0.4185, Average Validation Accuracy: 0.8163\n",
      "Epoch [9/500], Average Training Loss: 0.4095\n",
      "Epoch [9/500], Average Validation Loss: 0.4126, Average Validation Accuracy: 0.8198\n",
      "Epoch [10/500], Average Training Loss: 0.4083\n",
      "Epoch [10/500], Average Validation Loss: 0.4132, Average Validation Accuracy: 0.8181\n",
      "Epoch [11/500], Average Training Loss: 0.4077\n",
      "Epoch [11/500], Average Validation Loss: 0.4102, Average Validation Accuracy: 0.8209\n",
      "Epoch [12/500], Average Training Loss: 0.4072\n",
      "Epoch [12/500], Average Validation Loss: 0.4157, Average Validation Accuracy: 0.8161\n",
      "Epoch [13/500], Average Training Loss: 0.4068\n",
      "Epoch [13/500], Average Validation Loss: 0.4152, Average Validation Accuracy: 0.8185\n",
      "Epoch [14/500], Average Training Loss: 0.4053\n",
      "Epoch [14/500], Average Validation Loss: 0.4081, Average Validation Accuracy: 0.8216\n",
      "Epoch [15/500], Average Training Loss: 0.4050\n",
      "Epoch [15/500], Average Validation Loss: 0.4080, Average Validation Accuracy: 0.8226\n",
      "Epoch [16/500], Average Training Loss: 0.4042\n",
      "Epoch [16/500], Average Validation Loss: 0.4095, Average Validation Accuracy: 0.8243\n",
      "Epoch [17/500], Average Training Loss: 0.4032\n",
      "Epoch [17/500], Average Validation Loss: 0.4074, Average Validation Accuracy: 0.8232\n",
      "Epoch [18/500], Average Training Loss: 0.4026\n",
      "Epoch [18/500], Average Validation Loss: 0.4126, Average Validation Accuracy: 0.8212\n",
      "Epoch [19/500], Average Training Loss: 0.4027\n",
      "Epoch [19/500], Average Validation Loss: 0.4081, Average Validation Accuracy: 0.8250\n",
      "Epoch [20/500], Average Training Loss: 0.4013\n",
      "Epoch [20/500], Average Validation Loss: 0.4091, Average Validation Accuracy: 0.8226\n",
      "Epoch [21/500], Average Training Loss: 0.4010\n",
      "Epoch [21/500], Average Validation Loss: 0.4069, Average Validation Accuracy: 0.8230\n",
      "Epoch [22/500], Average Training Loss: 0.4003\n",
      "Epoch [22/500], Average Validation Loss: 0.4092, Average Validation Accuracy: 0.8212\n",
      "Epoch [23/500], Average Training Loss: 0.3994\n",
      "Epoch [23/500], Average Validation Loss: 0.4066, Average Validation Accuracy: 0.8255\n",
      "Epoch [24/500], Average Training Loss: 0.3986\n",
      "Epoch [24/500], Average Validation Loss: 0.4053, Average Validation Accuracy: 0.8258\n",
      "Epoch [25/500], Average Training Loss: 0.3989\n",
      "Epoch [25/500], Average Validation Loss: 0.4059, Average Validation Accuracy: 0.8249\n",
      "Epoch [26/500], Average Training Loss: 0.3980\n",
      "Epoch [26/500], Average Validation Loss: 0.4064, Average Validation Accuracy: 0.8246\n",
      "Epoch [27/500], Average Training Loss: 0.3969\n",
      "Epoch [27/500], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8244\n",
      "Epoch [28/500], Average Training Loss: 0.3965\n",
      "Epoch [28/500], Average Validation Loss: 0.4058, Average Validation Accuracy: 0.8259\n",
      "Epoch [29/500], Average Training Loss: 0.3959\n",
      "Epoch [29/500], Average Validation Loss: 0.4078, Average Validation Accuracy: 0.8240\n",
      "Epoch [30/500], Average Training Loss: 0.3954\n",
      "Epoch [30/500], Average Validation Loss: 0.4073, Average Validation Accuracy: 0.8256\n",
      "Epoch [31/500], Average Training Loss: 0.3951\n",
      "Epoch [31/500], Average Validation Loss: 0.4091, Average Validation Accuracy: 0.8232\n",
      "Epoch [32/500], Average Training Loss: 0.3942\n",
      "Epoch [32/500], Average Validation Loss: 0.4084, Average Validation Accuracy: 0.8245\n",
      "Epoch [33/500], Average Training Loss: 0.3932\n",
      "Epoch [33/500], Average Validation Loss: 0.4066, Average Validation Accuracy: 0.8263\n",
      "Epoch [34/500], Average Training Loss: 0.3925\n",
      "Epoch [34/500], Average Validation Loss: 0.4092, Average Validation Accuracy: 0.8257\n",
      "Epoch [35/500], Average Training Loss: 0.3916\n",
      "Early stopping at epoch 34. Best loss was 0.4053\n",
      "Best Validation Accuracy: 0.8263 at epoch 33 for trial 5\n",
      "Epoch [1/200], Average Training Loss: 0.4393\n",
      "Epoch [1/200], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8082\n",
      "Epoch [2/200], Average Training Loss: 0.4261\n",
      "Epoch [2/200], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8103\n",
      "Epoch [3/200], Average Training Loss: 0.4215\n",
      "Epoch [3/200], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8158\n",
      "Epoch [4/200], Average Training Loss: 0.4171\n",
      "Epoch [4/200], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8115\n",
      "Epoch [5/200], Average Training Loss: 0.4149\n",
      "Epoch [5/200], Average Validation Loss: 0.4178, Average Validation Accuracy: 0.8196\n",
      "Epoch [6/200], Average Training Loss: 0.4128\n",
      "Epoch [6/200], Average Validation Loss: 0.4133, Average Validation Accuracy: 0.8200\n",
      "Epoch [7/200], Average Training Loss: 0.4121\n",
      "Epoch [7/200], Average Validation Loss: 0.4144, Average Validation Accuracy: 0.8198\n",
      "Epoch [8/200], Average Training Loss: 0.4111\n",
      "Epoch [8/200], Average Validation Loss: 0.4127, Average Validation Accuracy: 0.8213\n",
      "Epoch [9/200], Average Training Loss: 0.4102\n",
      "Epoch [9/200], Average Validation Loss: 0.4121, Average Validation Accuracy: 0.8212\n",
      "Epoch [10/200], Average Training Loss: 0.4093\n",
      "Epoch [10/200], Average Validation Loss: 0.4135, Average Validation Accuracy: 0.8221\n",
      "Epoch [11/200], Average Training Loss: 0.4084\n",
      "Epoch [11/200], Average Validation Loss: 0.4133, Average Validation Accuracy: 0.8198\n",
      "Epoch [12/200], Average Training Loss: 0.4071\n",
      "Epoch [12/200], Average Validation Loss: 0.4149, Average Validation Accuracy: 0.8164\n",
      "Epoch [13/200], Average Training Loss: 0.4069\n",
      "Epoch [13/200], Average Validation Loss: 0.4123, Average Validation Accuracy: 0.8201\n",
      "Epoch [14/200], Average Training Loss: 0.4059\n",
      "Epoch [14/200], Average Validation Loss: 0.4097, Average Validation Accuracy: 0.8217\n",
      "Epoch [15/200], Average Training Loss: 0.4050\n",
      "Epoch [15/200], Average Validation Loss: 0.4083, Average Validation Accuracy: 0.8227\n",
      "Epoch [16/200], Average Training Loss: 0.4050\n",
      "Epoch [16/200], Average Validation Loss: 0.4092, Average Validation Accuracy: 0.8213\n",
      "Epoch [17/200], Average Training Loss: 0.4042\n",
      "Epoch [17/200], Average Validation Loss: 0.4097, Average Validation Accuracy: 0.8226\n",
      "Epoch [18/200], Average Training Loss: 0.4034\n",
      "Epoch [18/200], Average Validation Loss: 0.4082, Average Validation Accuracy: 0.8221\n",
      "Epoch [19/200], Average Training Loss: 0.4028\n",
      "Epoch [19/200], Average Validation Loss: 0.4111, Average Validation Accuracy: 0.8198\n",
      "Epoch [20/200], Average Training Loss: 0.4022\n",
      "Epoch [20/200], Average Validation Loss: 0.4145, Average Validation Accuracy: 0.8212\n",
      "Epoch [21/200], Average Training Loss: 0.4019\n",
      "Epoch [21/200], Average Validation Loss: 0.4107, Average Validation Accuracy: 0.8203\n",
      "Epoch [22/200], Average Training Loss: 0.4015\n",
      "Epoch [22/200], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8245\n",
      "Epoch [23/200], Average Training Loss: 0.4011\n",
      "Epoch [23/200], Average Validation Loss: 0.4073, Average Validation Accuracy: 0.8215\n",
      "Epoch [24/200], Average Training Loss: 0.4004\n",
      "Epoch [24/200], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8227\n",
      "Epoch [25/200], Average Training Loss: 0.3999\n",
      "Epoch [25/200], Average Validation Loss: 0.4076, Average Validation Accuracy: 0.8248\n",
      "Epoch [26/200], Average Training Loss: 0.3995\n",
      "Epoch [26/200], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8238\n",
      "Epoch [27/200], Average Training Loss: 0.3990\n",
      "Epoch [27/200], Average Validation Loss: 0.4105, Average Validation Accuracy: 0.8195\n",
      "Epoch [28/200], Average Training Loss: 0.3983\n",
      "Epoch [28/200], Average Validation Loss: 0.4079, Average Validation Accuracy: 0.8232\n",
      "Epoch [29/200], Average Training Loss: 0.3981\n",
      "Epoch [29/200], Average Validation Loss: 0.4087, Average Validation Accuracy: 0.8214\n",
      "Epoch [30/200], Average Training Loss: 0.3977\n",
      "Epoch [30/200], Average Validation Loss: 0.4066, Average Validation Accuracy: 0.8244\n",
      "Epoch [31/200], Average Training Loss: 0.3972\n",
      "Epoch [31/200], Average Validation Loss: 0.4137, Average Validation Accuracy: 0.8222\n",
      "Epoch [32/200], Average Training Loss: 0.3965\n",
      "Epoch [32/200], Average Validation Loss: 0.4071, Average Validation Accuracy: 0.8228\n",
      "Epoch [33/200], Average Training Loss: 0.3963\n",
      "Epoch [33/200], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8234\n",
      "Epoch [34/200], Average Training Loss: 0.3954\n",
      "Epoch [34/200], Average Validation Loss: 0.4118, Average Validation Accuracy: 0.8226\n",
      "Epoch [35/200], Average Training Loss: 0.3951\n",
      "Epoch [35/200], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8252\n",
      "Epoch [36/200], Average Training Loss: 0.3947\n",
      "Epoch [36/200], Average Validation Loss: 0.4121, Average Validation Accuracy: 0.8217\n",
      "Epoch [37/200], Average Training Loss: 0.3940\n",
      "Early stopping at epoch 36. Best loss was 0.4061\n",
      "Best Validation Accuracy: 0.8252 at epoch 35 for trial 6\n",
      "Epoch [1/200], Average Training Loss: 0.4439\n",
      "Epoch [1/200], Average Validation Loss: 0.4324, Average Validation Accuracy: 0.8091\n",
      "Epoch [2/200], Average Training Loss: 0.4269\n",
      "Epoch [2/200], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8117\n",
      "Epoch [3/200], Average Training Loss: 0.4230\n",
      "Epoch [3/200], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8129\n",
      "Epoch [4/200], Average Training Loss: 0.4197\n",
      "Epoch [4/200], Average Validation Loss: 0.4185, Average Validation Accuracy: 0.8185\n",
      "Epoch [5/200], Average Training Loss: 0.4167\n",
      "Epoch [5/200], Average Validation Loss: 0.4186, Average Validation Accuracy: 0.8175\n",
      "Epoch [6/200], Average Training Loss: 0.4160\n",
      "Epoch [6/200], Average Validation Loss: 0.4186, Average Validation Accuracy: 0.8167\n",
      "Epoch [7/200], Average Training Loss: 0.4133\n",
      "Epoch [7/200], Average Validation Loss: 0.4186, Average Validation Accuracy: 0.8157\n",
      "Epoch [8/200], Average Training Loss: 0.4118\n",
      "Epoch [8/200], Average Validation Loss: 0.4134, Average Validation Accuracy: 0.8216\n",
      "Epoch [9/200], Average Training Loss: 0.4104\n",
      "Epoch [9/200], Average Validation Loss: 0.4171, Average Validation Accuracy: 0.8176\n",
      "Epoch [10/200], Average Training Loss: 0.4097\n",
      "Epoch [10/200], Average Validation Loss: 0.4131, Average Validation Accuracy: 0.8215\n",
      "Epoch [11/200], Average Training Loss: 0.4083\n",
      "Epoch [11/200], Average Validation Loss: 0.4111, Average Validation Accuracy: 0.8207\n",
      "Epoch [12/200], Average Training Loss: 0.4069\n",
      "Epoch [12/200], Average Validation Loss: 0.4102, Average Validation Accuracy: 0.8217\n",
      "Epoch [13/200], Average Training Loss: 0.4063\n",
      "Epoch [13/200], Average Validation Loss: 0.4087, Average Validation Accuracy: 0.8213\n",
      "Epoch [14/200], Average Training Loss: 0.4064\n",
      "Epoch [14/200], Average Validation Loss: 0.4078, Average Validation Accuracy: 0.8219\n",
      "Epoch [15/200], Average Training Loss: 0.4054\n",
      "Epoch [15/200], Average Validation Loss: 0.4082, Average Validation Accuracy: 0.8226\n",
      "Epoch [16/200], Average Training Loss: 0.4052\n",
      "Epoch [16/200], Average Validation Loss: 0.4097, Average Validation Accuracy: 0.8206\n",
      "Epoch [17/200], Average Training Loss: 0.4033\n",
      "Epoch [17/200], Average Validation Loss: 0.4050, Average Validation Accuracy: 0.8239\n",
      "Epoch [18/200], Average Training Loss: 0.4032\n",
      "Epoch [18/200], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8221\n",
      "Epoch [19/200], Average Training Loss: 0.4030\n",
      "Epoch [19/200], Average Validation Loss: 0.4049, Average Validation Accuracy: 0.8236\n",
      "Epoch [20/200], Average Training Loss: 0.4027\n",
      "Epoch [20/200], Average Validation Loss: 0.4051, Average Validation Accuracy: 0.8244\n",
      "Epoch [21/200], Average Training Loss: 0.4016\n",
      "Epoch [21/200], Average Validation Loss: 0.4098, Average Validation Accuracy: 0.8193\n",
      "Epoch [22/200], Average Training Loss: 0.4012\n",
      "Epoch [22/200], Average Validation Loss: 0.4102, Average Validation Accuracy: 0.8220\n",
      "Epoch [23/200], Average Training Loss: 0.4001\n",
      "Epoch [23/200], Average Validation Loss: 0.4053, Average Validation Accuracy: 0.8229\n",
      "Epoch [24/200], Average Training Loss: 0.4003\n",
      "Epoch [24/200], Average Validation Loss: 0.4057, Average Validation Accuracy: 0.8244\n",
      "Epoch [25/200], Average Training Loss: 0.3994\n",
      "Epoch [25/200], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8236\n",
      "Epoch [26/200], Average Training Loss: 0.3989\n",
      "Epoch [26/200], Average Validation Loss: 0.4087, Average Validation Accuracy: 0.8220\n",
      "Epoch [27/200], Average Training Loss: 0.3983\n",
      "Epoch [27/200], Average Validation Loss: 0.4046, Average Validation Accuracy: 0.8250\n",
      "Epoch [28/200], Average Training Loss: 0.3984\n",
      "Epoch [28/200], Average Validation Loss: 0.4065, Average Validation Accuracy: 0.8229\n",
      "Epoch [29/200], Average Training Loss: 0.3972\n",
      "Epoch [29/200], Average Validation Loss: 0.4056, Average Validation Accuracy: 0.8253\n",
      "Epoch [30/200], Average Training Loss: 0.3977\n",
      "Epoch [30/200], Average Validation Loss: 0.4057, Average Validation Accuracy: 0.8233\n",
      "Epoch [31/200], Average Training Loss: 0.3969\n",
      "Epoch [31/200], Average Validation Loss: 0.4074, Average Validation Accuracy: 0.8247\n",
      "Epoch [32/200], Average Training Loss: 0.3964\n",
      "Epoch [32/200], Average Validation Loss: 0.4050, Average Validation Accuracy: 0.8242\n",
      "Epoch [33/200], Average Training Loss: 0.3957\n",
      "Epoch [33/200], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8241\n",
      "Epoch [34/200], Average Training Loss: 0.3958\n",
      "Epoch [34/200], Average Validation Loss: 0.4052, Average Validation Accuracy: 0.8246\n",
      "Epoch [35/200], Average Training Loss: 0.3948\n",
      "Epoch [35/200], Average Validation Loss: 0.4055, Average Validation Accuracy: 0.8249\n",
      "Epoch [36/200], Average Training Loss: 0.3944\n",
      "Epoch [36/200], Average Validation Loss: 0.4078, Average Validation Accuracy: 0.8250\n",
      "Epoch [37/200], Average Training Loss: 0.3944\n",
      "Epoch [37/200], Average Validation Loss: 0.4068, Average Validation Accuracy: 0.8240\n",
      "Epoch [38/200], Average Training Loss: 0.3936\n",
      "Early stopping at epoch 37. Best loss was 0.4046\n",
      "Best Validation Accuracy: 0.8253 at epoch 29 for trial 7\n",
      "Epoch [1/50], Average Training Loss: 0.6865\n",
      "Epoch [1/50], Average Validation Loss: 0.6775, Average Validation Accuracy: 0.6373\n",
      "Epoch [2/50], Average Training Loss: 0.6698\n",
      "Epoch [2/50], Average Validation Loss: 0.6617, Average Validation Accuracy: 0.7438\n",
      "Epoch [3/50], Average Training Loss: 0.6522\n",
      "Epoch [3/50], Average Validation Loss: 0.6426, Average Validation Accuracy: 0.7508\n",
      "Epoch [4/50], Average Training Loss: 0.6315\n",
      "Epoch [4/50], Average Validation Loss: 0.6204, Average Validation Accuracy: 0.7540\n",
      "Epoch [5/50], Average Training Loss: 0.6082\n",
      "Epoch [5/50], Average Validation Loss: 0.5962, Average Validation Accuracy: 0.7608\n",
      "Epoch [6/50], Average Training Loss: 0.5833\n",
      "Epoch [6/50], Average Validation Loss: 0.5714, Average Validation Accuracy: 0.7647\n",
      "Epoch [7/50], Average Training Loss: 0.5587\n",
      "Epoch [7/50], Average Validation Loss: 0.5476, Average Validation Accuracy: 0.7693\n",
      "Epoch [8/50], Average Training Loss: 0.5357\n",
      "Epoch [8/50], Average Validation Loss: 0.5258, Average Validation Accuracy: 0.7749\n",
      "Epoch [9/50], Average Training Loss: 0.5152\n",
      "Epoch [9/50], Average Validation Loss: 0.5075, Average Validation Accuracy: 0.7788\n",
      "Epoch [10/50], Average Training Loss: 0.4984\n",
      "Epoch [10/50], Average Validation Loss: 0.4927, Average Validation Accuracy: 0.7824\n",
      "Epoch [11/50], Average Training Loss: 0.4851\n",
      "Epoch [11/50], Average Validation Loss: 0.4812, Average Validation Accuracy: 0.7853\n",
      "Epoch [12/50], Average Training Loss: 0.4748\n",
      "Epoch [12/50], Average Validation Loss: 0.4729, Average Validation Accuracy: 0.7886\n",
      "Epoch [13/50], Average Training Loss: 0.4674\n",
      "Epoch [13/50], Average Validation Loss: 0.4671, Average Validation Accuracy: 0.7895\n",
      "Epoch [14/50], Average Training Loss: 0.4619\n",
      "Epoch [14/50], Average Validation Loss: 0.4631, Average Validation Accuracy: 0.7899\n",
      "Epoch [15/50], Average Training Loss: 0.4586\n",
      "Epoch [15/50], Average Validation Loss: 0.4604, Average Validation Accuracy: 0.7916\n",
      "Epoch [16/50], Average Training Loss: 0.4560\n",
      "Epoch [16/50], Average Validation Loss: 0.4585, Average Validation Accuracy: 0.7915\n",
      "Epoch [17/50], Average Training Loss: 0.4544\n",
      "Epoch [17/50], Average Validation Loss: 0.4570, Average Validation Accuracy: 0.7924\n",
      "Epoch [18/50], Average Training Loss: 0.4527\n",
      "Epoch [18/50], Average Validation Loss: 0.4557, Average Validation Accuracy: 0.7936\n",
      "Epoch [19/50], Average Training Loss: 0.4513\n",
      "Epoch [19/50], Average Validation Loss: 0.4547, Average Validation Accuracy: 0.7936\n",
      "Epoch [20/50], Average Training Loss: 0.4500\n",
      "Epoch [20/50], Average Validation Loss: 0.4536, Average Validation Accuracy: 0.7953\n",
      "Epoch [21/50], Average Training Loss: 0.4493\n",
      "Epoch [21/50], Average Validation Loss: 0.4527, Average Validation Accuracy: 0.7955\n",
      "Epoch [22/50], Average Training Loss: 0.4483\n",
      "Epoch [22/50], Average Validation Loss: 0.4518, Average Validation Accuracy: 0.7961\n",
      "Epoch [23/50], Average Training Loss: 0.4473\n",
      "Epoch [23/50], Average Validation Loss: 0.4510, Average Validation Accuracy: 0.7970\n",
      "Epoch [24/50], Average Training Loss: 0.4466\n",
      "Epoch [24/50], Average Validation Loss: 0.4502, Average Validation Accuracy: 0.7975\n",
      "Epoch [25/50], Average Training Loss: 0.4460\n",
      "Epoch [25/50], Average Validation Loss: 0.4495, Average Validation Accuracy: 0.7980\n",
      "Epoch [26/50], Average Training Loss: 0.4452\n",
      "Epoch [26/50], Average Validation Loss: 0.4488, Average Validation Accuracy: 0.7985\n",
      "Epoch [27/50], Average Training Loss: 0.4447\n",
      "Epoch [27/50], Average Validation Loss: 0.4481, Average Validation Accuracy: 0.7992\n",
      "Epoch [28/50], Average Training Loss: 0.4441\n",
      "Epoch [28/50], Average Validation Loss: 0.4476, Average Validation Accuracy: 0.7996\n",
      "Epoch [29/50], Average Training Loss: 0.4434\n",
      "Epoch [29/50], Average Validation Loss: 0.4469, Average Validation Accuracy: 0.8002\n",
      "Epoch [30/50], Average Training Loss: 0.4428\n",
      "Epoch [30/50], Average Validation Loss: 0.4464, Average Validation Accuracy: 0.8005\n",
      "Epoch [31/50], Average Training Loss: 0.4421\n",
      "Epoch [31/50], Average Validation Loss: 0.4458, Average Validation Accuracy: 0.8007\n",
      "Epoch [32/50], Average Training Loss: 0.4417\n",
      "Epoch [32/50], Average Validation Loss: 0.4453, Average Validation Accuracy: 0.8012\n",
      "Epoch [33/50], Average Training Loss: 0.4412\n",
      "Epoch [33/50], Average Validation Loss: 0.4448, Average Validation Accuracy: 0.8018\n",
      "Epoch [34/50], Average Training Loss: 0.4408\n",
      "Epoch [34/50], Average Validation Loss: 0.4444, Average Validation Accuracy: 0.8013\n",
      "Epoch [35/50], Average Training Loss: 0.4405\n",
      "Epoch [35/50], Average Validation Loss: 0.4439, Average Validation Accuracy: 0.8026\n",
      "Epoch [36/50], Average Training Loss: 0.4398\n",
      "Epoch [36/50], Average Validation Loss: 0.4434, Average Validation Accuracy: 0.8024\n",
      "Epoch [37/50], Average Training Loss: 0.4396\n",
      "Epoch [37/50], Average Validation Loss: 0.4430, Average Validation Accuracy: 0.8033\n",
      "Epoch [38/50], Average Training Loss: 0.4389\n",
      "Epoch [38/50], Average Validation Loss: 0.4426, Average Validation Accuracy: 0.8027\n",
      "Epoch [39/50], Average Training Loss: 0.4385\n",
      "Epoch [39/50], Average Validation Loss: 0.4422, Average Validation Accuracy: 0.8033\n",
      "Epoch [40/50], Average Training Loss: 0.4386\n",
      "Epoch [40/50], Average Validation Loss: 0.4419, Average Validation Accuracy: 0.8030\n",
      "Epoch [41/50], Average Training Loss: 0.4380\n",
      "Epoch [41/50], Average Validation Loss: 0.4415, Average Validation Accuracy: 0.8031\n",
      "Epoch [42/50], Average Training Loss: 0.4378\n",
      "Epoch [42/50], Average Validation Loss: 0.4412, Average Validation Accuracy: 0.8026\n",
      "Epoch [43/50], Average Training Loss: 0.4374\n",
      "Epoch [43/50], Average Validation Loss: 0.4408, Average Validation Accuracy: 0.8032\n",
      "Epoch [44/50], Average Training Loss: 0.4368\n",
      "Epoch [44/50], Average Validation Loss: 0.4405, Average Validation Accuracy: 0.8029\n",
      "Epoch [45/50], Average Training Loss: 0.4365\n",
      "Epoch [45/50], Average Validation Loss: 0.4402, Average Validation Accuracy: 0.8035\n",
      "Epoch [46/50], Average Training Loss: 0.4365\n",
      "Epoch [46/50], Average Validation Loss: 0.4399, Average Validation Accuracy: 0.8042\n",
      "Epoch [47/50], Average Training Loss: 0.4362\n",
      "Epoch [47/50], Average Validation Loss: 0.4396, Average Validation Accuracy: 0.8045\n",
      "Epoch [48/50], Average Training Loss: 0.4358\n",
      "Epoch [48/50], Average Validation Loss: 0.4394, Average Validation Accuracy: 0.8043\n",
      "Epoch [49/50], Average Training Loss: 0.4356\n",
      "Epoch [49/50], Average Validation Loss: 0.4391, Average Validation Accuracy: 0.8042\n",
      "Epoch [50/50], Average Training Loss: 0.4352\n",
      "Epoch [50/50], Average Validation Loss: 0.4388, Average Validation Accuracy: 0.8047\n",
      "Best Validation Accuracy: 0.8047 at epoch 50 for trial 8\n",
      "Epoch [1/200], Average Training Loss: 0.6910\n",
      "Epoch [1/200], Average Validation Loss: 0.6886, Average Validation Accuracy: 0.5115\n",
      "Epoch [2/200], Average Training Loss: 0.6877\n",
      "Epoch [2/200], Average Validation Loss: 0.6855, Average Validation Accuracy: 0.5496\n",
      "Epoch [3/200], Average Training Loss: 0.6846\n",
      "Epoch [3/200], Average Validation Loss: 0.6825, Average Validation Accuracy: 0.5917\n",
      "Epoch [4/200], Average Training Loss: 0.6815\n",
      "Epoch [4/200], Average Validation Loss: 0.6795, Average Validation Accuracy: 0.6238\n",
      "Epoch [5/200], Average Training Loss: 0.6784\n",
      "Epoch [5/200], Average Validation Loss: 0.6764, Average Validation Accuracy: 0.6621\n",
      "Epoch [6/200], Average Training Loss: 0.6753\n",
      "Epoch [6/200], Average Validation Loss: 0.6733, Average Validation Accuracy: 0.7001\n",
      "Epoch [7/200], Average Training Loss: 0.6721\n",
      "Epoch [7/200], Average Validation Loss: 0.6701, Average Validation Accuracy: 0.7319\n",
      "Epoch [8/200], Average Training Loss: 0.6687\n",
      "Epoch [8/200], Average Validation Loss: 0.6667, Average Validation Accuracy: 0.7454\n",
      "Epoch [9/200], Average Training Loss: 0.6652\n",
      "Epoch [9/200], Average Validation Loss: 0.6630, Average Validation Accuracy: 0.7515\n",
      "Epoch [10/200], Average Training Loss: 0.6614\n",
      "Epoch [10/200], Average Validation Loss: 0.6592, Average Validation Accuracy: 0.7551\n",
      "Epoch [11/200], Average Training Loss: 0.6574\n",
      "Epoch [11/200], Average Validation Loss: 0.6551, Average Validation Accuracy: 0.7552\n",
      "Epoch [12/200], Average Training Loss: 0.6531\n",
      "Epoch [12/200], Average Validation Loss: 0.6507, Average Validation Accuracy: 0.7547\n",
      "Epoch [13/200], Average Training Loss: 0.6486\n",
      "Epoch [13/200], Average Validation Loss: 0.6459, Average Validation Accuracy: 0.7550\n",
      "Epoch [14/200], Average Training Loss: 0.6437\n",
      "Epoch [14/200], Average Validation Loss: 0.6408, Average Validation Accuracy: 0.7548\n",
      "Epoch [15/200], Average Training Loss: 0.6384\n",
      "Epoch [15/200], Average Validation Loss: 0.6354, Average Validation Accuracy: 0.7555\n",
      "Epoch [16/200], Average Training Loss: 0.6327\n",
      "Epoch [16/200], Average Validation Loss: 0.6295, Average Validation Accuracy: 0.7557\n",
      "Epoch [17/200], Average Training Loss: 0.6267\n",
      "Epoch [17/200], Average Validation Loss: 0.6233, Average Validation Accuracy: 0.7557\n",
      "Epoch [18/200], Average Training Loss: 0.6202\n",
      "Epoch [18/200], Average Validation Loss: 0.6167, Average Validation Accuracy: 0.7557\n",
      "Epoch [19/200], Average Training Loss: 0.6135\n",
      "Epoch [19/200], Average Validation Loss: 0.6097, Average Validation Accuracy: 0.7564\n",
      "Epoch [20/200], Average Training Loss: 0.6063\n",
      "Epoch [20/200], Average Validation Loss: 0.6024, Average Validation Accuracy: 0.7564\n",
      "Epoch [21/200], Average Training Loss: 0.5989\n",
      "Epoch [21/200], Average Validation Loss: 0.5948, Average Validation Accuracy: 0.7571\n",
      "Epoch [22/200], Average Training Loss: 0.5912\n",
      "Epoch [22/200], Average Validation Loss: 0.5871, Average Validation Accuracy: 0.7577\n",
      "Epoch [23/200], Average Training Loss: 0.5832\n",
      "Epoch [23/200], Average Validation Loss: 0.5791, Average Validation Accuracy: 0.7582\n",
      "Epoch [24/200], Average Training Loss: 0.5754\n",
      "Epoch [24/200], Average Validation Loss: 0.5711, Average Validation Accuracy: 0.7588\n",
      "Epoch [25/200], Average Training Loss: 0.5672\n",
      "Epoch [25/200], Average Validation Loss: 0.5632, Average Validation Accuracy: 0.7593\n",
      "Epoch [26/200], Average Training Loss: 0.5594\n",
      "Epoch [26/200], Average Validation Loss: 0.5554, Average Validation Accuracy: 0.7603\n",
      "Epoch [27/200], Average Training Loss: 0.5517\n",
      "Epoch [27/200], Average Validation Loss: 0.5479, Average Validation Accuracy: 0.7611\n",
      "Epoch [28/200], Average Training Loss: 0.5444\n",
      "Epoch [28/200], Average Validation Loss: 0.5407, Average Validation Accuracy: 0.7621\n",
      "Epoch [29/200], Average Training Loss: 0.5372\n",
      "Epoch [29/200], Average Validation Loss: 0.5338, Average Validation Accuracy: 0.7623\n",
      "Epoch [30/200], Average Training Loss: 0.5305\n",
      "Epoch [30/200], Average Validation Loss: 0.5274, Average Validation Accuracy: 0.7632\n",
      "Epoch [31/200], Average Training Loss: 0.5244\n",
      "Epoch [31/200], Average Validation Loss: 0.5215, Average Validation Accuracy: 0.7648\n",
      "Epoch [32/200], Average Training Loss: 0.5185\n",
      "Epoch [32/200], Average Validation Loss: 0.5160, Average Validation Accuracy: 0.7666\n",
      "Epoch [33/200], Average Training Loss: 0.5133\n",
      "Epoch [33/200], Average Validation Loss: 0.5110, Average Validation Accuracy: 0.7682\n",
      "Epoch [34/200], Average Training Loss: 0.5084\n",
      "Epoch [34/200], Average Validation Loss: 0.5064, Average Validation Accuracy: 0.7696\n",
      "Epoch [35/200], Average Training Loss: 0.5040\n",
      "Epoch [35/200], Average Validation Loss: 0.5022, Average Validation Accuracy: 0.7711\n",
      "Epoch [36/200], Average Training Loss: 0.4997\n",
      "Epoch [36/200], Average Validation Loss: 0.4984, Average Validation Accuracy: 0.7720\n",
      "Epoch [37/200], Average Training Loss: 0.4962\n",
      "Epoch [37/200], Average Validation Loss: 0.4950, Average Validation Accuracy: 0.7726\n",
      "Epoch [38/200], Average Training Loss: 0.4927\n",
      "Epoch [38/200], Average Validation Loss: 0.4919, Average Validation Accuracy: 0.7738\n",
      "Epoch [39/200], Average Training Loss: 0.4898\n",
      "Epoch [39/200], Average Validation Loss: 0.4891, Average Validation Accuracy: 0.7752\n",
      "Epoch [40/200], Average Training Loss: 0.4869\n",
      "Epoch [40/200], Average Validation Loss: 0.4865, Average Validation Accuracy: 0.7763\n",
      "Epoch [41/200], Average Training Loss: 0.4844\n",
      "Epoch [41/200], Average Validation Loss: 0.4842, Average Validation Accuracy: 0.7779\n",
      "Epoch [42/200], Average Training Loss: 0.4822\n",
      "Epoch [42/200], Average Validation Loss: 0.4821, Average Validation Accuracy: 0.7800\n",
      "Epoch [43/200], Average Training Loss: 0.4800\n",
      "Epoch [43/200], Average Validation Loss: 0.4802, Average Validation Accuracy: 0.7814\n",
      "Epoch [44/200], Average Training Loss: 0.4780\n",
      "Epoch [44/200], Average Validation Loss: 0.4785, Average Validation Accuracy: 0.7820\n",
      "Epoch [45/200], Average Training Loss: 0.4766\n",
      "Epoch [45/200], Average Validation Loss: 0.4769, Average Validation Accuracy: 0.7827\n",
      "Epoch [46/200], Average Training Loss: 0.4749\n",
      "Epoch [46/200], Average Validation Loss: 0.4755, Average Validation Accuracy: 0.7836\n",
      "Epoch [47/200], Average Training Loss: 0.4733\n",
      "Epoch [47/200], Average Validation Loss: 0.4741, Average Validation Accuracy: 0.7845\n",
      "Epoch [48/200], Average Training Loss: 0.4719\n",
      "Epoch [48/200], Average Validation Loss: 0.4729, Average Validation Accuracy: 0.7854\n",
      "Epoch [49/200], Average Training Loss: 0.4707\n",
      "Epoch [49/200], Average Validation Loss: 0.4718, Average Validation Accuracy: 0.7866\n",
      "Epoch [50/200], Average Training Loss: 0.4696\n",
      "Epoch [50/200], Average Validation Loss: 0.4708, Average Validation Accuracy: 0.7872\n",
      "Epoch [51/200], Average Training Loss: 0.4687\n",
      "Epoch [51/200], Average Validation Loss: 0.4698, Average Validation Accuracy: 0.7873\n",
      "Epoch [52/200], Average Training Loss: 0.4674\n",
      "Epoch [52/200], Average Validation Loss: 0.4690, Average Validation Accuracy: 0.7865\n",
      "Epoch [53/200], Average Training Loss: 0.4669\n",
      "Epoch [53/200], Average Validation Loss: 0.4682, Average Validation Accuracy: 0.7871\n",
      "Epoch [54/200], Average Training Loss: 0.4657\n",
      "Epoch [54/200], Average Validation Loss: 0.4674, Average Validation Accuracy: 0.7874\n",
      "Epoch [55/200], Average Training Loss: 0.4653\n",
      "Epoch [55/200], Average Validation Loss: 0.4667, Average Validation Accuracy: 0.7882\n",
      "Epoch [56/200], Average Training Loss: 0.4642\n",
      "Epoch [56/200], Average Validation Loss: 0.4661, Average Validation Accuracy: 0.7888\n",
      "Epoch [57/200], Average Training Loss: 0.4635\n",
      "Epoch [57/200], Average Validation Loss: 0.4655, Average Validation Accuracy: 0.7890\n",
      "Epoch [58/200], Average Training Loss: 0.4627\n",
      "Epoch [58/200], Average Validation Loss: 0.4649, Average Validation Accuracy: 0.7891\n",
      "Epoch [59/200], Average Training Loss: 0.4621\n",
      "Epoch [59/200], Average Validation Loss: 0.4644, Average Validation Accuracy: 0.7892\n",
      "Epoch [60/200], Average Training Loss: 0.4615\n",
      "Epoch [60/200], Average Validation Loss: 0.4639, Average Validation Accuracy: 0.7894\n",
      "Epoch [61/200], Average Training Loss: 0.4612\n",
      "Epoch [61/200], Average Validation Loss: 0.4634, Average Validation Accuracy: 0.7893\n",
      "Epoch [62/200], Average Training Loss: 0.4605\n",
      "Epoch [62/200], Average Validation Loss: 0.4629, Average Validation Accuracy: 0.7896\n",
      "Epoch [63/200], Average Training Loss: 0.4601\n",
      "Epoch [63/200], Average Validation Loss: 0.4625, Average Validation Accuracy: 0.7893\n",
      "Epoch [64/200], Average Training Loss: 0.4597\n",
      "Epoch [64/200], Average Validation Loss: 0.4621, Average Validation Accuracy: 0.7894\n",
      "Epoch [65/200], Average Training Loss: 0.4591\n",
      "Epoch [65/200], Average Validation Loss: 0.4617, Average Validation Accuracy: 0.7892\n",
      "Epoch [66/200], Average Training Loss: 0.4590\n",
      "Epoch [66/200], Average Validation Loss: 0.4613, Average Validation Accuracy: 0.7894\n",
      "Epoch [67/200], Average Training Loss: 0.4583\n",
      "Epoch [67/200], Average Validation Loss: 0.4610, Average Validation Accuracy: 0.7890\n",
      "Epoch [68/200], Average Training Loss: 0.4578\n",
      "Epoch [68/200], Average Validation Loss: 0.4607, Average Validation Accuracy: 0.7891\n",
      "Epoch [69/200], Average Training Loss: 0.4575\n",
      "Epoch [69/200], Average Validation Loss: 0.4603, Average Validation Accuracy: 0.7891\n",
      "Epoch [70/200], Average Training Loss: 0.4573\n",
      "Epoch [70/200], Average Validation Loss: 0.4600, Average Validation Accuracy: 0.7894\n",
      "Epoch [71/200], Average Training Loss: 0.4568\n",
      "Epoch [71/200], Average Validation Loss: 0.4597, Average Validation Accuracy: 0.7894\n",
      "Epoch [72/200], Average Training Loss: 0.4565\n",
      "Epoch [72/200], Average Validation Loss: 0.4595, Average Validation Accuracy: 0.7899\n",
      "Epoch [73/200], Average Training Loss: 0.4562\n",
      "Epoch [73/200], Average Validation Loss: 0.4592, Average Validation Accuracy: 0.7899\n",
      "Epoch [74/200], Average Training Loss: 0.4558\n",
      "Epoch [74/200], Average Validation Loss: 0.4589, Average Validation Accuracy: 0.7901\n",
      "Epoch [75/200], Average Training Loss: 0.4556\n",
      "Epoch [75/200], Average Validation Loss: 0.4586, Average Validation Accuracy: 0.7904\n",
      "Epoch [76/200], Average Training Loss: 0.4554\n",
      "Epoch [76/200], Average Validation Loss: 0.4584, Average Validation Accuracy: 0.7904\n",
      "Epoch [77/200], Average Training Loss: 0.4548\n",
      "Epoch [77/200], Average Validation Loss: 0.4581, Average Validation Accuracy: 0.7909\n",
      "Epoch [78/200], Average Training Loss: 0.4549\n",
      "Epoch [78/200], Average Validation Loss: 0.4579, Average Validation Accuracy: 0.7913\n",
      "Epoch [79/200], Average Training Loss: 0.4545\n",
      "Epoch [79/200], Average Validation Loss: 0.4577, Average Validation Accuracy: 0.7911\n",
      "Epoch [80/200], Average Training Loss: 0.4542\n",
      "Epoch [80/200], Average Validation Loss: 0.4574, Average Validation Accuracy: 0.7915\n",
      "Epoch [81/200], Average Training Loss: 0.4538\n",
      "Epoch [81/200], Average Validation Loss: 0.4572, Average Validation Accuracy: 0.7915\n",
      "Epoch [82/200], Average Training Loss: 0.4536\n",
      "Epoch [82/200], Average Validation Loss: 0.4570, Average Validation Accuracy: 0.7917\n",
      "Epoch [83/200], Average Training Loss: 0.4535\n",
      "Epoch [83/200], Average Validation Loss: 0.4568, Average Validation Accuracy: 0.7919\n",
      "Epoch [84/200], Average Training Loss: 0.4531\n",
      "Epoch [84/200], Average Validation Loss: 0.4566, Average Validation Accuracy: 0.7922\n",
      "Epoch [85/200], Average Training Loss: 0.4529\n",
      "Epoch [85/200], Average Validation Loss: 0.4564, Average Validation Accuracy: 0.7923\n",
      "Epoch [86/200], Average Training Loss: 0.4526\n",
      "Epoch [86/200], Average Validation Loss: 0.4562, Average Validation Accuracy: 0.7926\n",
      "Epoch [87/200], Average Training Loss: 0.4522\n",
      "Epoch [87/200], Average Validation Loss: 0.4560, Average Validation Accuracy: 0.7924\n",
      "Epoch [88/200], Average Training Loss: 0.4523\n",
      "Epoch [88/200], Average Validation Loss: 0.4558, Average Validation Accuracy: 0.7924\n",
      "Epoch [89/200], Average Training Loss: 0.4521\n",
      "Epoch [89/200], Average Validation Loss: 0.4556, Average Validation Accuracy: 0.7926\n",
      "Epoch [90/200], Average Training Loss: 0.4519\n",
      "Epoch [90/200], Average Validation Loss: 0.4554, Average Validation Accuracy: 0.7926\n",
      "Epoch [91/200], Average Training Loss: 0.4515\n",
      "Epoch [91/200], Average Validation Loss: 0.4552, Average Validation Accuracy: 0.7930\n",
      "Epoch [92/200], Average Training Loss: 0.4515\n",
      "Epoch [92/200], Average Validation Loss: 0.4550, Average Validation Accuracy: 0.7932\n",
      "Epoch [93/200], Average Training Loss: 0.4513\n",
      "Epoch [93/200], Average Validation Loss: 0.4548, Average Validation Accuracy: 0.7933\n",
      "Epoch [94/200], Average Training Loss: 0.4509\n",
      "Epoch [94/200], Average Validation Loss: 0.4547, Average Validation Accuracy: 0.7933\n",
      "Epoch [95/200], Average Training Loss: 0.4509\n",
      "Epoch [95/200], Average Validation Loss: 0.4545, Average Validation Accuracy: 0.7934\n",
      "Epoch [96/200], Average Training Loss: 0.4506\n",
      "Epoch [96/200], Average Validation Loss: 0.4543, Average Validation Accuracy: 0.7934\n",
      "Epoch [97/200], Average Training Loss: 0.4505\n",
      "Epoch [97/200], Average Validation Loss: 0.4542, Average Validation Accuracy: 0.7936\n",
      "Epoch [98/200], Average Training Loss: 0.4505\n",
      "Epoch [98/200], Average Validation Loss: 0.4540, Average Validation Accuracy: 0.7933\n",
      "Epoch [99/200], Average Training Loss: 0.4504\n",
      "Epoch [99/200], Average Validation Loss: 0.4538, Average Validation Accuracy: 0.7934\n",
      "Epoch [100/200], Average Training Loss: 0.4501\n",
      "Epoch [100/200], Average Validation Loss: 0.4537, Average Validation Accuracy: 0.7936\n",
      "Epoch [101/200], Average Training Loss: 0.4498\n",
      "Epoch [101/200], Average Validation Loss: 0.4535, Average Validation Accuracy: 0.7937\n",
      "Epoch [102/200], Average Training Loss: 0.4497\n",
      "Epoch [102/200], Average Validation Loss: 0.4534, Average Validation Accuracy: 0.7935\n",
      "Epoch [103/200], Average Training Loss: 0.4498\n",
      "Epoch [103/200], Average Validation Loss: 0.4532, Average Validation Accuracy: 0.7937\n",
      "Epoch [104/200], Average Training Loss: 0.4492\n",
      "Epoch [104/200], Average Validation Loss: 0.4531, Average Validation Accuracy: 0.7937\n",
      "Epoch [105/200], Average Training Loss: 0.4492\n",
      "Epoch [105/200], Average Validation Loss: 0.4529, Average Validation Accuracy: 0.7937\n",
      "Epoch [106/200], Average Training Loss: 0.4492\n",
      "Epoch [106/200], Average Validation Loss: 0.4527, Average Validation Accuracy: 0.7938\n",
      "Epoch [107/200], Average Training Loss: 0.4486\n",
      "Epoch [107/200], Average Validation Loss: 0.4526, Average Validation Accuracy: 0.7940\n",
      "Epoch [108/200], Average Training Loss: 0.4487\n",
      "Epoch [108/200], Average Validation Loss: 0.4524, Average Validation Accuracy: 0.7947\n",
      "Epoch [109/200], Average Training Loss: 0.4486\n",
      "Epoch [109/200], Average Validation Loss: 0.4523, Average Validation Accuracy: 0.7943\n",
      "Epoch [110/200], Average Training Loss: 0.4483\n",
      "Epoch [110/200], Average Validation Loss: 0.4521, Average Validation Accuracy: 0.7945\n",
      "Epoch [111/200], Average Training Loss: 0.4486\n",
      "Epoch [111/200], Average Validation Loss: 0.4520, Average Validation Accuracy: 0.7947\n",
      "Epoch [112/200], Average Training Loss: 0.4480\n",
      "Epoch [112/200], Average Validation Loss: 0.4519, Average Validation Accuracy: 0.7948\n",
      "Epoch [113/200], Average Training Loss: 0.4479\n",
      "Epoch [113/200], Average Validation Loss: 0.4517, Average Validation Accuracy: 0.7950\n",
      "Epoch [114/200], Average Training Loss: 0.4479\n",
      "Epoch [114/200], Average Validation Loss: 0.4516, Average Validation Accuracy: 0.7953\n",
      "Epoch [115/200], Average Training Loss: 0.4477\n",
      "Epoch [115/200], Average Validation Loss: 0.4514, Average Validation Accuracy: 0.7957\n",
      "Epoch [116/200], Average Training Loss: 0.4474\n",
      "Epoch [116/200], Average Validation Loss: 0.4513, Average Validation Accuracy: 0.7957\n",
      "Epoch [117/200], Average Training Loss: 0.4474\n",
      "Epoch [117/200], Average Validation Loss: 0.4512, Average Validation Accuracy: 0.7960\n",
      "Epoch [118/200], Average Training Loss: 0.4472\n",
      "Epoch [118/200], Average Validation Loss: 0.4510, Average Validation Accuracy: 0.7961\n",
      "Epoch [119/200], Average Training Loss: 0.4471\n",
      "Epoch [119/200], Average Validation Loss: 0.4509, Average Validation Accuracy: 0.7964\n",
      "Epoch [120/200], Average Training Loss: 0.4471\n",
      "Epoch [120/200], Average Validation Loss: 0.4508, Average Validation Accuracy: 0.7964\n",
      "Epoch [121/200], Average Training Loss: 0.4469\n",
      "Epoch [121/200], Average Validation Loss: 0.4506, Average Validation Accuracy: 0.7966\n",
      "Epoch [122/200], Average Training Loss: 0.4471\n",
      "Epoch [122/200], Average Validation Loss: 0.4505, Average Validation Accuracy: 0.7966\n",
      "Epoch [123/200], Average Training Loss: 0.4466\n",
      "Epoch [123/200], Average Validation Loss: 0.4504, Average Validation Accuracy: 0.7968\n",
      "Epoch [124/200], Average Training Loss: 0.4464\n",
      "Epoch [124/200], Average Validation Loss: 0.4502, Average Validation Accuracy: 0.7967\n",
      "Epoch [125/200], Average Training Loss: 0.4463\n",
      "Epoch [125/200], Average Validation Loss: 0.4501, Average Validation Accuracy: 0.7971\n",
      "Epoch [126/200], Average Training Loss: 0.4462\n",
      "Epoch [126/200], Average Validation Loss: 0.4500, Average Validation Accuracy: 0.7974\n",
      "Epoch [127/200], Average Training Loss: 0.4462\n",
      "Epoch [127/200], Average Validation Loss: 0.4499, Average Validation Accuracy: 0.7970\n",
      "Epoch [128/200], Average Training Loss: 0.4461\n",
      "Epoch [128/200], Average Validation Loss: 0.4497, Average Validation Accuracy: 0.7970\n",
      "Epoch [129/200], Average Training Loss: 0.4457\n",
      "Epoch [129/200], Average Validation Loss: 0.4496, Average Validation Accuracy: 0.7976\n",
      "Epoch [130/200], Average Training Loss: 0.4455\n",
      "Epoch [130/200], Average Validation Loss: 0.4495, Average Validation Accuracy: 0.7974\n",
      "Epoch [131/200], Average Training Loss: 0.4458\n",
      "Epoch [131/200], Average Validation Loss: 0.4493, Average Validation Accuracy: 0.7974\n",
      "Epoch [132/200], Average Training Loss: 0.4457\n",
      "Epoch [132/200], Average Validation Loss: 0.4492, Average Validation Accuracy: 0.7974\n",
      "Epoch [133/200], Average Training Loss: 0.4455\n",
      "Epoch [133/200], Average Validation Loss: 0.4491, Average Validation Accuracy: 0.7974\n",
      "Epoch [134/200], Average Training Loss: 0.4451\n",
      "Epoch [134/200], Average Validation Loss: 0.4490, Average Validation Accuracy: 0.7974\n",
      "Epoch [135/200], Average Training Loss: 0.4449\n",
      "Epoch [135/200], Average Validation Loss: 0.4489, Average Validation Accuracy: 0.7974\n",
      "Epoch [136/200], Average Training Loss: 0.4449\n",
      "Epoch [136/200], Average Validation Loss: 0.4488, Average Validation Accuracy: 0.7974\n",
      "Epoch [137/200], Average Training Loss: 0.4447\n",
      "Epoch [137/200], Average Validation Loss: 0.4486, Average Validation Accuracy: 0.7978\n",
      "Epoch [138/200], Average Training Loss: 0.4446\n",
      "Epoch [138/200], Average Validation Loss: 0.4485, Average Validation Accuracy: 0.7978\n",
      "Epoch [139/200], Average Training Loss: 0.4447\n",
      "Epoch [139/200], Average Validation Loss: 0.4484, Average Validation Accuracy: 0.7978\n",
      "Epoch [140/200], Average Training Loss: 0.4444\n",
      "Epoch [140/200], Average Validation Loss: 0.4483, Average Validation Accuracy: 0.7977\n",
      "Epoch [141/200], Average Training Loss: 0.4444\n",
      "Epoch [141/200], Average Validation Loss: 0.4482, Average Validation Accuracy: 0.7975\n",
      "Epoch [142/200], Average Training Loss: 0.4441\n",
      "Epoch [142/200], Average Validation Loss: 0.4481, Average Validation Accuracy: 0.7980\n",
      "Epoch [143/200], Average Training Loss: 0.4441\n",
      "Epoch [143/200], Average Validation Loss: 0.4479, Average Validation Accuracy: 0.7981\n",
      "Epoch [144/200], Average Training Loss: 0.4441\n",
      "Epoch [144/200], Average Validation Loss: 0.4478, Average Validation Accuracy: 0.7981\n",
      "Epoch [145/200], Average Training Loss: 0.4440\n",
      "Epoch [145/200], Average Validation Loss: 0.4477, Average Validation Accuracy: 0.7982\n",
      "Epoch [146/200], Average Training Loss: 0.4437\n",
      "Epoch [146/200], Average Validation Loss: 0.4476, Average Validation Accuracy: 0.7988\n",
      "Epoch [147/200], Average Training Loss: 0.4438\n",
      "Epoch [147/200], Average Validation Loss: 0.4475, Average Validation Accuracy: 0.7983\n",
      "Epoch [148/200], Average Training Loss: 0.4434\n",
      "Epoch [148/200], Average Validation Loss: 0.4474, Average Validation Accuracy: 0.7990\n",
      "Epoch [149/200], Average Training Loss: 0.4433\n",
      "Epoch [149/200], Average Validation Loss: 0.4473, Average Validation Accuracy: 0.7991\n",
      "Epoch [150/200], Average Training Loss: 0.4433\n",
      "Epoch [150/200], Average Validation Loss: 0.4472, Average Validation Accuracy: 0.7990\n",
      "Epoch [151/200], Average Training Loss: 0.4431\n",
      "Epoch [151/200], Average Validation Loss: 0.4471, Average Validation Accuracy: 0.7995\n",
      "Epoch [152/200], Average Training Loss: 0.4429\n",
      "Epoch [152/200], Average Validation Loss: 0.4470, Average Validation Accuracy: 0.7993\n",
      "Epoch [153/200], Average Training Loss: 0.4433\n",
      "Epoch [153/200], Average Validation Loss: 0.4468, Average Validation Accuracy: 0.7994\n",
      "Epoch [154/200], Average Training Loss: 0.4428\n",
      "Epoch [154/200], Average Validation Loss: 0.4467, Average Validation Accuracy: 0.7994\n",
      "Epoch [155/200], Average Training Loss: 0.4427\n",
      "Epoch [155/200], Average Validation Loss: 0.4467, Average Validation Accuracy: 0.7995\n",
      "Epoch [156/200], Average Training Loss: 0.4426\n",
      "Epoch [156/200], Average Validation Loss: 0.4465, Average Validation Accuracy: 0.7995\n",
      "Epoch [157/200], Average Training Loss: 0.4428\n",
      "Epoch [157/200], Average Validation Loss: 0.4464, Average Validation Accuracy: 0.7998\n",
      "Epoch [158/200], Average Training Loss: 0.4425\n",
      "Epoch [158/200], Average Validation Loss: 0.4463, Average Validation Accuracy: 0.7999\n",
      "Epoch [159/200], Average Training Loss: 0.4422\n",
      "Epoch [159/200], Average Validation Loss: 0.4462, Average Validation Accuracy: 0.7999\n",
      "Epoch [160/200], Average Training Loss: 0.4421\n",
      "Epoch [160/200], Average Validation Loss: 0.4461, Average Validation Accuracy: 0.8000\n",
      "Epoch [161/200], Average Training Loss: 0.4423\n",
      "Epoch [161/200], Average Validation Loss: 0.4460, Average Validation Accuracy: 0.8001\n",
      "Epoch [162/200], Average Training Loss: 0.4422\n",
      "Epoch [162/200], Average Validation Loss: 0.4459, Average Validation Accuracy: 0.8002\n",
      "Epoch [163/200], Average Training Loss: 0.4420\n",
      "Epoch [163/200], Average Validation Loss: 0.4458, Average Validation Accuracy: 0.8005\n",
      "Epoch [164/200], Average Training Loss: 0.4422\n",
      "Epoch [164/200], Average Validation Loss: 0.4457, Average Validation Accuracy: 0.8005\n",
      "Epoch [165/200], Average Training Loss: 0.4422\n",
      "Epoch [165/200], Average Validation Loss: 0.4456, Average Validation Accuracy: 0.8008\n",
      "Epoch [166/200], Average Training Loss: 0.4414\n",
      "Epoch [166/200], Average Validation Loss: 0.4455, Average Validation Accuracy: 0.8007\n",
      "Epoch [167/200], Average Training Loss: 0.4417\n",
      "Epoch [167/200], Average Validation Loss: 0.4454, Average Validation Accuracy: 0.8007\n",
      "Epoch [168/200], Average Training Loss: 0.4418\n",
      "Epoch [168/200], Average Validation Loss: 0.4453, Average Validation Accuracy: 0.8008\n",
      "Epoch [169/200], Average Training Loss: 0.4414\n",
      "Epoch [169/200], Average Validation Loss: 0.4452, Average Validation Accuracy: 0.8012\n",
      "Epoch [170/200], Average Training Loss: 0.4413\n",
      "Epoch [170/200], Average Validation Loss: 0.4452, Average Validation Accuracy: 0.8008\n",
      "Epoch [171/200], Average Training Loss: 0.4414\n",
      "Epoch [171/200], Average Validation Loss: 0.4451, Average Validation Accuracy: 0.8011\n",
      "Epoch [172/200], Average Training Loss: 0.4411\n",
      "Epoch [172/200], Average Validation Loss: 0.4450, Average Validation Accuracy: 0.8013\n",
      "Epoch [173/200], Average Training Loss: 0.4412\n",
      "Epoch [173/200], Average Validation Loss: 0.4449, Average Validation Accuracy: 0.8014\n",
      "Epoch [174/200], Average Training Loss: 0.4412\n",
      "Epoch [174/200], Average Validation Loss: 0.4448, Average Validation Accuracy: 0.8015\n",
      "Epoch [175/200], Average Training Loss: 0.4411\n",
      "Epoch [175/200], Average Validation Loss: 0.4447, Average Validation Accuracy: 0.8015\n",
      "Epoch [176/200], Average Training Loss: 0.4408\n",
      "Epoch [176/200], Average Validation Loss: 0.4446, Average Validation Accuracy: 0.8013\n",
      "Epoch [177/200], Average Training Loss: 0.4408\n",
      "Epoch [177/200], Average Validation Loss: 0.4445, Average Validation Accuracy: 0.8015\n",
      "Epoch [178/200], Average Training Loss: 0.4407\n",
      "Epoch [178/200], Average Validation Loss: 0.4444, Average Validation Accuracy: 0.8014\n",
      "Epoch [179/200], Average Training Loss: 0.4404\n",
      "Epoch [179/200], Average Validation Loss: 0.4443, Average Validation Accuracy: 0.8016\n",
      "Epoch [180/200], Average Training Loss: 0.4405\n",
      "Epoch [180/200], Average Validation Loss: 0.4442, Average Validation Accuracy: 0.8015\n",
      "Epoch [181/200], Average Training Loss: 0.4405\n",
      "Epoch [181/200], Average Validation Loss: 0.4442, Average Validation Accuracy: 0.8014\n",
      "Epoch [182/200], Average Training Loss: 0.4405\n",
      "Epoch [182/200], Average Validation Loss: 0.4441, Average Validation Accuracy: 0.8015\n",
      "Epoch [183/200], Average Training Loss: 0.4403\n",
      "Epoch [183/200], Average Validation Loss: 0.4440, Average Validation Accuracy: 0.8014\n",
      "Epoch [184/200], Average Training Loss: 0.4401\n",
      "Epoch [184/200], Average Validation Loss: 0.4439, Average Validation Accuracy: 0.8013\n",
      "Epoch [185/200], Average Training Loss: 0.4399\n",
      "Epoch [185/200], Average Validation Loss: 0.4438, Average Validation Accuracy: 0.8017\n",
      "Epoch [186/200], Average Training Loss: 0.4401\n",
      "Epoch [186/200], Average Validation Loss: 0.4437, Average Validation Accuracy: 0.8014\n",
      "Epoch [187/200], Average Training Loss: 0.4398\n",
      "Epoch [187/200], Average Validation Loss: 0.4436, Average Validation Accuracy: 0.8018\n",
      "Epoch [188/200], Average Training Loss: 0.4394\n",
      "Epoch [188/200], Average Validation Loss: 0.4436, Average Validation Accuracy: 0.8015\n",
      "Epoch [189/200], Average Training Loss: 0.4397\n",
      "Epoch [189/200], Average Validation Loss: 0.4435, Average Validation Accuracy: 0.8020\n",
      "Epoch [190/200], Average Training Loss: 0.4396\n",
      "Epoch [190/200], Average Validation Loss: 0.4434, Average Validation Accuracy: 0.8022\n",
      "Epoch [191/200], Average Training Loss: 0.4396\n",
      "Epoch [191/200], Average Validation Loss: 0.4433, Average Validation Accuracy: 0.8014\n",
      "Epoch [192/200], Average Training Loss: 0.4396\n",
      "Epoch [192/200], Average Validation Loss: 0.4432, Average Validation Accuracy: 0.8024\n",
      "Epoch [193/200], Average Training Loss: 0.4397\n",
      "Epoch [193/200], Average Validation Loss: 0.4431, Average Validation Accuracy: 0.8020\n",
      "Epoch [194/200], Average Training Loss: 0.4394\n",
      "Epoch [194/200], Average Validation Loss: 0.4430, Average Validation Accuracy: 0.8023\n",
      "Epoch [195/200], Average Training Loss: 0.4391\n",
      "Epoch [195/200], Average Validation Loss: 0.4430, Average Validation Accuracy: 0.8023\n",
      "Epoch [196/200], Average Training Loss: 0.4393\n",
      "Epoch [196/200], Average Validation Loss: 0.4429, Average Validation Accuracy: 0.8023\n",
      "Epoch [197/200], Average Training Loss: 0.4391\n",
      "Epoch [197/200], Average Validation Loss: 0.4428, Average Validation Accuracy: 0.8028\n",
      "Epoch [198/200], Average Training Loss: 0.4391\n",
      "Epoch [198/200], Average Validation Loss: 0.4427, Average Validation Accuracy: 0.8025\n",
      "Epoch [199/200], Average Training Loss: 0.4389\n",
      "Epoch [199/200], Average Validation Loss: 0.4427, Average Validation Accuracy: 0.8027\n",
      "Epoch [200/200], Average Training Loss: 0.4388\n",
      "Epoch [200/200], Average Validation Loss: 0.4426, Average Validation Accuracy: 0.8027\n",
      "Best Validation Accuracy: 0.8028 at epoch 197 for trial 9\n",
      "Epoch [1/500], Average Training Loss: 0.4517\n",
      "Epoch [1/500], Average Validation Loss: 0.4353, Average Validation Accuracy: 0.8106\n",
      "Epoch [2/500], Average Training Loss: 0.4287\n",
      "Epoch [2/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8093\n",
      "Epoch [3/500], Average Training Loss: 0.4248\n",
      "Epoch [3/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8132\n",
      "Epoch [4/500], Average Training Loss: 0.4223\n",
      "Epoch [4/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8133\n",
      "Epoch [5/500], Average Training Loss: 0.4186\n",
      "Epoch [5/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8145\n",
      "Epoch [6/500], Average Training Loss: 0.4162\n",
      "Epoch [6/500], Average Validation Loss: 0.4209, Average Validation Accuracy: 0.8144\n",
      "Epoch [7/500], Average Training Loss: 0.4145\n",
      "Epoch [7/500], Average Validation Loss: 0.4154, Average Validation Accuracy: 0.8185\n",
      "Epoch [8/500], Average Training Loss: 0.4130\n",
      "Epoch [8/500], Average Validation Loss: 0.4141, Average Validation Accuracy: 0.8189\n",
      "Epoch [9/500], Average Training Loss: 0.4118\n",
      "Epoch [9/500], Average Validation Loss: 0.4183, Average Validation Accuracy: 0.8175\n",
      "Epoch [10/500], Average Training Loss: 0.4101\n",
      "Epoch [10/500], Average Validation Loss: 0.4145, Average Validation Accuracy: 0.8194\n",
      "Epoch [11/500], Average Training Loss: 0.4096\n",
      "Epoch [11/500], Average Validation Loss: 0.4155, Average Validation Accuracy: 0.8177\n",
      "Epoch [12/500], Average Training Loss: 0.4086\n",
      "Epoch [12/500], Average Validation Loss: 0.4111, Average Validation Accuracy: 0.8213\n",
      "Epoch [13/500], Average Training Loss: 0.4080\n",
      "Epoch [13/500], Average Validation Loss: 0.4124, Average Validation Accuracy: 0.8215\n",
      "Epoch [14/500], Average Training Loss: 0.4068\n",
      "Epoch [14/500], Average Validation Loss: 0.4105, Average Validation Accuracy: 0.8217\n",
      "Epoch [15/500], Average Training Loss: 0.4065\n",
      "Epoch [15/500], Average Validation Loss: 0.4086, Average Validation Accuracy: 0.8242\n",
      "Epoch [16/500], Average Training Loss: 0.4053\n",
      "Epoch [16/500], Average Validation Loss: 0.4118, Average Validation Accuracy: 0.8214\n",
      "Epoch [17/500], Average Training Loss: 0.4049\n",
      "Epoch [17/500], Average Validation Loss: 0.4089, Average Validation Accuracy: 0.8223\n",
      "Epoch [18/500], Average Training Loss: 0.4044\n",
      "Epoch [18/500], Average Validation Loss: 0.4085, Average Validation Accuracy: 0.8216\n",
      "Epoch [19/500], Average Training Loss: 0.4042\n",
      "Epoch [19/500], Average Validation Loss: 0.4137, Average Validation Accuracy: 0.8200\n",
      "Epoch [20/500], Average Training Loss: 0.4039\n",
      "Epoch [20/500], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8230\n",
      "Epoch [21/500], Average Training Loss: 0.4036\n",
      "Epoch [21/500], Average Validation Loss: 0.4077, Average Validation Accuracy: 0.8244\n",
      "Epoch [22/500], Average Training Loss: 0.4027\n",
      "Epoch [22/500], Average Validation Loss: 0.4078, Average Validation Accuracy: 0.8245\n",
      "Epoch [23/500], Average Training Loss: 0.4023\n",
      "Epoch [23/500], Average Validation Loss: 0.4182, Average Validation Accuracy: 0.8148\n",
      "Epoch [24/500], Average Training Loss: 0.4025\n",
      "Epoch [24/500], Average Validation Loss: 0.4067, Average Validation Accuracy: 0.8236\n",
      "Epoch [25/500], Average Training Loss: 0.4016\n",
      "Epoch [25/500], Average Validation Loss: 0.4062, Average Validation Accuracy: 0.8236\n",
      "Epoch [26/500], Average Training Loss: 0.4012\n",
      "Epoch [26/500], Average Validation Loss: 0.4114, Average Validation Accuracy: 0.8210\n",
      "Epoch [27/500], Average Training Loss: 0.4010\n",
      "Epoch [27/500], Average Validation Loss: 0.4095, Average Validation Accuracy: 0.8233\n",
      "Epoch [28/500], Average Training Loss: 0.3998\n",
      "Epoch [28/500], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8233\n",
      "Epoch [29/500], Average Training Loss: 0.3999\n",
      "Epoch [29/500], Average Validation Loss: 0.4059, Average Validation Accuracy: 0.8251\n",
      "Epoch [30/500], Average Training Loss: 0.3995\n",
      "Epoch [30/500], Average Validation Loss: 0.4055, Average Validation Accuracy: 0.8232\n",
      "Epoch [31/500], Average Training Loss: 0.3992\n",
      "Epoch [31/500], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8234\n",
      "Epoch [32/500], Average Training Loss: 0.3988\n",
      "Epoch [32/500], Average Validation Loss: 0.4067, Average Validation Accuracy: 0.8232\n",
      "Epoch [33/500], Average Training Loss: 0.3983\n",
      "Epoch [33/500], Average Validation Loss: 0.4052, Average Validation Accuracy: 0.8260\n",
      "Epoch [34/500], Average Training Loss: 0.3979\n",
      "Epoch [34/500], Average Validation Loss: 0.4071, Average Validation Accuracy: 0.8213\n",
      "Epoch [35/500], Average Training Loss: 0.3973\n",
      "Epoch [35/500], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8247\n",
      "Epoch [36/500], Average Training Loss: 0.3976\n",
      "Epoch [36/500], Average Validation Loss: 0.4096, Average Validation Accuracy: 0.8192\n",
      "Epoch [37/500], Average Training Loss: 0.3971\n",
      "Epoch [37/500], Average Validation Loss: 0.4048, Average Validation Accuracy: 0.8256\n",
      "Epoch [38/500], Average Training Loss: 0.3964\n",
      "Epoch [38/500], Average Validation Loss: 0.4048, Average Validation Accuracy: 0.8242\n",
      "Epoch [39/500], Average Training Loss: 0.3964\n",
      "Epoch [39/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8246\n",
      "Epoch [40/500], Average Training Loss: 0.3958\n",
      "Epoch [40/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8248\n",
      "Epoch [41/500], Average Training Loss: 0.3961\n",
      "Epoch [41/500], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8260\n",
      "Epoch [42/500], Average Training Loss: 0.3950\n",
      "Epoch [42/500], Average Validation Loss: 0.4077, Average Validation Accuracy: 0.8219\n",
      "Epoch [43/500], Average Training Loss: 0.3944\n",
      "Epoch [43/500], Average Validation Loss: 0.4078, Average Validation Accuracy: 0.8233\n",
      "Epoch [44/500], Average Training Loss: 0.3941\n",
      "Epoch [44/500], Average Validation Loss: 0.4078, Average Validation Accuracy: 0.8244\n",
      "Epoch [45/500], Average Training Loss: 0.3940\n",
      "Epoch [45/500], Average Validation Loss: 0.4059, Average Validation Accuracy: 0.8235\n",
      "Epoch [46/500], Average Training Loss: 0.3940\n",
      "Epoch [46/500], Average Validation Loss: 0.4060, Average Validation Accuracy: 0.8239\n",
      "Epoch [47/500], Average Training Loss: 0.3932\n",
      "Epoch [47/500], Average Validation Loss: 0.4081, Average Validation Accuracy: 0.8231\n",
      "Epoch [48/500], Average Training Loss: 0.3929\n",
      "Early stopping at epoch 47. Best loss was 0.4048\n",
      "Best Validation Accuracy: 0.8260 at epoch 33 for trial 10\n",
      "Epoch [1/50], Average Training Loss: 0.4444\n",
      "Epoch [1/50], Average Validation Loss: 0.4331, Average Validation Accuracy: 0.8099\n",
      "Epoch [2/50], Average Training Loss: 0.4270\n",
      "Epoch [2/50], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8095\n",
      "Epoch [3/50], Average Training Loss: 0.4234\n",
      "Epoch [3/50], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8156\n",
      "Epoch [4/50], Average Training Loss: 0.4185\n",
      "Epoch [4/50], Average Validation Loss: 0.4206, Average Validation Accuracy: 0.8159\n",
      "Epoch [5/50], Average Training Loss: 0.4159\n",
      "Epoch [5/50], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8176\n",
      "Epoch [6/50], Average Training Loss: 0.4142\n",
      "Epoch [6/50], Average Validation Loss: 0.4163, Average Validation Accuracy: 0.8187\n",
      "Epoch [7/50], Average Training Loss: 0.4119\n",
      "Epoch [7/50], Average Validation Loss: 0.4139, Average Validation Accuracy: 0.8194\n",
      "Epoch [8/50], Average Training Loss: 0.4110\n",
      "Epoch [8/50], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8182\n",
      "Epoch [9/50], Average Training Loss: 0.4093\n",
      "Epoch [9/50], Average Validation Loss: 0.4175, Average Validation Accuracy: 0.8174\n",
      "Epoch [10/50], Average Training Loss: 0.4093\n",
      "Epoch [10/50], Average Validation Loss: 0.4106, Average Validation Accuracy: 0.8216\n",
      "Epoch [11/50], Average Training Loss: 0.4086\n",
      "Epoch [11/50], Average Validation Loss: 0.4121, Average Validation Accuracy: 0.8211\n",
      "Epoch [12/50], Average Training Loss: 0.4080\n",
      "Epoch [12/50], Average Validation Loss: 0.4102, Average Validation Accuracy: 0.8207\n",
      "Epoch [13/50], Average Training Loss: 0.4074\n",
      "Epoch [13/50], Average Validation Loss: 0.4086, Average Validation Accuracy: 0.8227\n",
      "Epoch [14/50], Average Training Loss: 0.4071\n",
      "Epoch [14/50], Average Validation Loss: 0.4128, Average Validation Accuracy: 0.8202\n",
      "Epoch [15/50], Average Training Loss: 0.4061\n",
      "Epoch [15/50], Average Validation Loss: 0.4080, Average Validation Accuracy: 0.8226\n",
      "Epoch [16/50], Average Training Loss: 0.4062\n",
      "Epoch [16/50], Average Validation Loss: 0.4176, Average Validation Accuracy: 0.8155\n",
      "Epoch [17/50], Average Training Loss: 0.4054\n",
      "Epoch [17/50], Average Validation Loss: 0.4086, Average Validation Accuracy: 0.8225\n",
      "Epoch [18/50], Average Training Loss: 0.4043\n",
      "Epoch [18/50], Average Validation Loss: 0.4077, Average Validation Accuracy: 0.8245\n",
      "Epoch [19/50], Average Training Loss: 0.4037\n",
      "Epoch [19/50], Average Validation Loss: 0.4079, Average Validation Accuracy: 0.8228\n",
      "Epoch [20/50], Average Training Loss: 0.4034\n",
      "Epoch [20/50], Average Validation Loss: 0.4071, Average Validation Accuracy: 0.8251\n",
      "Epoch [21/50], Average Training Loss: 0.4026\n",
      "Epoch [21/50], Average Validation Loss: 0.4102, Average Validation Accuracy: 0.8204\n",
      "Epoch [22/50], Average Training Loss: 0.4019\n",
      "Epoch [22/50], Average Validation Loss: 0.4113, Average Validation Accuracy: 0.8195\n",
      "Epoch [23/50], Average Training Loss: 0.4012\n",
      "Epoch [23/50], Average Validation Loss: 0.4089, Average Validation Accuracy: 0.8220\n",
      "Epoch [24/50], Average Training Loss: 0.4007\n",
      "Epoch [24/50], Average Validation Loss: 0.4052, Average Validation Accuracy: 0.8245\n",
      "Epoch [25/50], Average Training Loss: 0.4004\n",
      "Epoch [25/50], Average Validation Loss: 0.4059, Average Validation Accuracy: 0.8247\n",
      "Epoch [26/50], Average Training Loss: 0.3992\n",
      "Epoch [26/50], Average Validation Loss: 0.4072, Average Validation Accuracy: 0.8239\n",
      "Epoch [27/50], Average Training Loss: 0.3989\n",
      "Epoch [27/50], Average Validation Loss: 0.4064, Average Validation Accuracy: 0.8236\n",
      "Epoch [28/50], Average Training Loss: 0.3983\n",
      "Epoch [28/50], Average Validation Loss: 0.4052, Average Validation Accuracy: 0.8255\n",
      "Epoch [29/50], Average Training Loss: 0.3975\n",
      "Epoch [29/50], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8205\n",
      "Epoch [30/50], Average Training Loss: 0.3976\n",
      "Epoch [30/50], Average Validation Loss: 0.4067, Average Validation Accuracy: 0.8227\n",
      "Epoch [31/50], Average Training Loss: 0.3969\n",
      "Epoch [31/50], Average Validation Loss: 0.4057, Average Validation Accuracy: 0.8259\n",
      "Epoch [32/50], Average Training Loss: 0.3963\n",
      "Epoch [32/50], Average Validation Loss: 0.4074, Average Validation Accuracy: 0.8247\n",
      "Epoch [33/50], Average Training Loss: 0.3960\n",
      "Epoch [33/50], Average Validation Loss: 0.4086, Average Validation Accuracy: 0.8224\n",
      "Epoch [34/50], Average Training Loss: 0.3953\n",
      "Epoch [34/50], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8241\n",
      "Epoch [35/50], Average Training Loss: 0.3944\n",
      "Early stopping at epoch 34. Best loss was 0.4052\n",
      "Best Validation Accuracy: 0.8259 at epoch 31 for trial 11\n",
      "Epoch [1/50], Average Training Loss: 0.4600\n",
      "Epoch [1/50], Average Validation Loss: 0.4414, Average Validation Accuracy: 0.8041\n",
      "Epoch [2/50], Average Training Loss: 0.4350\n",
      "Epoch [2/50], Average Validation Loss: 0.4355, Average Validation Accuracy: 0.8066\n",
      "Epoch [3/50], Average Training Loss: 0.4312\n",
      "Epoch [3/50], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8097\n",
      "Epoch [4/50], Average Training Loss: 0.4297\n",
      "Epoch [4/50], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8119\n",
      "Epoch [5/50], Average Training Loss: 0.4285\n",
      "Epoch [5/50], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8111\n",
      "Epoch [6/50], Average Training Loss: 0.4273\n",
      "Epoch [6/50], Average Validation Loss: 0.4308, Average Validation Accuracy: 0.8111\n",
      "Epoch [7/50], Average Training Loss: 0.4263\n",
      "Epoch [7/50], Average Validation Loss: 0.4282, Average Validation Accuracy: 0.8125\n",
      "Epoch [8/50], Average Training Loss: 0.4250\n",
      "Epoch [8/50], Average Validation Loss: 0.4274, Average Validation Accuracy: 0.8125\n",
      "Epoch [9/50], Average Training Loss: 0.4238\n",
      "Epoch [9/50], Average Validation Loss: 0.4272, Average Validation Accuracy: 0.8128\n",
      "Epoch [10/50], Average Training Loss: 0.4229\n",
      "Epoch [10/50], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8137\n",
      "Epoch [11/50], Average Training Loss: 0.4218\n",
      "Epoch [11/50], Average Validation Loss: 0.4245, Average Validation Accuracy: 0.8128\n",
      "Epoch [12/50], Average Training Loss: 0.4209\n",
      "Epoch [12/50], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8131\n",
      "Epoch [13/50], Average Training Loss: 0.4203\n",
      "Epoch [13/50], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8139\n",
      "Epoch [14/50], Average Training Loss: 0.4199\n",
      "Epoch [14/50], Average Validation Loss: 0.4227, Average Validation Accuracy: 0.8143\n",
      "Epoch [15/50], Average Training Loss: 0.4193\n",
      "Epoch [15/50], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8135\n",
      "Epoch [16/50], Average Training Loss: 0.4187\n",
      "Epoch [16/50], Average Validation Loss: 0.4223, Average Validation Accuracy: 0.8149\n",
      "Epoch [17/50], Average Training Loss: 0.4182\n",
      "Epoch [17/50], Average Validation Loss: 0.4215, Average Validation Accuracy: 0.8149\n",
      "Epoch [18/50], Average Training Loss: 0.4177\n",
      "Epoch [18/50], Average Validation Loss: 0.4207, Average Validation Accuracy: 0.8151\n",
      "Epoch [19/50], Average Training Loss: 0.4170\n",
      "Epoch [19/50], Average Validation Loss: 0.4224, Average Validation Accuracy: 0.8147\n",
      "Epoch [20/50], Average Training Loss: 0.4163\n",
      "Epoch [20/50], Average Validation Loss: 0.4202, Average Validation Accuracy: 0.8158\n",
      "Epoch [21/50], Average Training Loss: 0.4158\n",
      "Epoch [21/50], Average Validation Loss: 0.4193, Average Validation Accuracy: 0.8165\n",
      "Epoch [22/50], Average Training Loss: 0.4153\n",
      "Epoch [22/50], Average Validation Loss: 0.4191, Average Validation Accuracy: 0.8174\n",
      "Epoch [23/50], Average Training Loss: 0.4148\n",
      "Epoch [23/50], Average Validation Loss: 0.4176, Average Validation Accuracy: 0.8164\n",
      "Epoch [24/50], Average Training Loss: 0.4144\n",
      "Epoch [24/50], Average Validation Loss: 0.4171, Average Validation Accuracy: 0.8174\n",
      "Epoch [25/50], Average Training Loss: 0.4138\n",
      "Epoch [25/50], Average Validation Loss: 0.4169, Average Validation Accuracy: 0.8174\n",
      "Epoch [26/50], Average Training Loss: 0.4137\n",
      "Epoch [26/50], Average Validation Loss: 0.4170, Average Validation Accuracy: 0.8178\n",
      "Epoch [27/50], Average Training Loss: 0.4136\n",
      "Epoch [27/50], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8181\n",
      "Epoch [28/50], Average Training Loss: 0.4133\n",
      "Epoch [28/50], Average Validation Loss: 0.4169, Average Validation Accuracy: 0.8179\n",
      "Epoch [29/50], Average Training Loss: 0.4131\n",
      "Epoch [29/50], Average Validation Loss: 0.4167, Average Validation Accuracy: 0.8183\n",
      "Epoch [30/50], Average Training Loss: 0.4128\n",
      "Epoch [30/50], Average Validation Loss: 0.4154, Average Validation Accuracy: 0.8186\n",
      "Epoch [31/50], Average Training Loss: 0.4126\n",
      "Epoch [31/50], Average Validation Loss: 0.4161, Average Validation Accuracy: 0.8176\n",
      "Epoch [32/50], Average Training Loss: 0.4124\n",
      "Epoch [32/50], Average Validation Loss: 0.4158, Average Validation Accuracy: 0.8189\n",
      "Epoch [33/50], Average Training Loss: 0.4121\n",
      "Epoch [33/50], Average Validation Loss: 0.4168, Average Validation Accuracy: 0.8167\n",
      "Epoch [34/50], Average Training Loss: 0.4121\n",
      "Epoch [34/50], Average Validation Loss: 0.4148, Average Validation Accuracy: 0.8202\n",
      "Epoch [35/50], Average Training Loss: 0.4114\n",
      "Epoch [35/50], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8175\n",
      "Epoch [36/50], Average Training Loss: 0.4110\n",
      "Epoch [36/50], Average Validation Loss: 0.4148, Average Validation Accuracy: 0.8190\n",
      "Epoch [37/50], Average Training Loss: 0.4109\n",
      "Epoch [37/50], Average Validation Loss: 0.4160, Average Validation Accuracy: 0.8176\n",
      "Epoch [38/50], Average Training Loss: 0.4107\n",
      "Epoch [38/50], Average Validation Loss: 0.4143, Average Validation Accuracy: 0.8194\n",
      "Epoch [39/50], Average Training Loss: 0.4101\n",
      "Epoch [39/50], Average Validation Loss: 0.4139, Average Validation Accuracy: 0.8181\n",
      "Epoch [40/50], Average Training Loss: 0.4100\n",
      "Epoch [40/50], Average Validation Loss: 0.4153, Average Validation Accuracy: 0.8177\n",
      "Epoch [41/50], Average Training Loss: 0.4098\n",
      "Epoch [41/50], Average Validation Loss: 0.4127, Average Validation Accuracy: 0.8191\n",
      "Epoch [42/50], Average Training Loss: 0.4095\n",
      "Epoch [42/50], Average Validation Loss: 0.4127, Average Validation Accuracy: 0.8209\n",
      "Epoch [43/50], Average Training Loss: 0.4092\n",
      "Epoch [43/50], Average Validation Loss: 0.4127, Average Validation Accuracy: 0.8200\n",
      "Epoch [44/50], Average Training Loss: 0.4087\n",
      "Epoch [44/50], Average Validation Loss: 0.4131, Average Validation Accuracy: 0.8206\n",
      "Epoch [45/50], Average Training Loss: 0.4084\n",
      "Epoch [45/50], Average Validation Loss: 0.4117, Average Validation Accuracy: 0.8215\n",
      "Epoch [46/50], Average Training Loss: 0.4081\n",
      "Epoch [46/50], Average Validation Loss: 0.4118, Average Validation Accuracy: 0.8197\n",
      "Epoch [47/50], Average Training Loss: 0.4078\n",
      "Epoch [47/50], Average Validation Loss: 0.4110, Average Validation Accuracy: 0.8214\n",
      "Epoch [48/50], Average Training Loss: 0.4078\n",
      "Epoch [48/50], Average Validation Loss: 0.4108, Average Validation Accuracy: 0.8225\n",
      "Epoch [49/50], Average Training Loss: 0.4074\n",
      "Epoch [49/50], Average Validation Loss: 0.4105, Average Validation Accuracy: 0.8222\n",
      "Epoch [50/50], Average Training Loss: 0.4071\n",
      "Epoch [50/50], Average Validation Loss: 0.4104, Average Validation Accuracy: 0.8211\n",
      "Best Validation Accuracy: 0.8225 at epoch 48 for trial 12\n",
      "Epoch [1/500], Average Training Loss: 0.6963\n",
      "Epoch [1/500], Average Validation Loss: 0.6955, Average Validation Accuracy: 0.5046\n",
      "Epoch [2/500], Average Training Loss: 0.6961\n",
      "Epoch [2/500], Average Validation Loss: 0.6953, Average Validation Accuracy: 0.5046\n",
      "Epoch [3/500], Average Training Loss: 0.6959\n",
      "Epoch [3/500], Average Validation Loss: 0.6952, Average Validation Accuracy: 0.5046\n",
      "Epoch [4/500], Average Training Loss: 0.6958\n",
      "Epoch [4/500], Average Validation Loss: 0.6950, Average Validation Accuracy: 0.5046\n",
      "Epoch [5/500], Average Training Loss: 0.6956\n",
      "Epoch [5/500], Average Validation Loss: 0.6949, Average Validation Accuracy: 0.5046\n",
      "Epoch [6/500], Average Training Loss: 0.6955\n",
      "Epoch [6/500], Average Validation Loss: 0.6948, Average Validation Accuracy: 0.5046\n",
      "Epoch [7/500], Average Training Loss: 0.6953\n",
      "Epoch [7/500], Average Validation Loss: 0.6946, Average Validation Accuracy: 0.5046\n",
      "Epoch [8/500], Average Training Loss: 0.6952\n",
      "Epoch [8/500], Average Validation Loss: 0.6945, Average Validation Accuracy: 0.5046\n",
      "Epoch [9/500], Average Training Loss: 0.6950\n",
      "Epoch [9/500], Average Validation Loss: 0.6943, Average Validation Accuracy: 0.5046\n",
      "Epoch [10/500], Average Training Loss: 0.6949\n",
      "Epoch [10/500], Average Validation Loss: 0.6942, Average Validation Accuracy: 0.5046\n",
      "Epoch [11/500], Average Training Loss: 0.6947\n",
      "Epoch [11/500], Average Validation Loss: 0.6941, Average Validation Accuracy: 0.5046\n",
      "Epoch [12/500], Average Training Loss: 0.6946\n",
      "Epoch [12/500], Average Validation Loss: 0.6939, Average Validation Accuracy: 0.5046\n",
      "Epoch [13/500], Average Training Loss: 0.6945\n",
      "Epoch [13/500], Average Validation Loss: 0.6938, Average Validation Accuracy: 0.5046\n",
      "Epoch [14/500], Average Training Loss: 0.6943\n",
      "Epoch [14/500], Average Validation Loss: 0.6936, Average Validation Accuracy: 0.5046\n",
      "Epoch [15/500], Average Training Loss: 0.6942\n",
      "Epoch [15/500], Average Validation Loss: 0.6935, Average Validation Accuracy: 0.5046\n",
      "Epoch [16/500], Average Training Loss: 0.6940\n",
      "Epoch [16/500], Average Validation Loss: 0.6934, Average Validation Accuracy: 0.5046\n",
      "Epoch [17/500], Average Training Loss: 0.6939\n",
      "Epoch [17/500], Average Validation Loss: 0.6932, Average Validation Accuracy: 0.5046\n",
      "Epoch [18/500], Average Training Loss: 0.6937\n",
      "Epoch [18/500], Average Validation Loss: 0.6931, Average Validation Accuracy: 0.5046\n",
      "Epoch [19/500], Average Training Loss: 0.6936\n",
      "Epoch [19/500], Average Validation Loss: 0.6930, Average Validation Accuracy: 0.5046\n",
      "Epoch [20/500], Average Training Loss: 0.6935\n",
      "Epoch [20/500], Average Validation Loss: 0.6929, Average Validation Accuracy: 0.5046\n",
      "Epoch [21/500], Average Training Loss: 0.6933\n",
      "Epoch [21/500], Average Validation Loss: 0.6927, Average Validation Accuracy: 0.5046\n",
      "Epoch [22/500], Average Training Loss: 0.6932\n",
      "Epoch [22/500], Average Validation Loss: 0.6926, Average Validation Accuracy: 0.5046\n",
      "Epoch [23/500], Average Training Loss: 0.6931\n",
      "Epoch [23/500], Average Validation Loss: 0.6925, Average Validation Accuracy: 0.5046\n",
      "Epoch [24/500], Average Training Loss: 0.6929\n",
      "Epoch [24/500], Average Validation Loss: 0.6923, Average Validation Accuracy: 0.5046\n",
      "Epoch [25/500], Average Training Loss: 0.6928\n",
      "Epoch [25/500], Average Validation Loss: 0.6922, Average Validation Accuracy: 0.5046\n",
      "Epoch [26/500], Average Training Loss: 0.6927\n",
      "Epoch [26/500], Average Validation Loss: 0.6921, Average Validation Accuracy: 0.5046\n",
      "Epoch [27/500], Average Training Loss: 0.6925\n",
      "Epoch [27/500], Average Validation Loss: 0.6920, Average Validation Accuracy: 0.5046\n",
      "Epoch [28/500], Average Training Loss: 0.6924\n",
      "Epoch [28/500], Average Validation Loss: 0.6918, Average Validation Accuracy: 0.5046\n",
      "Epoch [29/500], Average Training Loss: 0.6923\n",
      "Epoch [29/500], Average Validation Loss: 0.6917, Average Validation Accuracy: 0.5046\n",
      "Epoch [30/500], Average Training Loss: 0.6921\n",
      "Epoch [30/500], Average Validation Loss: 0.6916, Average Validation Accuracy: 0.5046\n",
      "Epoch [31/500], Average Training Loss: 0.6920\n",
      "Epoch [31/500], Average Validation Loss: 0.6915, Average Validation Accuracy: 0.5046\n",
      "Epoch [32/500], Average Training Loss: 0.6919\n",
      "Epoch [32/500], Average Validation Loss: 0.6913, Average Validation Accuracy: 0.5046\n",
      "Epoch [33/500], Average Training Loss: 0.6917\n",
      "Epoch [33/500], Average Validation Loss: 0.6912, Average Validation Accuracy: 0.5046\n",
      "Epoch [34/500], Average Training Loss: 0.6916\n",
      "Epoch [34/500], Average Validation Loss: 0.6911, Average Validation Accuracy: 0.5046\n",
      "Epoch [35/500], Average Training Loss: 0.6915\n",
      "Epoch [35/500], Average Validation Loss: 0.6910, Average Validation Accuracy: 0.5046\n",
      "Epoch [36/500], Average Training Loss: 0.6913\n",
      "Epoch [36/500], Average Validation Loss: 0.6908, Average Validation Accuracy: 0.5046\n",
      "Epoch [37/500], Average Training Loss: 0.6912\n",
      "Epoch [37/500], Average Validation Loss: 0.6907, Average Validation Accuracy: 0.5046\n",
      "Epoch [38/500], Average Training Loss: 0.6911\n",
      "Epoch [38/500], Average Validation Loss: 0.6906, Average Validation Accuracy: 0.5046\n",
      "Epoch [39/500], Average Training Loss: 0.6910\n",
      "Epoch [39/500], Average Validation Loss: 0.6905, Average Validation Accuracy: 0.5046\n",
      "Epoch [40/500], Average Training Loss: 0.6908\n",
      "Epoch [40/500], Average Validation Loss: 0.6904, Average Validation Accuracy: 0.5046\n",
      "Epoch [41/500], Average Training Loss: 0.6907\n",
      "Epoch [41/500], Average Validation Loss: 0.6902, Average Validation Accuracy: 0.5046\n",
      "Epoch [42/500], Average Training Loss: 0.6906\n",
      "Epoch [42/500], Average Validation Loss: 0.6901, Average Validation Accuracy: 0.5046\n",
      "Epoch [43/500], Average Training Loss: 0.6905\n",
      "Epoch [43/500], Average Validation Loss: 0.6900, Average Validation Accuracy: 0.5046\n",
      "Epoch [44/500], Average Training Loss: 0.6903\n",
      "Epoch [44/500], Average Validation Loss: 0.6899, Average Validation Accuracy: 0.5046\n",
      "Epoch [45/500], Average Training Loss: 0.6902\n",
      "Epoch [45/500], Average Validation Loss: 0.6898, Average Validation Accuracy: 0.5046\n",
      "Epoch [46/500], Average Training Loss: 0.6901\n",
      "Epoch [46/500], Average Validation Loss: 0.6896, Average Validation Accuracy: 0.5046\n",
      "Epoch [47/500], Average Training Loss: 0.6900\n",
      "Epoch [47/500], Average Validation Loss: 0.6895, Average Validation Accuracy: 0.5046\n",
      "Epoch [48/500], Average Training Loss: 0.6898\n",
      "Epoch [48/500], Average Validation Loss: 0.6894, Average Validation Accuracy: 0.5046\n",
      "Epoch [49/500], Average Training Loss: 0.6897\n",
      "Epoch [49/500], Average Validation Loss: 0.6893, Average Validation Accuracy: 0.5046\n",
      "Epoch [50/500], Average Training Loss: 0.6896\n",
      "Epoch [50/500], Average Validation Loss: 0.6892, Average Validation Accuracy: 0.5046\n",
      "Epoch [51/500], Average Training Loss: 0.6895\n",
      "Epoch [51/500], Average Validation Loss: 0.6890, Average Validation Accuracy: 0.5046\n",
      "Epoch [52/500], Average Training Loss: 0.6893\n",
      "Epoch [52/500], Average Validation Loss: 0.6889, Average Validation Accuracy: 0.5046\n",
      "Epoch [53/500], Average Training Loss: 0.6892\n",
      "Epoch [53/500], Average Validation Loss: 0.6888, Average Validation Accuracy: 0.5046\n",
      "Epoch [54/500], Average Training Loss: 0.6891\n",
      "Epoch [54/500], Average Validation Loss: 0.6887, Average Validation Accuracy: 0.5046\n",
      "Epoch [55/500], Average Training Loss: 0.6890\n",
      "Epoch [55/500], Average Validation Loss: 0.6886, Average Validation Accuracy: 0.5046\n",
      "Epoch [56/500], Average Training Loss: 0.6888\n",
      "Epoch [56/500], Average Validation Loss: 0.6885, Average Validation Accuracy: 0.5046\n",
      "Epoch [57/500], Average Training Loss: 0.6887\n",
      "Epoch [57/500], Average Validation Loss: 0.6883, Average Validation Accuracy: 0.5046\n",
      "Epoch [58/500], Average Training Loss: 0.6886\n",
      "Epoch [58/500], Average Validation Loss: 0.6882, Average Validation Accuracy: 0.5046\n",
      "Epoch [59/500], Average Training Loss: 0.6885\n",
      "Epoch [59/500], Average Validation Loss: 0.6881, Average Validation Accuracy: 0.5046\n",
      "Epoch [60/500], Average Training Loss: 0.6883\n",
      "Epoch [60/500], Average Validation Loss: 0.6880, Average Validation Accuracy: 0.5046\n",
      "Epoch [61/500], Average Training Loss: 0.6882\n",
      "Epoch [61/500], Average Validation Loss: 0.6879, Average Validation Accuracy: 0.5046\n",
      "Epoch [62/500], Average Training Loss: 0.6881\n",
      "Epoch [62/500], Average Validation Loss: 0.6877, Average Validation Accuracy: 0.5046\n",
      "Epoch [63/500], Average Training Loss: 0.6880\n",
      "Epoch [63/500], Average Validation Loss: 0.6876, Average Validation Accuracy: 0.5046\n",
      "Epoch [64/500], Average Training Loss: 0.6878\n",
      "Epoch [64/500], Average Validation Loss: 0.6875, Average Validation Accuracy: 0.5046\n",
      "Epoch [65/500], Average Training Loss: 0.6877\n",
      "Epoch [65/500], Average Validation Loss: 0.6874, Average Validation Accuracy: 0.5046\n",
      "Epoch [66/500], Average Training Loss: 0.6876\n",
      "Epoch [66/500], Average Validation Loss: 0.6873, Average Validation Accuracy: 0.5046\n",
      "Epoch [67/500], Average Training Loss: 0.6875\n",
      "Epoch [67/500], Average Validation Loss: 0.6872, Average Validation Accuracy: 0.5046\n",
      "Epoch [68/500], Average Training Loss: 0.6874\n",
      "Epoch [68/500], Average Validation Loss: 0.6870, Average Validation Accuracy: 0.5046\n",
      "Epoch [69/500], Average Training Loss: 0.6872\n",
      "Epoch [69/500], Average Validation Loss: 0.6869, Average Validation Accuracy: 0.5047\n",
      "Epoch [70/500], Average Training Loss: 0.6871\n",
      "Epoch [70/500], Average Validation Loss: 0.6868, Average Validation Accuracy: 0.5047\n",
      "Epoch [71/500], Average Training Loss: 0.6870\n",
      "Epoch [71/500], Average Validation Loss: 0.6867, Average Validation Accuracy: 0.5049\n",
      "Epoch [72/500], Average Training Loss: 0.6869\n",
      "Epoch [72/500], Average Validation Loss: 0.6866, Average Validation Accuracy: 0.5048\n",
      "Epoch [73/500], Average Training Loss: 0.6867\n",
      "Epoch [73/500], Average Validation Loss: 0.6864, Average Validation Accuracy: 0.5048\n",
      "Epoch [74/500], Average Training Loss: 0.6866\n",
      "Epoch [74/500], Average Validation Loss: 0.6863, Average Validation Accuracy: 0.5053\n",
      "Epoch [75/500], Average Training Loss: 0.6865\n",
      "Epoch [75/500], Average Validation Loss: 0.6862, Average Validation Accuracy: 0.5054\n",
      "Epoch [76/500], Average Training Loss: 0.6864\n",
      "Epoch [76/500], Average Validation Loss: 0.6861, Average Validation Accuracy: 0.5058\n",
      "Epoch [77/500], Average Training Loss: 0.6862\n",
      "Epoch [77/500], Average Validation Loss: 0.6860, Average Validation Accuracy: 0.5064\n",
      "Epoch [78/500], Average Training Loss: 0.6861\n",
      "Epoch [78/500], Average Validation Loss: 0.6858, Average Validation Accuracy: 0.5079\n",
      "Epoch [79/500], Average Training Loss: 0.6860\n",
      "Epoch [79/500], Average Validation Loss: 0.6857, Average Validation Accuracy: 0.5097\n",
      "Epoch [80/500], Average Training Loss: 0.6859\n",
      "Epoch [80/500], Average Validation Loss: 0.6856, Average Validation Accuracy: 0.5112\n",
      "Epoch [81/500], Average Training Loss: 0.6857\n",
      "Epoch [81/500], Average Validation Loss: 0.6855, Average Validation Accuracy: 0.5133\n",
      "Epoch [82/500], Average Training Loss: 0.6856\n",
      "Epoch [82/500], Average Validation Loss: 0.6854, Average Validation Accuracy: 0.5160\n",
      "Epoch [83/500], Average Training Loss: 0.6855\n",
      "Epoch [83/500], Average Validation Loss: 0.6852, Average Validation Accuracy: 0.5189\n",
      "Epoch [84/500], Average Training Loss: 0.6854\n",
      "Epoch [84/500], Average Validation Loss: 0.6851, Average Validation Accuracy: 0.5222\n",
      "Epoch [85/500], Average Training Loss: 0.6852\n",
      "Epoch [85/500], Average Validation Loss: 0.6850, Average Validation Accuracy: 0.5253\n",
      "Epoch [86/500], Average Training Loss: 0.6851\n",
      "Epoch [86/500], Average Validation Loss: 0.6849, Average Validation Accuracy: 0.5303\n",
      "Epoch [87/500], Average Training Loss: 0.6850\n",
      "Epoch [87/500], Average Validation Loss: 0.6847, Average Validation Accuracy: 0.5350\n",
      "Epoch [88/500], Average Training Loss: 0.6849\n",
      "Epoch [88/500], Average Validation Loss: 0.6846, Average Validation Accuracy: 0.5406\n",
      "Epoch [89/500], Average Training Loss: 0.6847\n",
      "Epoch [89/500], Average Validation Loss: 0.6845, Average Validation Accuracy: 0.5467\n",
      "Epoch [90/500], Average Training Loss: 0.6846\n",
      "Epoch [90/500], Average Validation Loss: 0.6844, Average Validation Accuracy: 0.5531\n",
      "Epoch [91/500], Average Training Loss: 0.6845\n",
      "Epoch [91/500], Average Validation Loss: 0.6843, Average Validation Accuracy: 0.5605\n",
      "Epoch [92/500], Average Training Loss: 0.6844\n",
      "Epoch [92/500], Average Validation Loss: 0.6841, Average Validation Accuracy: 0.5673\n",
      "Epoch [93/500], Average Training Loss: 0.6842\n",
      "Epoch [93/500], Average Validation Loss: 0.6840, Average Validation Accuracy: 0.5764\n",
      "Epoch [94/500], Average Training Loss: 0.6841\n",
      "Epoch [94/500], Average Validation Loss: 0.6839, Average Validation Accuracy: 0.5856\n",
      "Epoch [95/500], Average Training Loss: 0.6840\n",
      "Epoch [95/500], Average Validation Loss: 0.6838, Average Validation Accuracy: 0.5947\n",
      "Epoch [96/500], Average Training Loss: 0.6838\n",
      "Epoch [96/500], Average Validation Loss: 0.6836, Average Validation Accuracy: 0.6038\n",
      "Epoch [97/500], Average Training Loss: 0.6837\n",
      "Epoch [97/500], Average Validation Loss: 0.6835, Average Validation Accuracy: 0.6127\n",
      "Epoch [98/500], Average Training Loss: 0.6836\n",
      "Epoch [98/500], Average Validation Loss: 0.6834, Average Validation Accuracy: 0.6211\n",
      "Epoch [99/500], Average Training Loss: 0.6835\n",
      "Epoch [99/500], Average Validation Loss: 0.6832, Average Validation Accuracy: 0.6300\n",
      "Epoch [100/500], Average Training Loss: 0.6833\n",
      "Epoch [100/500], Average Validation Loss: 0.6831, Average Validation Accuracy: 0.6391\n",
      "Epoch [101/500], Average Training Loss: 0.6832\n",
      "Epoch [101/500], Average Validation Loss: 0.6830, Average Validation Accuracy: 0.6487\n",
      "Epoch [102/500], Average Training Loss: 0.6831\n",
      "Epoch [102/500], Average Validation Loss: 0.6829, Average Validation Accuracy: 0.6590\n",
      "Epoch [103/500], Average Training Loss: 0.6829\n",
      "Epoch [103/500], Average Validation Loss: 0.6827, Average Validation Accuracy: 0.6675\n",
      "Epoch [104/500], Average Training Loss: 0.6828\n",
      "Epoch [104/500], Average Validation Loss: 0.6826, Average Validation Accuracy: 0.6759\n",
      "Epoch [105/500], Average Training Loss: 0.6827\n",
      "Epoch [105/500], Average Validation Loss: 0.6825, Average Validation Accuracy: 0.6825\n",
      "Epoch [106/500], Average Training Loss: 0.6825\n",
      "Epoch [106/500], Average Validation Loss: 0.6823, Average Validation Accuracy: 0.6895\n",
      "Epoch [107/500], Average Training Loss: 0.6824\n",
      "Epoch [107/500], Average Validation Loss: 0.6822, Average Validation Accuracy: 0.6965\n",
      "Epoch [108/500], Average Training Loss: 0.6823\n",
      "Epoch [108/500], Average Validation Loss: 0.6821, Average Validation Accuracy: 0.7022\n",
      "Epoch [109/500], Average Training Loss: 0.6821\n",
      "Epoch [109/500], Average Validation Loss: 0.6820, Average Validation Accuracy: 0.7087\n",
      "Epoch [110/500], Average Training Loss: 0.6820\n",
      "Epoch [110/500], Average Validation Loss: 0.6818, Average Validation Accuracy: 0.7145\n",
      "Epoch [111/500], Average Training Loss: 0.6819\n",
      "Epoch [111/500], Average Validation Loss: 0.6817, Average Validation Accuracy: 0.7205\n",
      "Epoch [112/500], Average Training Loss: 0.6817\n",
      "Epoch [112/500], Average Validation Loss: 0.6816, Average Validation Accuracy: 0.7255\n",
      "Epoch [113/500], Average Training Loss: 0.6816\n",
      "Epoch [113/500], Average Validation Loss: 0.6814, Average Validation Accuracy: 0.7298\n",
      "Epoch [114/500], Average Training Loss: 0.6814\n",
      "Epoch [114/500], Average Validation Loss: 0.6813, Average Validation Accuracy: 0.7338\n",
      "Epoch [115/500], Average Training Loss: 0.6813\n",
      "Epoch [115/500], Average Validation Loss: 0.6811, Average Validation Accuracy: 0.7380\n",
      "Epoch [116/500], Average Training Loss: 0.6812\n",
      "Epoch [116/500], Average Validation Loss: 0.6810, Average Validation Accuracy: 0.7415\n",
      "Epoch [117/500], Average Training Loss: 0.6810\n",
      "Epoch [117/500], Average Validation Loss: 0.6809, Average Validation Accuracy: 0.7441\n",
      "Epoch [118/500], Average Training Loss: 0.6809\n",
      "Epoch [118/500], Average Validation Loss: 0.6807, Average Validation Accuracy: 0.7462\n",
      "Epoch [119/500], Average Training Loss: 0.6808\n",
      "Epoch [119/500], Average Validation Loss: 0.6806, Average Validation Accuracy: 0.7482\n",
      "Epoch [120/500], Average Training Loss: 0.6806\n",
      "Epoch [120/500], Average Validation Loss: 0.6805, Average Validation Accuracy: 0.7498\n",
      "Epoch [121/500], Average Training Loss: 0.6805\n",
      "Epoch [121/500], Average Validation Loss: 0.6803, Average Validation Accuracy: 0.7526\n",
      "Epoch [122/500], Average Training Loss: 0.6803\n",
      "Epoch [122/500], Average Validation Loss: 0.6802, Average Validation Accuracy: 0.7550\n",
      "Epoch [123/500], Average Training Loss: 0.6802\n",
      "Epoch [123/500], Average Validation Loss: 0.6801, Average Validation Accuracy: 0.7564\n",
      "Epoch [124/500], Average Training Loss: 0.6800\n",
      "Epoch [124/500], Average Validation Loss: 0.6799, Average Validation Accuracy: 0.7586\n",
      "Epoch [125/500], Average Training Loss: 0.6799\n",
      "Epoch [125/500], Average Validation Loss: 0.6798, Average Validation Accuracy: 0.7605\n",
      "Epoch [126/500], Average Training Loss: 0.6798\n",
      "Epoch [126/500], Average Validation Loss: 0.6796, Average Validation Accuracy: 0.7615\n",
      "Epoch [127/500], Average Training Loss: 0.6796\n",
      "Epoch [127/500], Average Validation Loss: 0.6795, Average Validation Accuracy: 0.7634\n",
      "Epoch [128/500], Average Training Loss: 0.6795\n",
      "Epoch [128/500], Average Validation Loss: 0.6793, Average Validation Accuracy: 0.7643\n",
      "Epoch [129/500], Average Training Loss: 0.6793\n",
      "Epoch [129/500], Average Validation Loss: 0.6792, Average Validation Accuracy: 0.7652\n",
      "Epoch [130/500], Average Training Loss: 0.6792\n",
      "Epoch [130/500], Average Validation Loss: 0.6791, Average Validation Accuracy: 0.7660\n",
      "Epoch [131/500], Average Training Loss: 0.6790\n",
      "Epoch [131/500], Average Validation Loss: 0.6789, Average Validation Accuracy: 0.7669\n",
      "Epoch [132/500], Average Training Loss: 0.6789\n",
      "Epoch [132/500], Average Validation Loss: 0.6788, Average Validation Accuracy: 0.7673\n",
      "Epoch [133/500], Average Training Loss: 0.6787\n",
      "Epoch [133/500], Average Validation Loss: 0.6786, Average Validation Accuracy: 0.7675\n",
      "Epoch [134/500], Average Training Loss: 0.6786\n",
      "Epoch [134/500], Average Validation Loss: 0.6785, Average Validation Accuracy: 0.7681\n",
      "Epoch [135/500], Average Training Loss: 0.6784\n",
      "Epoch [135/500], Average Validation Loss: 0.6783, Average Validation Accuracy: 0.7688\n",
      "Epoch [136/500], Average Training Loss: 0.6783\n",
      "Epoch [136/500], Average Validation Loss: 0.6782, Average Validation Accuracy: 0.7692\n",
      "Epoch [137/500], Average Training Loss: 0.6781\n",
      "Epoch [137/500], Average Validation Loss: 0.6780, Average Validation Accuracy: 0.7698\n",
      "Epoch [138/500], Average Training Loss: 0.6780\n",
      "Epoch [138/500], Average Validation Loss: 0.6779, Average Validation Accuracy: 0.7702\n",
      "Epoch [139/500], Average Training Loss: 0.6778\n",
      "Epoch [139/500], Average Validation Loss: 0.6777, Average Validation Accuracy: 0.7709\n",
      "Epoch [140/500], Average Training Loss: 0.6777\n",
      "Epoch [140/500], Average Validation Loss: 0.6776, Average Validation Accuracy: 0.7712\n",
      "Epoch [141/500], Average Training Loss: 0.6775\n",
      "Epoch [141/500], Average Validation Loss: 0.6774, Average Validation Accuracy: 0.7718\n",
      "Epoch [142/500], Average Training Loss: 0.6774\n",
      "Epoch [142/500], Average Validation Loss: 0.6773, Average Validation Accuracy: 0.7721\n",
      "Epoch [143/500], Average Training Loss: 0.6772\n",
      "Epoch [143/500], Average Validation Loss: 0.6771, Average Validation Accuracy: 0.7726\n",
      "Epoch [144/500], Average Training Loss: 0.6771\n",
      "Epoch [144/500], Average Validation Loss: 0.6770, Average Validation Accuracy: 0.7729\n",
      "Epoch [145/500], Average Training Loss: 0.6769\n",
      "Epoch [145/500], Average Validation Loss: 0.6768, Average Validation Accuracy: 0.7731\n",
      "Epoch [146/500], Average Training Loss: 0.6767\n",
      "Epoch [146/500], Average Validation Loss: 0.6766, Average Validation Accuracy: 0.7736\n",
      "Epoch [147/500], Average Training Loss: 0.6766\n",
      "Epoch [147/500], Average Validation Loss: 0.6765, Average Validation Accuracy: 0.7742\n",
      "Epoch [148/500], Average Training Loss: 0.6764\n",
      "Epoch [148/500], Average Validation Loss: 0.6763, Average Validation Accuracy: 0.7742\n",
      "Epoch [149/500], Average Training Loss: 0.6763\n",
      "Epoch [149/500], Average Validation Loss: 0.6762, Average Validation Accuracy: 0.7747\n",
      "Epoch [150/500], Average Training Loss: 0.6761\n",
      "Epoch [150/500], Average Validation Loss: 0.6760, Average Validation Accuracy: 0.7753\n",
      "Epoch [151/500], Average Training Loss: 0.6759\n",
      "Epoch [151/500], Average Validation Loss: 0.6759, Average Validation Accuracy: 0.7756\n",
      "Epoch [152/500], Average Training Loss: 0.6758\n",
      "Epoch [152/500], Average Validation Loss: 0.6757, Average Validation Accuracy: 0.7762\n",
      "Epoch [153/500], Average Training Loss: 0.6756\n",
      "Epoch [153/500], Average Validation Loss: 0.6755, Average Validation Accuracy: 0.7765\n",
      "Epoch [154/500], Average Training Loss: 0.6755\n",
      "Epoch [154/500], Average Validation Loss: 0.6754, Average Validation Accuracy: 0.7763\n",
      "Epoch [155/500], Average Training Loss: 0.6753\n",
      "Epoch [155/500], Average Validation Loss: 0.6752, Average Validation Accuracy: 0.7769\n",
      "Epoch [156/500], Average Training Loss: 0.6751\n",
      "Epoch [156/500], Average Validation Loss: 0.6750, Average Validation Accuracy: 0.7773\n",
      "Epoch [157/500], Average Training Loss: 0.6750\n",
      "Epoch [157/500], Average Validation Loss: 0.6749, Average Validation Accuracy: 0.7768\n",
      "Epoch [158/500], Average Training Loss: 0.6748\n",
      "Epoch [158/500], Average Validation Loss: 0.6747, Average Validation Accuracy: 0.7770\n",
      "Epoch [159/500], Average Training Loss: 0.6746\n",
      "Epoch [159/500], Average Validation Loss: 0.6745, Average Validation Accuracy: 0.7772\n",
      "Epoch [160/500], Average Training Loss: 0.6744\n",
      "Epoch [160/500], Average Validation Loss: 0.6744, Average Validation Accuracy: 0.7768\n",
      "Epoch [161/500], Average Training Loss: 0.6743\n",
      "Epoch [161/500], Average Validation Loss: 0.6742, Average Validation Accuracy: 0.7769\n",
      "Epoch [162/500], Average Training Loss: 0.6741\n",
      "Epoch [162/500], Average Validation Loss: 0.6740, Average Validation Accuracy: 0.7769\n",
      "Epoch [163/500], Average Training Loss: 0.6739\n",
      "Epoch [163/500], Average Validation Loss: 0.6739, Average Validation Accuracy: 0.7771\n",
      "Epoch [164/500], Average Training Loss: 0.6738\n",
      "Epoch [164/500], Average Validation Loss: 0.6737, Average Validation Accuracy: 0.7772\n",
      "Epoch [165/500], Average Training Loss: 0.6736\n",
      "Epoch [165/500], Average Validation Loss: 0.6735, Average Validation Accuracy: 0.7774\n",
      "Epoch [166/500], Average Training Loss: 0.6734\n",
      "Epoch [166/500], Average Validation Loss: 0.6733, Average Validation Accuracy: 0.7780\n",
      "Epoch [167/500], Average Training Loss: 0.6732\n",
      "Epoch [167/500], Average Validation Loss: 0.6732, Average Validation Accuracy: 0.7780\n",
      "Epoch [168/500], Average Training Loss: 0.6730\n",
      "Epoch [168/500], Average Validation Loss: 0.6730, Average Validation Accuracy: 0.7783\n",
      "Epoch [169/500], Average Training Loss: 0.6729\n",
      "Epoch [169/500], Average Validation Loss: 0.6728, Average Validation Accuracy: 0.7782\n",
      "Epoch [170/500], Average Training Loss: 0.6727\n",
      "Epoch [170/500], Average Validation Loss: 0.6726, Average Validation Accuracy: 0.7778\n",
      "Epoch [171/500], Average Training Loss: 0.6725\n",
      "Epoch [171/500], Average Validation Loss: 0.6724, Average Validation Accuracy: 0.7778\n",
      "Epoch [172/500], Average Training Loss: 0.6723\n",
      "Epoch [172/500], Average Validation Loss: 0.6723, Average Validation Accuracy: 0.7777\n",
      "Epoch [173/500], Average Training Loss: 0.6721\n",
      "Epoch [173/500], Average Validation Loss: 0.6721, Average Validation Accuracy: 0.7779\n",
      "Epoch [174/500], Average Training Loss: 0.6720\n",
      "Epoch [174/500], Average Validation Loss: 0.6719, Average Validation Accuracy: 0.7782\n",
      "Epoch [175/500], Average Training Loss: 0.6718\n",
      "Epoch [175/500], Average Validation Loss: 0.6717, Average Validation Accuracy: 0.7783\n",
      "Epoch [176/500], Average Training Loss: 0.6716\n",
      "Epoch [176/500], Average Validation Loss: 0.6715, Average Validation Accuracy: 0.7784\n",
      "Epoch [177/500], Average Training Loss: 0.6714\n",
      "Epoch [177/500], Average Validation Loss: 0.6713, Average Validation Accuracy: 0.7783\n",
      "Epoch [178/500], Average Training Loss: 0.6712\n",
      "Epoch [178/500], Average Validation Loss: 0.6712, Average Validation Accuracy: 0.7781\n",
      "Epoch [179/500], Average Training Loss: 0.6710\n",
      "Epoch [179/500], Average Validation Loss: 0.6710, Average Validation Accuracy: 0.7781\n",
      "Epoch [180/500], Average Training Loss: 0.6708\n",
      "Epoch [180/500], Average Validation Loss: 0.6708, Average Validation Accuracy: 0.7784\n",
      "Epoch [181/500], Average Training Loss: 0.6706\n",
      "Epoch [181/500], Average Validation Loss: 0.6706, Average Validation Accuracy: 0.7789\n",
      "Epoch [182/500], Average Training Loss: 0.6704\n",
      "Epoch [182/500], Average Validation Loss: 0.6704, Average Validation Accuracy: 0.7789\n",
      "Epoch [183/500], Average Training Loss: 0.6702\n",
      "Epoch [183/500], Average Validation Loss: 0.6702, Average Validation Accuracy: 0.7790\n",
      "Epoch [184/500], Average Training Loss: 0.6700\n",
      "Epoch [184/500], Average Validation Loss: 0.6700, Average Validation Accuracy: 0.7789\n",
      "Epoch [185/500], Average Training Loss: 0.6698\n",
      "Epoch [185/500], Average Validation Loss: 0.6698, Average Validation Accuracy: 0.7791\n",
      "Epoch [186/500], Average Training Loss: 0.6696\n",
      "Epoch [186/500], Average Validation Loss: 0.6696, Average Validation Accuracy: 0.7791\n",
      "Epoch [187/500], Average Training Loss: 0.6694\n",
      "Epoch [187/500], Average Validation Loss: 0.6694, Average Validation Accuracy: 0.7793\n",
      "Epoch [188/500], Average Training Loss: 0.6692\n",
      "Epoch [188/500], Average Validation Loss: 0.6692, Average Validation Accuracy: 0.7794\n",
      "Epoch [189/500], Average Training Loss: 0.6690\n",
      "Epoch [189/500], Average Validation Loss: 0.6690, Average Validation Accuracy: 0.7788\n",
      "Epoch [190/500], Average Training Loss: 0.6688\n",
      "Epoch [190/500], Average Validation Loss: 0.6688, Average Validation Accuracy: 0.7787\n",
      "Epoch [191/500], Average Training Loss: 0.6686\n",
      "Epoch [191/500], Average Validation Loss: 0.6686, Average Validation Accuracy: 0.7791\n",
      "Epoch [192/500], Average Training Loss: 0.6684\n",
      "Epoch [192/500], Average Validation Loss: 0.6684, Average Validation Accuracy: 0.7792\n",
      "Epoch [193/500], Average Training Loss: 0.6682\n",
      "Epoch [193/500], Average Validation Loss: 0.6682, Average Validation Accuracy: 0.7793\n",
      "Epoch [194/500], Average Training Loss: 0.6680\n",
      "Epoch [194/500], Average Validation Loss: 0.6680, Average Validation Accuracy: 0.7795\n",
      "Epoch [195/500], Average Training Loss: 0.6678\n",
      "Epoch [195/500], Average Validation Loss: 0.6678, Average Validation Accuracy: 0.7792\n",
      "Epoch [196/500], Average Training Loss: 0.6676\n",
      "Epoch [196/500], Average Validation Loss: 0.6676, Average Validation Accuracy: 0.7790\n",
      "Epoch [197/500], Average Training Loss: 0.6674\n",
      "Epoch [197/500], Average Validation Loss: 0.6674, Average Validation Accuracy: 0.7790\n",
      "Epoch [198/500], Average Training Loss: 0.6672\n",
      "Epoch [198/500], Average Validation Loss: 0.6671, Average Validation Accuracy: 0.7789\n",
      "Epoch [199/500], Average Training Loss: 0.6670\n",
      "Epoch [199/500], Average Validation Loss: 0.6669, Average Validation Accuracy: 0.7792\n",
      "Epoch [200/500], Average Training Loss: 0.6667\n",
      "Epoch [200/500], Average Validation Loss: 0.6667, Average Validation Accuracy: 0.7791\n",
      "Epoch [201/500], Average Training Loss: 0.6665\n",
      "Epoch [201/500], Average Validation Loss: 0.6665, Average Validation Accuracy: 0.7794\n",
      "Epoch [202/500], Average Training Loss: 0.6663\n",
      "Epoch [202/500], Average Validation Loss: 0.6663, Average Validation Accuracy: 0.7794\n",
      "Epoch [203/500], Average Training Loss: 0.6661\n",
      "Epoch [203/500], Average Validation Loss: 0.6661, Average Validation Accuracy: 0.7794\n",
      "Epoch [204/500], Average Training Loss: 0.6659\n",
      "Epoch [204/500], Average Validation Loss: 0.6658, Average Validation Accuracy: 0.7795\n",
      "Epoch [205/500], Average Training Loss: 0.6656\n",
      "Epoch [205/500], Average Validation Loss: 0.6656, Average Validation Accuracy: 0.7792\n",
      "Epoch [206/500], Average Training Loss: 0.6654\n",
      "Epoch [206/500], Average Validation Loss: 0.6654, Average Validation Accuracy: 0.7792\n",
      "Epoch [207/500], Average Training Loss: 0.6652\n",
      "Epoch [207/500], Average Validation Loss: 0.6652, Average Validation Accuracy: 0.7793\n",
      "Epoch [208/500], Average Training Loss: 0.6649\n",
      "Epoch [208/500], Average Validation Loss: 0.6649, Average Validation Accuracy: 0.7793\n",
      "Epoch [209/500], Average Training Loss: 0.6647\n",
      "Epoch [209/500], Average Validation Loss: 0.6647, Average Validation Accuracy: 0.7789\n",
      "Epoch [210/500], Average Training Loss: 0.6645\n",
      "Epoch [210/500], Average Validation Loss: 0.6645, Average Validation Accuracy: 0.7788\n",
      "Epoch [211/500], Average Training Loss: 0.6643\n",
      "Epoch [211/500], Average Validation Loss: 0.6642, Average Validation Accuracy: 0.7789\n",
      "Epoch [212/500], Average Training Loss: 0.6640\n",
      "Epoch [212/500], Average Validation Loss: 0.6640, Average Validation Accuracy: 0.7787\n",
      "Epoch [213/500], Average Training Loss: 0.6638\n",
      "Epoch [213/500], Average Validation Loss: 0.6638, Average Validation Accuracy: 0.7787\n",
      "Epoch [214/500], Average Training Loss: 0.6635\n",
      "Epoch [214/500], Average Validation Loss: 0.6635, Average Validation Accuracy: 0.7788\n",
      "Epoch [215/500], Average Training Loss: 0.6633\n",
      "Epoch [215/500], Average Validation Loss: 0.6633, Average Validation Accuracy: 0.7790\n",
      "Epoch [216/500], Average Training Loss: 0.6631\n",
      "Epoch [216/500], Average Validation Loss: 0.6631, Average Validation Accuracy: 0.7791\n",
      "Epoch [217/500], Average Training Loss: 0.6628\n",
      "Epoch [217/500], Average Validation Loss: 0.6628, Average Validation Accuracy: 0.7792\n",
      "Epoch [218/500], Average Training Loss: 0.6626\n",
      "Epoch [218/500], Average Validation Loss: 0.6626, Average Validation Accuracy: 0.7791\n",
      "Epoch [219/500], Average Training Loss: 0.6623\n",
      "Epoch [219/500], Average Validation Loss: 0.6623, Average Validation Accuracy: 0.7789\n",
      "Epoch [220/500], Average Training Loss: 0.6621\n",
      "Epoch [220/500], Average Validation Loss: 0.6621, Average Validation Accuracy: 0.7786\n",
      "Epoch [221/500], Average Training Loss: 0.6618\n",
      "Epoch [221/500], Average Validation Loss: 0.6618, Average Validation Accuracy: 0.7789\n",
      "Epoch [222/500], Average Training Loss: 0.6616\n",
      "Epoch [222/500], Average Validation Loss: 0.6616, Average Validation Accuracy: 0.7785\n",
      "Epoch [223/500], Average Training Loss: 0.6613\n",
      "Epoch [223/500], Average Validation Loss: 0.6613, Average Validation Accuracy: 0.7785\n",
      "Epoch [224/500], Average Training Loss: 0.6611\n",
      "Epoch [224/500], Average Validation Loss: 0.6611, Average Validation Accuracy: 0.7786\n",
      "Epoch [225/500], Average Training Loss: 0.6608\n",
      "Epoch [225/500], Average Validation Loss: 0.6608, Average Validation Accuracy: 0.7788\n",
      "Epoch [226/500], Average Training Loss: 0.6606\n",
      "Epoch [226/500], Average Validation Loss: 0.6606, Average Validation Accuracy: 0.7788\n",
      "Epoch [227/500], Average Training Loss: 0.6603\n",
      "Epoch [227/500], Average Validation Loss: 0.6603, Average Validation Accuracy: 0.7786\n",
      "Epoch [228/500], Average Training Loss: 0.6600\n",
      "Epoch [228/500], Average Validation Loss: 0.6600, Average Validation Accuracy: 0.7788\n",
      "Epoch [229/500], Average Training Loss: 0.6598\n",
      "Epoch [229/500], Average Validation Loss: 0.6598, Average Validation Accuracy: 0.7789\n",
      "Epoch [230/500], Average Training Loss: 0.6595\n",
      "Epoch [230/500], Average Validation Loss: 0.6595, Average Validation Accuracy: 0.7787\n",
      "Epoch [231/500], Average Training Loss: 0.6593\n",
      "Epoch [231/500], Average Validation Loss: 0.6592, Average Validation Accuracy: 0.7784\n",
      "Epoch [232/500], Average Training Loss: 0.6590\n",
      "Epoch [232/500], Average Validation Loss: 0.6590, Average Validation Accuracy: 0.7783\n",
      "Epoch [233/500], Average Training Loss: 0.6587\n",
      "Epoch [233/500], Average Validation Loss: 0.6587, Average Validation Accuracy: 0.7783\n",
      "Epoch [234/500], Average Training Loss: 0.6584\n",
      "Epoch [234/500], Average Validation Loss: 0.6584, Average Validation Accuracy: 0.7783\n",
      "Epoch [235/500], Average Training Loss: 0.6582\n",
      "Epoch [235/500], Average Validation Loss: 0.6582, Average Validation Accuracy: 0.7782\n",
      "Epoch [236/500], Average Training Loss: 0.6579\n",
      "Epoch [236/500], Average Validation Loss: 0.6579, Average Validation Accuracy: 0.7781\n",
      "Epoch [237/500], Average Training Loss: 0.6576\n",
      "Epoch [237/500], Average Validation Loss: 0.6576, Average Validation Accuracy: 0.7781\n",
      "Epoch [238/500], Average Training Loss: 0.6573\n",
      "Epoch [238/500], Average Validation Loss: 0.6573, Average Validation Accuracy: 0.7781\n",
      "Epoch [239/500], Average Training Loss: 0.6571\n",
      "Epoch [239/500], Average Validation Loss: 0.6571, Average Validation Accuracy: 0.7781\n",
      "Epoch [240/500], Average Training Loss: 0.6568\n",
      "Epoch [240/500], Average Validation Loss: 0.6568, Average Validation Accuracy: 0.7781\n",
      "Epoch [241/500], Average Training Loss: 0.6565\n",
      "Epoch [241/500], Average Validation Loss: 0.6565, Average Validation Accuracy: 0.7781\n",
      "Epoch [242/500], Average Training Loss: 0.6562\n",
      "Epoch [242/500], Average Validation Loss: 0.6562, Average Validation Accuracy: 0.7779\n",
      "Epoch [243/500], Average Training Loss: 0.6559\n",
      "Epoch [243/500], Average Validation Loss: 0.6559, Average Validation Accuracy: 0.7777\n",
      "Epoch [244/500], Average Training Loss: 0.6556\n",
      "Epoch [244/500], Average Validation Loss: 0.6556, Average Validation Accuracy: 0.7775\n",
      "Epoch [245/500], Average Training Loss: 0.6553\n",
      "Epoch [245/500], Average Validation Loss: 0.6553, Average Validation Accuracy: 0.7775\n",
      "Epoch [246/500], Average Training Loss: 0.6550\n",
      "Epoch [246/500], Average Validation Loss: 0.6550, Average Validation Accuracy: 0.7774\n",
      "Epoch [247/500], Average Training Loss: 0.6547\n",
      "Epoch [247/500], Average Validation Loss: 0.6547, Average Validation Accuracy: 0.7774\n",
      "Epoch [248/500], Average Training Loss: 0.6544\n",
      "Epoch [248/500], Average Validation Loss: 0.6544, Average Validation Accuracy: 0.7773\n",
      "Epoch [249/500], Average Training Loss: 0.6541\n",
      "Epoch [249/500], Average Validation Loss: 0.6541, Average Validation Accuracy: 0.7774\n",
      "Epoch [250/500], Average Training Loss: 0.6538\n",
      "Epoch [250/500], Average Validation Loss: 0.6538, Average Validation Accuracy: 0.7774\n",
      "Epoch [251/500], Average Training Loss: 0.6535\n",
      "Epoch [251/500], Average Validation Loss: 0.6535, Average Validation Accuracy: 0.7773\n",
      "Epoch [252/500], Average Training Loss: 0.6532\n",
      "Epoch [252/500], Average Validation Loss: 0.6532, Average Validation Accuracy: 0.7775\n",
      "Epoch [253/500], Average Training Loss: 0.6529\n",
      "Epoch [253/500], Average Validation Loss: 0.6529, Average Validation Accuracy: 0.7778\n",
      "Epoch [254/500], Average Training Loss: 0.6526\n",
      "Epoch [254/500], Average Validation Loss: 0.6526, Average Validation Accuracy: 0.7778\n",
      "Epoch [255/500], Average Training Loss: 0.6523\n",
      "Epoch [255/500], Average Validation Loss: 0.6523, Average Validation Accuracy: 0.7779\n",
      "Epoch [256/500], Average Training Loss: 0.6520\n",
      "Epoch [256/500], Average Validation Loss: 0.6520, Average Validation Accuracy: 0.7777\n",
      "Epoch [257/500], Average Training Loss: 0.6516\n",
      "Epoch [257/500], Average Validation Loss: 0.6517, Average Validation Accuracy: 0.7776\n",
      "Epoch [258/500], Average Training Loss: 0.6513\n",
      "Epoch [258/500], Average Validation Loss: 0.6513, Average Validation Accuracy: 0.7775\n",
      "Epoch [259/500], Average Training Loss: 0.6510\n",
      "Epoch [259/500], Average Validation Loss: 0.6510, Average Validation Accuracy: 0.7775\n",
      "Epoch [260/500], Average Training Loss: 0.6507\n",
      "Epoch [260/500], Average Validation Loss: 0.6507, Average Validation Accuracy: 0.7775\n",
      "Epoch [261/500], Average Training Loss: 0.6504\n",
      "Epoch [261/500], Average Validation Loss: 0.6504, Average Validation Accuracy: 0.7775\n",
      "Epoch [262/500], Average Training Loss: 0.6500\n",
      "Epoch [262/500], Average Validation Loss: 0.6500, Average Validation Accuracy: 0.7774\n",
      "Epoch [263/500], Average Training Loss: 0.6497\n",
      "Epoch [263/500], Average Validation Loss: 0.6497, Average Validation Accuracy: 0.7774\n",
      "Epoch [264/500], Average Training Loss: 0.6494\n",
      "Epoch [264/500], Average Validation Loss: 0.6494, Average Validation Accuracy: 0.7774\n",
      "Epoch [265/500], Average Training Loss: 0.6490\n",
      "Epoch [265/500], Average Validation Loss: 0.6490, Average Validation Accuracy: 0.7775\n",
      "Epoch [266/500], Average Training Loss: 0.6487\n",
      "Epoch [266/500], Average Validation Loss: 0.6487, Average Validation Accuracy: 0.7775\n",
      "Epoch [267/500], Average Training Loss: 0.6483\n",
      "Epoch [267/500], Average Validation Loss: 0.6484, Average Validation Accuracy: 0.7775\n",
      "Epoch [268/500], Average Training Loss: 0.6480\n",
      "Epoch [268/500], Average Validation Loss: 0.6480, Average Validation Accuracy: 0.7774\n",
      "Epoch [269/500], Average Training Loss: 0.6477\n",
      "Epoch [269/500], Average Validation Loss: 0.6477, Average Validation Accuracy: 0.7774\n",
      "Epoch [270/500], Average Training Loss: 0.6473\n",
      "Epoch [270/500], Average Validation Loss: 0.6473, Average Validation Accuracy: 0.7773\n",
      "Epoch [271/500], Average Training Loss: 0.6470\n",
      "Epoch [271/500], Average Validation Loss: 0.6470, Average Validation Accuracy: 0.7773\n",
      "Epoch [272/500], Average Training Loss: 0.6466\n",
      "Epoch [272/500], Average Validation Loss: 0.6466, Average Validation Accuracy: 0.7772\n",
      "Epoch [273/500], Average Training Loss: 0.6462\n",
      "Epoch [273/500], Average Validation Loss: 0.6463, Average Validation Accuracy: 0.7772\n",
      "Epoch [274/500], Average Training Loss: 0.6459\n",
      "Epoch [274/500], Average Validation Loss: 0.6459, Average Validation Accuracy: 0.7772\n",
      "Epoch [275/500], Average Training Loss: 0.6455\n",
      "Epoch [275/500], Average Validation Loss: 0.6455, Average Validation Accuracy: 0.7771\n",
      "Epoch [276/500], Average Training Loss: 0.6452\n",
      "Epoch [276/500], Average Validation Loss: 0.6452, Average Validation Accuracy: 0.7771\n",
      "Epoch [277/500], Average Training Loss: 0.6448\n",
      "Epoch [277/500], Average Validation Loss: 0.6448, Average Validation Accuracy: 0.7770\n",
      "Epoch [278/500], Average Training Loss: 0.6444\n",
      "Epoch [278/500], Average Validation Loss: 0.6445, Average Validation Accuracy: 0.7771\n",
      "Epoch [279/500], Average Training Loss: 0.6441\n",
      "Epoch [279/500], Average Validation Loss: 0.6441, Average Validation Accuracy: 0.7770\n",
      "Epoch [280/500], Average Training Loss: 0.6437\n",
      "Epoch [280/500], Average Validation Loss: 0.6437, Average Validation Accuracy: 0.7770\n",
      "Epoch [281/500], Average Training Loss: 0.6433\n",
      "Epoch [281/500], Average Validation Loss: 0.6433, Average Validation Accuracy: 0.7770\n",
      "Epoch [282/500], Average Training Loss: 0.6429\n",
      "Epoch [282/500], Average Validation Loss: 0.6430, Average Validation Accuracy: 0.7768\n",
      "Epoch [283/500], Average Training Loss: 0.6426\n",
      "Epoch [283/500], Average Validation Loss: 0.6426, Average Validation Accuracy: 0.7769\n",
      "Epoch [284/500], Average Training Loss: 0.6422\n",
      "Epoch [284/500], Average Validation Loss: 0.6422, Average Validation Accuracy: 0.7768\n",
      "Epoch [285/500], Average Training Loss: 0.6418\n",
      "Epoch [285/500], Average Validation Loss: 0.6418, Average Validation Accuracy: 0.7769\n",
      "Epoch [286/500], Average Training Loss: 0.6414\n",
      "Epoch [286/500], Average Validation Loss: 0.6414, Average Validation Accuracy: 0.7770\n",
      "Epoch [287/500], Average Training Loss: 0.6410\n",
      "Epoch [287/500], Average Validation Loss: 0.6410, Average Validation Accuracy: 0.7770\n",
      "Epoch [288/500], Average Training Loss: 0.6406\n",
      "Epoch [288/500], Average Validation Loss: 0.6406, Average Validation Accuracy: 0.7769\n",
      "Epoch [289/500], Average Training Loss: 0.6402\n",
      "Epoch [289/500], Average Validation Loss: 0.6402, Average Validation Accuracy: 0.7768\n",
      "Epoch [290/500], Average Training Loss: 0.6398\n",
      "Epoch [290/500], Average Validation Loss: 0.6398, Average Validation Accuracy: 0.7767\n",
      "Epoch [291/500], Average Training Loss: 0.6394\n",
      "Epoch [291/500], Average Validation Loss: 0.6394, Average Validation Accuracy: 0.7767\n",
      "Epoch [292/500], Average Training Loss: 0.6390\n",
      "Epoch [292/500], Average Validation Loss: 0.6390, Average Validation Accuracy: 0.7768\n",
      "Epoch [293/500], Average Training Loss: 0.6386\n",
      "Epoch [293/500], Average Validation Loss: 0.6386, Average Validation Accuracy: 0.7769\n",
      "Epoch [294/500], Average Training Loss: 0.6382\n",
      "Epoch [294/500], Average Validation Loss: 0.6382, Average Validation Accuracy: 0.7769\n",
      "Epoch [295/500], Average Training Loss: 0.6378\n",
      "Epoch [295/500], Average Validation Loss: 0.6378, Average Validation Accuracy: 0.7772\n",
      "Epoch [296/500], Average Training Loss: 0.6374\n",
      "Epoch [296/500], Average Validation Loss: 0.6374, Average Validation Accuracy: 0.7772\n",
      "Epoch [297/500], Average Training Loss: 0.6370\n",
      "Epoch [297/500], Average Validation Loss: 0.6370, Average Validation Accuracy: 0.7771\n",
      "Epoch [298/500], Average Training Loss: 0.6365\n",
      "Epoch [298/500], Average Validation Loss: 0.6366, Average Validation Accuracy: 0.7771\n",
      "Epoch [299/500], Average Training Loss: 0.6361\n",
      "Epoch [299/500], Average Validation Loss: 0.6361, Average Validation Accuracy: 0.7771\n",
      "Epoch [300/500], Average Training Loss: 0.6357\n",
      "Epoch [300/500], Average Validation Loss: 0.6357, Average Validation Accuracy: 0.7772\n",
      "Epoch [301/500], Average Training Loss: 0.6353\n",
      "Epoch [301/500], Average Validation Loss: 0.6353, Average Validation Accuracy: 0.7771\n",
      "Epoch [302/500], Average Training Loss: 0.6348\n",
      "Epoch [302/500], Average Validation Loss: 0.6349, Average Validation Accuracy: 0.7772\n",
      "Epoch [303/500], Average Training Loss: 0.6344\n",
      "Epoch [303/500], Average Validation Loss: 0.6344, Average Validation Accuracy: 0.7773\n",
      "Epoch [304/500], Average Training Loss: 0.6340\n",
      "Epoch [304/500], Average Validation Loss: 0.6340, Average Validation Accuracy: 0.7773\n",
      "Epoch [305/500], Average Training Loss: 0.6335\n",
      "Epoch [305/500], Average Validation Loss: 0.6336, Average Validation Accuracy: 0.7772\n",
      "Epoch [306/500], Average Training Loss: 0.6331\n",
      "Epoch [306/500], Average Validation Loss: 0.6331, Average Validation Accuracy: 0.7772\n",
      "Epoch [307/500], Average Training Loss: 0.6326\n",
      "Epoch [307/500], Average Validation Loss: 0.6327, Average Validation Accuracy: 0.7772\n",
      "Epoch [308/500], Average Training Loss: 0.6322\n",
      "Epoch [308/500], Average Validation Loss: 0.6322, Average Validation Accuracy: 0.7771\n",
      "Epoch [309/500], Average Training Loss: 0.6317\n",
      "Epoch [309/500], Average Validation Loss: 0.6318, Average Validation Accuracy: 0.7770\n",
      "Epoch [310/500], Average Training Loss: 0.6313\n",
      "Epoch [310/500], Average Validation Loss: 0.6313, Average Validation Accuracy: 0.7770\n",
      "Epoch [311/500], Average Training Loss: 0.6308\n",
      "Epoch [311/500], Average Validation Loss: 0.6309, Average Validation Accuracy: 0.7771\n",
      "Epoch [312/500], Average Training Loss: 0.6304\n",
      "Epoch [312/500], Average Validation Loss: 0.6304, Average Validation Accuracy: 0.7771\n",
      "Epoch [313/500], Average Training Loss: 0.6299\n",
      "Epoch [313/500], Average Validation Loss: 0.6299, Average Validation Accuracy: 0.7772\n",
      "Epoch [314/500], Average Training Loss: 0.6294\n",
      "Epoch [314/500], Average Validation Loss: 0.6295, Average Validation Accuracy: 0.7771\n",
      "Epoch [315/500], Average Training Loss: 0.6290\n",
      "Epoch [315/500], Average Validation Loss: 0.6290, Average Validation Accuracy: 0.7771\n",
      "Epoch [316/500], Average Training Loss: 0.6285\n",
      "Epoch [316/500], Average Validation Loss: 0.6285, Average Validation Accuracy: 0.7771\n",
      "Epoch [317/500], Average Training Loss: 0.6280\n",
      "Epoch [317/500], Average Validation Loss: 0.6281, Average Validation Accuracy: 0.7772\n",
      "Epoch [318/500], Average Training Loss: 0.6276\n",
      "Epoch [318/500], Average Validation Loss: 0.6276, Average Validation Accuracy: 0.7772\n",
      "Epoch [319/500], Average Training Loss: 0.6271\n",
      "Epoch [319/500], Average Validation Loss: 0.6271, Average Validation Accuracy: 0.7772\n",
      "Epoch [320/500], Average Training Loss: 0.6266\n",
      "Epoch [320/500], Average Validation Loss: 0.6266, Average Validation Accuracy: 0.7772\n",
      "Epoch [321/500], Average Training Loss: 0.6261\n",
      "Epoch [321/500], Average Validation Loss: 0.6262, Average Validation Accuracy: 0.7772\n",
      "Epoch [322/500], Average Training Loss: 0.6256\n",
      "Epoch [322/500], Average Validation Loss: 0.6257, Average Validation Accuracy: 0.7773\n",
      "Epoch [323/500], Average Training Loss: 0.6251\n",
      "Epoch [323/500], Average Validation Loss: 0.6252, Average Validation Accuracy: 0.7775\n",
      "Epoch [324/500], Average Training Loss: 0.6246\n",
      "Epoch [324/500], Average Validation Loss: 0.6247, Average Validation Accuracy: 0.7778\n",
      "Epoch [325/500], Average Training Loss: 0.6241\n",
      "Epoch [325/500], Average Validation Loss: 0.6242, Average Validation Accuracy: 0.7778\n",
      "Epoch [326/500], Average Training Loss: 0.6236\n",
      "Epoch [326/500], Average Validation Loss: 0.6237, Average Validation Accuracy: 0.7779\n",
      "Epoch [327/500], Average Training Loss: 0.6231\n",
      "Epoch [327/500], Average Validation Loss: 0.6232, Average Validation Accuracy: 0.7779\n",
      "Epoch [328/500], Average Training Loss: 0.6226\n",
      "Epoch [328/500], Average Validation Loss: 0.6227, Average Validation Accuracy: 0.7780\n",
      "Epoch [329/500], Average Training Loss: 0.6221\n",
      "Epoch [329/500], Average Validation Loss: 0.6222, Average Validation Accuracy: 0.7779\n",
      "Epoch [330/500], Average Training Loss: 0.6216\n",
      "Epoch [330/500], Average Validation Loss: 0.6217, Average Validation Accuracy: 0.7779\n",
      "Epoch [331/500], Average Training Loss: 0.6211\n",
      "Epoch [331/500], Average Validation Loss: 0.6211, Average Validation Accuracy: 0.7780\n",
      "Epoch [332/500], Average Training Loss: 0.6206\n",
      "Epoch [332/500], Average Validation Loss: 0.6206, Average Validation Accuracy: 0.7779\n",
      "Epoch [333/500], Average Training Loss: 0.6201\n",
      "Epoch [333/500], Average Validation Loss: 0.6201, Average Validation Accuracy: 0.7779\n",
      "Epoch [334/500], Average Training Loss: 0.6195\n",
      "Epoch [334/500], Average Validation Loss: 0.6196, Average Validation Accuracy: 0.7779\n",
      "Epoch [335/500], Average Training Loss: 0.6190\n",
      "Epoch [335/500], Average Validation Loss: 0.6191, Average Validation Accuracy: 0.7780\n",
      "Epoch [336/500], Average Training Loss: 0.6185\n",
      "Epoch [336/500], Average Validation Loss: 0.6185, Average Validation Accuracy: 0.7780\n",
      "Epoch [337/500], Average Training Loss: 0.6180\n",
      "Epoch [337/500], Average Validation Loss: 0.6180, Average Validation Accuracy: 0.7780\n",
      "Epoch [338/500], Average Training Loss: 0.6174\n",
      "Epoch [338/500], Average Validation Loss: 0.6175, Average Validation Accuracy: 0.7780\n",
      "Epoch [339/500], Average Training Loss: 0.6169\n",
      "Epoch [339/500], Average Validation Loss: 0.6169, Average Validation Accuracy: 0.7780\n",
      "Epoch [340/500], Average Training Loss: 0.6163\n",
      "Epoch [340/500], Average Validation Loss: 0.6164, Average Validation Accuracy: 0.7780\n",
      "Epoch [341/500], Average Training Loss: 0.6158\n",
      "Epoch [341/500], Average Validation Loss: 0.6159, Average Validation Accuracy: 0.7781\n",
      "Epoch [342/500], Average Training Loss: 0.6152\n",
      "Epoch [342/500], Average Validation Loss: 0.6153, Average Validation Accuracy: 0.7781\n",
      "Epoch [343/500], Average Training Loss: 0.6147\n",
      "Epoch [343/500], Average Validation Loss: 0.6148, Average Validation Accuracy: 0.7780\n",
      "Epoch [344/500], Average Training Loss: 0.6141\n",
      "Epoch [344/500], Average Validation Loss: 0.6142, Average Validation Accuracy: 0.7781\n",
      "Epoch [345/500], Average Training Loss: 0.6136\n",
      "Epoch [345/500], Average Validation Loss: 0.6137, Average Validation Accuracy: 0.7781\n",
      "Epoch [346/500], Average Training Loss: 0.6130\n",
      "Epoch [346/500], Average Validation Loss: 0.6131, Average Validation Accuracy: 0.7780\n",
      "Epoch [347/500], Average Training Loss: 0.6125\n",
      "Epoch [347/500], Average Validation Loss: 0.6125, Average Validation Accuracy: 0.7779\n",
      "Epoch [348/500], Average Training Loss: 0.6119\n",
      "Epoch [348/500], Average Validation Loss: 0.6120, Average Validation Accuracy: 0.7781\n",
      "Epoch [349/500], Average Training Loss: 0.6113\n",
      "Epoch [349/500], Average Validation Loss: 0.6114, Average Validation Accuracy: 0.7781\n",
      "Epoch [350/500], Average Training Loss: 0.6108\n",
      "Epoch [350/500], Average Validation Loss: 0.6108, Average Validation Accuracy: 0.7781\n",
      "Epoch [351/500], Average Training Loss: 0.6102\n",
      "Epoch [351/500], Average Validation Loss: 0.6103, Average Validation Accuracy: 0.7782\n",
      "Epoch [352/500], Average Training Loss: 0.6096\n",
      "Epoch [352/500], Average Validation Loss: 0.6097, Average Validation Accuracy: 0.7782\n",
      "Epoch [353/500], Average Training Loss: 0.6090\n",
      "Epoch [353/500], Average Validation Loss: 0.6091, Average Validation Accuracy: 0.7782\n",
      "Epoch [354/500], Average Training Loss: 0.6085\n",
      "Epoch [354/500], Average Validation Loss: 0.6085, Average Validation Accuracy: 0.7782\n",
      "Epoch [355/500], Average Training Loss: 0.6079\n",
      "Epoch [355/500], Average Validation Loss: 0.6080, Average Validation Accuracy: 0.7783\n",
      "Epoch [356/500], Average Training Loss: 0.6073\n",
      "Epoch [356/500], Average Validation Loss: 0.6074, Average Validation Accuracy: 0.7783\n",
      "Epoch [357/500], Average Training Loss: 0.6067\n",
      "Epoch [357/500], Average Validation Loss: 0.6068, Average Validation Accuracy: 0.7784\n",
      "Epoch [358/500], Average Training Loss: 0.6061\n",
      "Epoch [358/500], Average Validation Loss: 0.6062, Average Validation Accuracy: 0.7784\n",
      "Epoch [359/500], Average Training Loss: 0.6055\n",
      "Epoch [359/500], Average Validation Loss: 0.6056, Average Validation Accuracy: 0.7785\n",
      "Epoch [360/500], Average Training Loss: 0.6049\n",
      "Epoch [360/500], Average Validation Loss: 0.6050, Average Validation Accuracy: 0.7788\n",
      "Epoch [361/500], Average Training Loss: 0.6043\n",
      "Epoch [361/500], Average Validation Loss: 0.6044, Average Validation Accuracy: 0.7788\n",
      "Epoch [362/500], Average Training Loss: 0.6037\n",
      "Epoch [362/500], Average Validation Loss: 0.6038, Average Validation Accuracy: 0.7788\n",
      "Epoch [363/500], Average Training Loss: 0.6031\n",
      "Epoch [363/500], Average Validation Loss: 0.6032, Average Validation Accuracy: 0.7788\n",
      "Epoch [364/500], Average Training Loss: 0.6025\n",
      "Epoch [364/500], Average Validation Loss: 0.6026, Average Validation Accuracy: 0.7789\n",
      "Epoch [365/500], Average Training Loss: 0.6019\n",
      "Epoch [365/500], Average Validation Loss: 0.6020, Average Validation Accuracy: 0.7789\n",
      "Epoch [366/500], Average Training Loss: 0.6013\n",
      "Epoch [366/500], Average Validation Loss: 0.6014, Average Validation Accuracy: 0.7790\n",
      "Epoch [367/500], Average Training Loss: 0.6007\n",
      "Epoch [367/500], Average Validation Loss: 0.6008, Average Validation Accuracy: 0.7791\n",
      "Epoch [368/500], Average Training Loss: 0.6000\n",
      "Epoch [368/500], Average Validation Loss: 0.6002, Average Validation Accuracy: 0.7789\n",
      "Epoch [369/500], Average Training Loss: 0.5994\n",
      "Epoch [369/500], Average Validation Loss: 0.5995, Average Validation Accuracy: 0.7789\n",
      "Epoch [370/500], Average Training Loss: 0.5988\n",
      "Epoch [370/500], Average Validation Loss: 0.5989, Average Validation Accuracy: 0.7788\n",
      "Epoch [371/500], Average Training Loss: 0.5982\n",
      "Epoch [371/500], Average Validation Loss: 0.5983, Average Validation Accuracy: 0.7790\n",
      "Epoch [372/500], Average Training Loss: 0.5976\n",
      "Epoch [372/500], Average Validation Loss: 0.5977, Average Validation Accuracy: 0.7789\n",
      "Epoch [373/500], Average Training Loss: 0.5969\n",
      "Epoch [373/500], Average Validation Loss: 0.5970, Average Validation Accuracy: 0.7790\n",
      "Epoch [374/500], Average Training Loss: 0.5963\n",
      "Epoch [374/500], Average Validation Loss: 0.5964, Average Validation Accuracy: 0.7789\n",
      "Epoch [375/500], Average Training Loss: 0.5957\n",
      "Epoch [375/500], Average Validation Loss: 0.5958, Average Validation Accuracy: 0.7790\n",
      "Epoch [376/500], Average Training Loss: 0.5950\n",
      "Epoch [376/500], Average Validation Loss: 0.5952, Average Validation Accuracy: 0.7791\n",
      "Epoch [377/500], Average Training Loss: 0.5944\n",
      "Epoch [377/500], Average Validation Loss: 0.5945, Average Validation Accuracy: 0.7792\n",
      "Epoch [378/500], Average Training Loss: 0.5937\n",
      "Epoch [378/500], Average Validation Loss: 0.5939, Average Validation Accuracy: 0.7792\n",
      "Epoch [379/500], Average Training Loss: 0.5931\n",
      "Epoch [379/500], Average Validation Loss: 0.5932, Average Validation Accuracy: 0.7794\n",
      "Epoch [380/500], Average Training Loss: 0.5924\n",
      "Epoch [380/500], Average Validation Loss: 0.5926, Average Validation Accuracy: 0.7794\n",
      "Epoch [381/500], Average Training Loss: 0.5918\n",
      "Epoch [381/500], Average Validation Loss: 0.5919, Average Validation Accuracy: 0.7795\n",
      "Epoch [382/500], Average Training Loss: 0.5912\n",
      "Epoch [382/500], Average Validation Loss: 0.5913, Average Validation Accuracy: 0.7794\n",
      "Epoch [383/500], Average Training Loss: 0.5905\n",
      "Epoch [383/500], Average Validation Loss: 0.5907, Average Validation Accuracy: 0.7796\n",
      "Epoch [384/500], Average Training Loss: 0.5898\n",
      "Epoch [384/500], Average Validation Loss: 0.5900, Average Validation Accuracy: 0.7795\n",
      "Epoch [385/500], Average Training Loss: 0.5892\n",
      "Epoch [385/500], Average Validation Loss: 0.5894, Average Validation Accuracy: 0.7796\n",
      "Epoch [386/500], Average Training Loss: 0.5885\n",
      "Epoch [386/500], Average Validation Loss: 0.5887, Average Validation Accuracy: 0.7795\n",
      "Epoch [387/500], Average Training Loss: 0.5879\n",
      "Epoch [387/500], Average Validation Loss: 0.5880, Average Validation Accuracy: 0.7797\n",
      "Epoch [388/500], Average Training Loss: 0.5872\n",
      "Epoch [388/500], Average Validation Loss: 0.5874, Average Validation Accuracy: 0.7799\n",
      "Epoch [389/500], Average Training Loss: 0.5865\n",
      "Epoch [389/500], Average Validation Loss: 0.5867, Average Validation Accuracy: 0.7800\n",
      "Epoch [390/500], Average Training Loss: 0.5859\n",
      "Epoch [390/500], Average Validation Loss: 0.5861, Average Validation Accuracy: 0.7800\n",
      "Epoch [391/500], Average Training Loss: 0.5852\n",
      "Epoch [391/500], Average Validation Loss: 0.5854, Average Validation Accuracy: 0.7801\n",
      "Epoch [392/500], Average Training Loss: 0.5845\n",
      "Epoch [392/500], Average Validation Loss: 0.5847, Average Validation Accuracy: 0.7801\n",
      "Epoch [393/500], Average Training Loss: 0.5839\n",
      "Epoch [393/500], Average Validation Loss: 0.5841, Average Validation Accuracy: 0.7802\n",
      "Epoch [394/500], Average Training Loss: 0.5832\n",
      "Epoch [394/500], Average Validation Loss: 0.5834, Average Validation Accuracy: 0.7802\n",
      "Epoch [395/500], Average Training Loss: 0.5825\n",
      "Epoch [395/500], Average Validation Loss: 0.5827, Average Validation Accuracy: 0.7801\n",
      "Epoch [396/500], Average Training Loss: 0.5819\n",
      "Epoch [396/500], Average Validation Loss: 0.5821, Average Validation Accuracy: 0.7801\n",
      "Epoch [397/500], Average Training Loss: 0.5812\n",
      "Epoch [397/500], Average Validation Loss: 0.5814, Average Validation Accuracy: 0.7802\n",
      "Epoch [398/500], Average Training Loss: 0.5805\n",
      "Epoch [398/500], Average Validation Loss: 0.5807, Average Validation Accuracy: 0.7802\n",
      "Epoch [399/500], Average Training Loss: 0.5798\n",
      "Epoch [399/500], Average Validation Loss: 0.5800, Average Validation Accuracy: 0.7803\n",
      "Epoch [400/500], Average Training Loss: 0.5791\n",
      "Epoch [400/500], Average Validation Loss: 0.5794, Average Validation Accuracy: 0.7802\n",
      "Epoch [401/500], Average Training Loss: 0.5785\n",
      "Epoch [401/500], Average Validation Loss: 0.5787, Average Validation Accuracy: 0.7802\n",
      "Epoch [402/500], Average Training Loss: 0.5778\n",
      "Epoch [402/500], Average Validation Loss: 0.5780, Average Validation Accuracy: 0.7803\n",
      "Epoch [403/500], Average Training Loss: 0.5771\n",
      "Epoch [403/500], Average Validation Loss: 0.5773, Average Validation Accuracy: 0.7801\n",
      "Epoch [404/500], Average Training Loss: 0.5764\n",
      "Epoch [404/500], Average Validation Loss: 0.5766, Average Validation Accuracy: 0.7802\n",
      "Epoch [405/500], Average Training Loss: 0.5757\n",
      "Epoch [405/500], Average Validation Loss: 0.5760, Average Validation Accuracy: 0.7802\n",
      "Epoch [406/500], Average Training Loss: 0.5750\n",
      "Epoch [406/500], Average Validation Loss: 0.5753, Average Validation Accuracy: 0.7802\n",
      "Epoch [407/500], Average Training Loss: 0.5743\n",
      "Epoch [407/500], Average Validation Loss: 0.5746, Average Validation Accuracy: 0.7802\n",
      "Epoch [408/500], Average Training Loss: 0.5737\n",
      "Epoch [408/500], Average Validation Loss: 0.5739, Average Validation Accuracy: 0.7803\n",
      "Epoch [409/500], Average Training Loss: 0.5730\n",
      "Epoch [409/500], Average Validation Loss: 0.5732, Average Validation Accuracy: 0.7804\n",
      "Epoch [410/500], Average Training Loss: 0.5723\n",
      "Epoch [410/500], Average Validation Loss: 0.5725, Average Validation Accuracy: 0.7802\n",
      "Epoch [411/500], Average Training Loss: 0.5716\n",
      "Epoch [411/500], Average Validation Loss: 0.5719, Average Validation Accuracy: 0.7802\n",
      "Epoch [412/500], Average Training Loss: 0.5709\n",
      "Epoch [412/500], Average Validation Loss: 0.5712, Average Validation Accuracy: 0.7802\n",
      "Epoch [413/500], Average Training Loss: 0.5702\n",
      "Epoch [413/500], Average Validation Loss: 0.5705, Average Validation Accuracy: 0.7802\n",
      "Epoch [414/500], Average Training Loss: 0.5695\n",
      "Epoch [414/500], Average Validation Loss: 0.5698, Average Validation Accuracy: 0.7803\n",
      "Epoch [415/500], Average Training Loss: 0.5688\n",
      "Epoch [415/500], Average Validation Loss: 0.5691, Average Validation Accuracy: 0.7803\n",
      "Epoch [416/500], Average Training Loss: 0.5681\n",
      "Epoch [416/500], Average Validation Loss: 0.5684, Average Validation Accuracy: 0.7805\n",
      "Epoch [417/500], Average Training Loss: 0.5674\n",
      "Epoch [417/500], Average Validation Loss: 0.5677, Average Validation Accuracy: 0.7805\n",
      "Epoch [418/500], Average Training Loss: 0.5667\n",
      "Epoch [418/500], Average Validation Loss: 0.5670, Average Validation Accuracy: 0.7805\n",
      "Epoch [419/500], Average Training Loss: 0.5660\n",
      "Epoch [419/500], Average Validation Loss: 0.5664, Average Validation Accuracy: 0.7806\n",
      "Epoch [420/500], Average Training Loss: 0.5653\n",
      "Epoch [420/500], Average Validation Loss: 0.5657, Average Validation Accuracy: 0.7809\n",
      "Epoch [421/500], Average Training Loss: 0.5646\n",
      "Epoch [421/500], Average Validation Loss: 0.5650, Average Validation Accuracy: 0.7807\n",
      "Epoch [422/500], Average Training Loss: 0.5639\n",
      "Epoch [422/500], Average Validation Loss: 0.5643, Average Validation Accuracy: 0.7810\n",
      "Epoch [423/500], Average Training Loss: 0.5633\n",
      "Epoch [423/500], Average Validation Loss: 0.5636, Average Validation Accuracy: 0.7811\n",
      "Epoch [424/500], Average Training Loss: 0.5626\n",
      "Epoch [424/500], Average Validation Loss: 0.5629, Average Validation Accuracy: 0.7812\n",
      "Epoch [425/500], Average Training Loss: 0.5619\n",
      "Epoch [425/500], Average Validation Loss: 0.5622, Average Validation Accuracy: 0.7812\n",
      "Epoch [426/500], Average Training Loss: 0.5612\n",
      "Epoch [426/500], Average Validation Loss: 0.5615, Average Validation Accuracy: 0.7813\n",
      "Epoch [427/500], Average Training Loss: 0.5605\n",
      "Epoch [427/500], Average Validation Loss: 0.5608, Average Validation Accuracy: 0.7815\n",
      "Epoch [428/500], Average Training Loss: 0.5598\n",
      "Epoch [428/500], Average Validation Loss: 0.5602, Average Validation Accuracy: 0.7815\n",
      "Epoch [429/500], Average Training Loss: 0.5591\n",
      "Epoch [429/500], Average Validation Loss: 0.5595, Average Validation Accuracy: 0.7814\n",
      "Epoch [430/500], Average Training Loss: 0.5584\n",
      "Epoch [430/500], Average Validation Loss: 0.5588, Average Validation Accuracy: 0.7815\n",
      "Epoch [431/500], Average Training Loss: 0.5577\n",
      "Epoch [431/500], Average Validation Loss: 0.5581, Average Validation Accuracy: 0.7815\n",
      "Epoch [432/500], Average Training Loss: 0.5570\n",
      "Epoch [432/500], Average Validation Loss: 0.5574, Average Validation Accuracy: 0.7816\n",
      "Epoch [433/500], Average Training Loss: 0.5563\n",
      "Epoch [433/500], Average Validation Loss: 0.5567, Average Validation Accuracy: 0.7815\n",
      "Epoch [434/500], Average Training Loss: 0.5556\n",
      "Epoch [434/500], Average Validation Loss: 0.5560, Average Validation Accuracy: 0.7816\n",
      "Epoch [435/500], Average Training Loss: 0.5549\n",
      "Epoch [435/500], Average Validation Loss: 0.5554, Average Validation Accuracy: 0.7816\n",
      "Epoch [436/500], Average Training Loss: 0.5542\n",
      "Epoch [436/500], Average Validation Loss: 0.5547, Average Validation Accuracy: 0.7816\n",
      "Epoch [437/500], Average Training Loss: 0.5535\n",
      "Epoch [437/500], Average Validation Loss: 0.5540, Average Validation Accuracy: 0.7815\n",
      "Epoch [438/500], Average Training Loss: 0.5529\n",
      "Epoch [438/500], Average Validation Loss: 0.5533, Average Validation Accuracy: 0.7815\n",
      "Epoch [439/500], Average Training Loss: 0.5522\n",
      "Epoch [439/500], Average Validation Loss: 0.5526, Average Validation Accuracy: 0.7815\n",
      "Epoch [440/500], Average Training Loss: 0.5515\n",
      "Epoch [440/500], Average Validation Loss: 0.5520, Average Validation Accuracy: 0.7816\n",
      "Epoch [441/500], Average Training Loss: 0.5508\n",
      "Epoch [441/500], Average Validation Loss: 0.5513, Average Validation Accuracy: 0.7817\n",
      "Epoch [442/500], Average Training Loss: 0.5501\n",
      "Epoch [442/500], Average Validation Loss: 0.5506, Average Validation Accuracy: 0.7818\n",
      "Epoch [443/500], Average Training Loss: 0.5494\n",
      "Epoch [443/500], Average Validation Loss: 0.5499, Average Validation Accuracy: 0.7819\n",
      "Epoch [444/500], Average Training Loss: 0.5487\n",
      "Epoch [444/500], Average Validation Loss: 0.5492, Average Validation Accuracy: 0.7819\n",
      "Epoch [445/500], Average Training Loss: 0.5481\n",
      "Epoch [445/500], Average Validation Loss: 0.5486, Average Validation Accuracy: 0.7819\n",
      "Epoch [446/500], Average Training Loss: 0.5474\n",
      "Epoch [446/500], Average Validation Loss: 0.5479, Average Validation Accuracy: 0.7820\n",
      "Epoch [447/500], Average Training Loss: 0.5467\n",
      "Epoch [447/500], Average Validation Loss: 0.5472, Average Validation Accuracy: 0.7821\n",
      "Epoch [448/500], Average Training Loss: 0.5460\n",
      "Epoch [448/500], Average Validation Loss: 0.5466, Average Validation Accuracy: 0.7821\n",
      "Epoch [449/500], Average Training Loss: 0.5454\n",
      "Epoch [449/500], Average Validation Loss: 0.5459, Average Validation Accuracy: 0.7820\n",
      "Epoch [450/500], Average Training Loss: 0.5447\n",
      "Epoch [450/500], Average Validation Loss: 0.5452, Average Validation Accuracy: 0.7820\n",
      "Epoch [451/500], Average Training Loss: 0.5440\n",
      "Epoch [451/500], Average Validation Loss: 0.5446, Average Validation Accuracy: 0.7820\n",
      "Epoch [452/500], Average Training Loss: 0.5433\n",
      "Epoch [452/500], Average Validation Loss: 0.5439, Average Validation Accuracy: 0.7819\n",
      "Epoch [453/500], Average Training Loss: 0.5427\n",
      "Epoch [453/500], Average Validation Loss: 0.5432, Average Validation Accuracy: 0.7817\n",
      "Epoch [454/500], Average Training Loss: 0.5420\n",
      "Epoch [454/500], Average Validation Loss: 0.5426, Average Validation Accuracy: 0.7817\n",
      "Epoch [455/500], Average Training Loss: 0.5413\n",
      "Epoch [455/500], Average Validation Loss: 0.5419, Average Validation Accuracy: 0.7819\n",
      "Epoch [456/500], Average Training Loss: 0.5407\n",
      "Epoch [456/500], Average Validation Loss: 0.5413, Average Validation Accuracy: 0.7821\n",
      "Epoch [457/500], Average Training Loss: 0.5400\n",
      "Epoch [457/500], Average Validation Loss: 0.5406, Average Validation Accuracy: 0.7821\n",
      "Epoch [458/500], Average Training Loss: 0.5393\n",
      "Epoch [458/500], Average Validation Loss: 0.5400, Average Validation Accuracy: 0.7821\n",
      "Epoch [459/500], Average Training Loss: 0.5387\n",
      "Epoch [459/500], Average Validation Loss: 0.5393, Average Validation Accuracy: 0.7822\n",
      "Epoch [460/500], Average Training Loss: 0.5380\n",
      "Epoch [460/500], Average Validation Loss: 0.5387, Average Validation Accuracy: 0.7823\n",
      "Epoch [461/500], Average Training Loss: 0.5374\n",
      "Epoch [461/500], Average Validation Loss: 0.5380, Average Validation Accuracy: 0.7823\n",
      "Epoch [462/500], Average Training Loss: 0.5367\n",
      "Epoch [462/500], Average Validation Loss: 0.5374, Average Validation Accuracy: 0.7823\n",
      "Epoch [463/500], Average Training Loss: 0.5361\n",
      "Epoch [463/500], Average Validation Loss: 0.5368, Average Validation Accuracy: 0.7824\n",
      "Epoch [464/500], Average Training Loss: 0.5354\n",
      "Epoch [464/500], Average Validation Loss: 0.5361, Average Validation Accuracy: 0.7826\n",
      "Epoch [465/500], Average Training Loss: 0.5348\n",
      "Epoch [465/500], Average Validation Loss: 0.5355, Average Validation Accuracy: 0.7826\n",
      "Epoch [466/500], Average Training Loss: 0.5342\n",
      "Epoch [466/500], Average Validation Loss: 0.5349, Average Validation Accuracy: 0.7825\n",
      "Epoch [467/500], Average Training Loss: 0.5335\n",
      "Epoch [467/500], Average Validation Loss: 0.5342, Average Validation Accuracy: 0.7825\n",
      "Epoch [468/500], Average Training Loss: 0.5329\n",
      "Epoch [468/500], Average Validation Loss: 0.5336, Average Validation Accuracy: 0.7825\n",
      "Epoch [469/500], Average Training Loss: 0.5322\n",
      "Epoch [469/500], Average Validation Loss: 0.5330, Average Validation Accuracy: 0.7825\n",
      "Epoch [470/500], Average Training Loss: 0.5316\n",
      "Epoch [470/500], Average Validation Loss: 0.5324, Average Validation Accuracy: 0.7825\n",
      "Epoch [471/500], Average Training Loss: 0.5310\n",
      "Epoch [471/500], Average Validation Loss: 0.5317, Average Validation Accuracy: 0.7825\n",
      "Epoch [472/500], Average Training Loss: 0.5304\n",
      "Epoch [472/500], Average Validation Loss: 0.5311, Average Validation Accuracy: 0.7824\n",
      "Epoch [473/500], Average Training Loss: 0.5297\n",
      "Epoch [473/500], Average Validation Loss: 0.5305, Average Validation Accuracy: 0.7824\n",
      "Epoch [474/500], Average Training Loss: 0.5291\n",
      "Epoch [474/500], Average Validation Loss: 0.5299, Average Validation Accuracy: 0.7825\n",
      "Epoch [475/500], Average Training Loss: 0.5285\n",
      "Epoch [475/500], Average Validation Loss: 0.5293, Average Validation Accuracy: 0.7825\n",
      "Epoch [476/500], Average Training Loss: 0.5279\n",
      "Epoch [476/500], Average Validation Loss: 0.5287, Average Validation Accuracy: 0.7825\n",
      "Epoch [477/500], Average Training Loss: 0.5273\n",
      "Epoch [477/500], Average Validation Loss: 0.5281, Average Validation Accuracy: 0.7826\n",
      "Epoch [478/500], Average Training Loss: 0.5267\n",
      "Epoch [478/500], Average Validation Loss: 0.5275, Average Validation Accuracy: 0.7826\n",
      "Epoch [479/500], Average Training Loss: 0.5261\n",
      "Epoch [479/500], Average Validation Loss: 0.5269, Average Validation Accuracy: 0.7826\n",
      "Epoch [480/500], Average Training Loss: 0.5255\n",
      "Epoch [480/500], Average Validation Loss: 0.5263, Average Validation Accuracy: 0.7828\n",
      "Epoch [481/500], Average Training Loss: 0.5249\n",
      "Epoch [481/500], Average Validation Loss: 0.5257, Average Validation Accuracy: 0.7829\n",
      "Epoch [482/500], Average Training Loss: 0.5243\n",
      "Epoch [482/500], Average Validation Loss: 0.5251, Average Validation Accuracy: 0.7830\n",
      "Epoch [483/500], Average Training Loss: 0.5237\n",
      "Epoch [483/500], Average Validation Loss: 0.5245, Average Validation Accuracy: 0.7831\n",
      "Epoch [484/500], Average Training Loss: 0.5231\n",
      "Epoch [484/500], Average Validation Loss: 0.5240, Average Validation Accuracy: 0.7831\n",
      "Epoch [485/500], Average Training Loss: 0.5225\n",
      "Epoch [485/500], Average Validation Loss: 0.5234, Average Validation Accuracy: 0.7831\n",
      "Epoch [486/500], Average Training Loss: 0.5219\n",
      "Epoch [486/500], Average Validation Loss: 0.5228, Average Validation Accuracy: 0.7832\n",
      "Epoch [487/500], Average Training Loss: 0.5213\n",
      "Epoch [487/500], Average Validation Loss: 0.5222, Average Validation Accuracy: 0.7833\n",
      "Epoch [488/500], Average Training Loss: 0.5207\n",
      "Epoch [488/500], Average Validation Loss: 0.5217, Average Validation Accuracy: 0.7833\n",
      "Epoch [489/500], Average Training Loss: 0.5202\n",
      "Epoch [489/500], Average Validation Loss: 0.5211, Average Validation Accuracy: 0.7832\n",
      "Epoch [490/500], Average Training Loss: 0.5196\n",
      "Epoch [490/500], Average Validation Loss: 0.5206, Average Validation Accuracy: 0.7831\n",
      "Epoch [491/500], Average Training Loss: 0.5190\n",
      "Epoch [491/500], Average Validation Loss: 0.5200, Average Validation Accuracy: 0.7831\n",
      "Epoch [492/500], Average Training Loss: 0.5185\n",
      "Epoch [492/500], Average Validation Loss: 0.5194, Average Validation Accuracy: 0.7830\n",
      "Epoch [493/500], Average Training Loss: 0.5179\n",
      "Epoch [493/500], Average Validation Loss: 0.5189, Average Validation Accuracy: 0.7831\n",
      "Epoch [494/500], Average Training Loss: 0.5173\n",
      "Epoch [494/500], Average Validation Loss: 0.5183, Average Validation Accuracy: 0.7831\n",
      "Epoch [495/500], Average Training Loss: 0.5168\n",
      "Epoch [495/500], Average Validation Loss: 0.5178, Average Validation Accuracy: 0.7831\n",
      "Epoch [496/500], Average Training Loss: 0.5162\n",
      "Epoch [496/500], Average Validation Loss: 0.5173, Average Validation Accuracy: 0.7829\n",
      "Epoch [497/500], Average Training Loss: 0.5157\n",
      "Epoch [497/500], Average Validation Loss: 0.5167, Average Validation Accuracy: 0.7829\n",
      "Epoch [498/500], Average Training Loss: 0.5151\n",
      "Epoch [498/500], Average Validation Loss: 0.5162, Average Validation Accuracy: 0.7830\n",
      "Epoch [499/500], Average Training Loss: 0.5146\n",
      "Epoch [499/500], Average Validation Loss: 0.5157, Average Validation Accuracy: 0.7829\n",
      "Epoch [500/500], Average Training Loss: 0.5141\n",
      "Epoch [500/500], Average Validation Loss: 0.5151, Average Validation Accuracy: 0.7828\n",
      "Best Validation Accuracy: 0.7833 at epoch 487 for trial 13\n",
      "Epoch [1/500], Average Training Loss: 0.6812\n",
      "Epoch [1/500], Average Validation Loss: 0.6727, Average Validation Accuracy: 0.7352\n",
      "Epoch [2/500], Average Training Loss: 0.6646\n",
      "Epoch [2/500], Average Validation Loss: 0.6559, Average Validation Accuracy: 0.7591\n",
      "Epoch [3/500], Average Training Loss: 0.6464\n",
      "Epoch [3/500], Average Validation Loss: 0.6362, Average Validation Accuracy: 0.7620\n",
      "Epoch [4/500], Average Training Loss: 0.6248\n",
      "Epoch [4/500], Average Validation Loss: 0.6132, Average Validation Accuracy: 0.7661\n",
      "Epoch [5/500], Average Training Loss: 0.6007\n",
      "Epoch [5/500], Average Validation Loss: 0.5884, Average Validation Accuracy: 0.7698\n",
      "Epoch [6/500], Average Training Loss: 0.5755\n",
      "Epoch [6/500], Average Validation Loss: 0.5632, Average Validation Accuracy: 0.7745\n",
      "Epoch [7/500], Average Training Loss: 0.5504\n",
      "Epoch [7/500], Average Validation Loss: 0.5392, Average Validation Accuracy: 0.7784\n",
      "Epoch [8/500], Average Training Loss: 0.5275\n",
      "Epoch [8/500], Average Validation Loss: 0.5179, Average Validation Accuracy: 0.7803\n",
      "Epoch [9/500], Average Training Loss: 0.5073\n",
      "Epoch [9/500], Average Validation Loss: 0.4998, Average Validation Accuracy: 0.7833\n",
      "Epoch [10/500], Average Training Loss: 0.4910\n",
      "Epoch [10/500], Average Validation Loss: 0.4856, Average Validation Accuracy: 0.7870\n",
      "Epoch [11/500], Average Training Loss: 0.4782\n",
      "Epoch [11/500], Average Validation Loss: 0.4751, Average Validation Accuracy: 0.7886\n",
      "Epoch [12/500], Average Training Loss: 0.4691\n",
      "Epoch [12/500], Average Validation Loss: 0.4679, Average Validation Accuracy: 0.7909\n",
      "Epoch [13/500], Average Training Loss: 0.4627\n",
      "Epoch [13/500], Average Validation Loss: 0.4631, Average Validation Accuracy: 0.7921\n",
      "Epoch [14/500], Average Training Loss: 0.4586\n",
      "Epoch [14/500], Average Validation Loss: 0.4601, Average Validation Accuracy: 0.7925\n",
      "Epoch [15/500], Average Training Loss: 0.4558\n",
      "Epoch [15/500], Average Validation Loss: 0.4583, Average Validation Accuracy: 0.7931\n",
      "Epoch [16/500], Average Training Loss: 0.4540\n",
      "Epoch [16/500], Average Validation Loss: 0.4570, Average Validation Accuracy: 0.7926\n",
      "Epoch [17/500], Average Training Loss: 0.4528\n",
      "Epoch [17/500], Average Validation Loss: 0.4561, Average Validation Accuracy: 0.7929\n",
      "Epoch [18/500], Average Training Loss: 0.4517\n",
      "Epoch [18/500], Average Validation Loss: 0.4551, Average Validation Accuracy: 0.7938\n",
      "Epoch [19/500], Average Training Loss: 0.4508\n",
      "Epoch [19/500], Average Validation Loss: 0.4541, Average Validation Accuracy: 0.7950\n",
      "Epoch [20/500], Average Training Loss: 0.4499\n",
      "Epoch [20/500], Average Validation Loss: 0.4533, Average Validation Accuracy: 0.7951\n",
      "Epoch [21/500], Average Training Loss: 0.4490\n",
      "Epoch [21/500], Average Validation Loss: 0.4525, Average Validation Accuracy: 0.7952\n",
      "Epoch [22/500], Average Training Loss: 0.4485\n",
      "Epoch [22/500], Average Validation Loss: 0.4517, Average Validation Accuracy: 0.7958\n",
      "Epoch [23/500], Average Training Loss: 0.4474\n",
      "Epoch [23/500], Average Validation Loss: 0.4510, Average Validation Accuracy: 0.7965\n",
      "Epoch [24/500], Average Training Loss: 0.4469\n",
      "Epoch [24/500], Average Validation Loss: 0.4503, Average Validation Accuracy: 0.7966\n",
      "Epoch [25/500], Average Training Loss: 0.4465\n",
      "Epoch [25/500], Average Validation Loss: 0.4496, Average Validation Accuracy: 0.7971\n",
      "Epoch [26/500], Average Training Loss: 0.4455\n",
      "Epoch [26/500], Average Validation Loss: 0.4490, Average Validation Accuracy: 0.7981\n",
      "Epoch [27/500], Average Training Loss: 0.4447\n",
      "Epoch [27/500], Average Validation Loss: 0.4484, Average Validation Accuracy: 0.7986\n",
      "Epoch [28/500], Average Training Loss: 0.4442\n",
      "Epoch [28/500], Average Validation Loss: 0.4478, Average Validation Accuracy: 0.7990\n",
      "Epoch [29/500], Average Training Loss: 0.4438\n",
      "Epoch [29/500], Average Validation Loss: 0.4472, Average Validation Accuracy: 0.7998\n",
      "Epoch [30/500], Average Training Loss: 0.4433\n",
      "Epoch [30/500], Average Validation Loss: 0.4467, Average Validation Accuracy: 0.7998\n",
      "Epoch [31/500], Average Training Loss: 0.4425\n",
      "Epoch [31/500], Average Validation Loss: 0.4462, Average Validation Accuracy: 0.8001\n",
      "Epoch [32/500], Average Training Loss: 0.4423\n",
      "Epoch [32/500], Average Validation Loss: 0.4456, Average Validation Accuracy: 0.8008\n",
      "Epoch [33/500], Average Training Loss: 0.4419\n",
      "Epoch [33/500], Average Validation Loss: 0.4451, Average Validation Accuracy: 0.8011\n",
      "Epoch [34/500], Average Training Loss: 0.4413\n",
      "Epoch [34/500], Average Validation Loss: 0.4446, Average Validation Accuracy: 0.8012\n",
      "Epoch [35/500], Average Training Loss: 0.4406\n",
      "Epoch [35/500], Average Validation Loss: 0.4442, Average Validation Accuracy: 0.8017\n",
      "Epoch [36/500], Average Training Loss: 0.4405\n",
      "Epoch [36/500], Average Validation Loss: 0.4437, Average Validation Accuracy: 0.8020\n",
      "Epoch [37/500], Average Training Loss: 0.4400\n",
      "Epoch [37/500], Average Validation Loss: 0.4433, Average Validation Accuracy: 0.8023\n",
      "Epoch [38/500], Average Training Loss: 0.4397\n",
      "Epoch [38/500], Average Validation Loss: 0.4429, Average Validation Accuracy: 0.8026\n",
      "Epoch [39/500], Average Training Loss: 0.4393\n",
      "Epoch [39/500], Average Validation Loss: 0.4425, Average Validation Accuracy: 0.8029\n",
      "Epoch [40/500], Average Training Loss: 0.4387\n",
      "Epoch [40/500], Average Validation Loss: 0.4421, Average Validation Accuracy: 0.8031\n",
      "Epoch [41/500], Average Training Loss: 0.4380\n",
      "Epoch [41/500], Average Validation Loss: 0.4417, Average Validation Accuracy: 0.8032\n",
      "Epoch [42/500], Average Training Loss: 0.4380\n",
      "Epoch [42/500], Average Validation Loss: 0.4414, Average Validation Accuracy: 0.8036\n",
      "Epoch [43/500], Average Training Loss: 0.4372\n",
      "Epoch [43/500], Average Validation Loss: 0.4411, Average Validation Accuracy: 0.8034\n",
      "Epoch [44/500], Average Training Loss: 0.4373\n",
      "Epoch [44/500], Average Validation Loss: 0.4407, Average Validation Accuracy: 0.8038\n",
      "Epoch [45/500], Average Training Loss: 0.4369\n",
      "Epoch [45/500], Average Validation Loss: 0.4404, Average Validation Accuracy: 0.8041\n",
      "Epoch [46/500], Average Training Loss: 0.4369\n",
      "Epoch [46/500], Average Validation Loss: 0.4401, Average Validation Accuracy: 0.8042\n",
      "Epoch [47/500], Average Training Loss: 0.4362\n",
      "Epoch [47/500], Average Validation Loss: 0.4398, Average Validation Accuracy: 0.8041\n",
      "Epoch [48/500], Average Training Loss: 0.4362\n",
      "Epoch [48/500], Average Validation Loss: 0.4395, Average Validation Accuracy: 0.8045\n",
      "Epoch [49/500], Average Training Loss: 0.4360\n",
      "Epoch [49/500], Average Validation Loss: 0.4392, Average Validation Accuracy: 0.8045\n",
      "Epoch [50/500], Average Training Loss: 0.4355\n",
      "Epoch [50/500], Average Validation Loss: 0.4389, Average Validation Accuracy: 0.8047\n",
      "Epoch [51/500], Average Training Loss: 0.4352\n",
      "Epoch [51/500], Average Validation Loss: 0.4386, Average Validation Accuracy: 0.8052\n",
      "Epoch [52/500], Average Training Loss: 0.4348\n",
      "Epoch [52/500], Average Validation Loss: 0.4384, Average Validation Accuracy: 0.8050\n",
      "Epoch [53/500], Average Training Loss: 0.4349\n",
      "Epoch [53/500], Average Validation Loss: 0.4381, Average Validation Accuracy: 0.8052\n",
      "Epoch [54/500], Average Training Loss: 0.4345\n",
      "Epoch [54/500], Average Validation Loss: 0.4379, Average Validation Accuracy: 0.8053\n",
      "Epoch [55/500], Average Training Loss: 0.4339\n",
      "Epoch [55/500], Average Validation Loss: 0.4376, Average Validation Accuracy: 0.8058\n",
      "Epoch [56/500], Average Training Loss: 0.4342\n",
      "Epoch [56/500], Average Validation Loss: 0.4374, Average Validation Accuracy: 0.8057\n",
      "Epoch [57/500], Average Training Loss: 0.4338\n",
      "Epoch [57/500], Average Validation Loss: 0.4372, Average Validation Accuracy: 0.8056\n",
      "Epoch [58/500], Average Training Loss: 0.4336\n",
      "Epoch [58/500], Average Validation Loss: 0.4370, Average Validation Accuracy: 0.8054\n",
      "Epoch [59/500], Average Training Loss: 0.4332\n",
      "Epoch [59/500], Average Validation Loss: 0.4368, Average Validation Accuracy: 0.8072\n",
      "Epoch [60/500], Average Training Loss: 0.4331\n",
      "Epoch [60/500], Average Validation Loss: 0.4365, Average Validation Accuracy: 0.8062\n",
      "Epoch [61/500], Average Training Loss: 0.4330\n",
      "Epoch [61/500], Average Validation Loss: 0.4363, Average Validation Accuracy: 0.8072\n",
      "Epoch [62/500], Average Training Loss: 0.4330\n",
      "Epoch [62/500], Average Validation Loss: 0.4361, Average Validation Accuracy: 0.8071\n",
      "Epoch [63/500], Average Training Loss: 0.4325\n",
      "Epoch [63/500], Average Validation Loss: 0.4360, Average Validation Accuracy: 0.8071\n",
      "Epoch [64/500], Average Training Loss: 0.4323\n",
      "Epoch [64/500], Average Validation Loss: 0.4358, Average Validation Accuracy: 0.8070\n",
      "Epoch [65/500], Average Training Loss: 0.4324\n",
      "Epoch [65/500], Average Validation Loss: 0.4356, Average Validation Accuracy: 0.8071\n",
      "Epoch [66/500], Average Training Loss: 0.4320\n",
      "Epoch [66/500], Average Validation Loss: 0.4354, Average Validation Accuracy: 0.8074\n",
      "Epoch [67/500], Average Training Loss: 0.4319\n",
      "Epoch [67/500], Average Validation Loss: 0.4353, Average Validation Accuracy: 0.8075\n",
      "Epoch [68/500], Average Training Loss: 0.4316\n",
      "Epoch [68/500], Average Validation Loss: 0.4351, Average Validation Accuracy: 0.8079\n",
      "Epoch [69/500], Average Training Loss: 0.4318\n",
      "Epoch [69/500], Average Validation Loss: 0.4350, Average Validation Accuracy: 0.8082\n",
      "Epoch [70/500], Average Training Loss: 0.4312\n",
      "Epoch [70/500], Average Validation Loss: 0.4348, Average Validation Accuracy: 0.8084\n",
      "Epoch [71/500], Average Training Loss: 0.4313\n",
      "Epoch [71/500], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8085\n",
      "Epoch [72/500], Average Training Loss: 0.4310\n",
      "Epoch [72/500], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8084\n",
      "Epoch [73/500], Average Training Loss: 0.4309\n",
      "Epoch [73/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8082\n",
      "Epoch [74/500], Average Training Loss: 0.4311\n",
      "Epoch [74/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8084\n",
      "Epoch [75/500], Average Training Loss: 0.4307\n",
      "Epoch [75/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8088\n",
      "Epoch [76/500], Average Training Loss: 0.4307\n",
      "Epoch [76/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8088\n",
      "Epoch [77/500], Average Training Loss: 0.4305\n",
      "Epoch [77/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8087\n",
      "Epoch [78/500], Average Training Loss: 0.4305\n",
      "Epoch [78/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8089\n",
      "Epoch [79/500], Average Training Loss: 0.4304\n",
      "Epoch [79/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8093\n",
      "Epoch [80/500], Average Training Loss: 0.4304\n",
      "Epoch [80/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8093\n",
      "Epoch [81/500], Average Training Loss: 0.4303\n",
      "Epoch [81/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8093\n",
      "Epoch [82/500], Average Training Loss: 0.4299\n",
      "Epoch [82/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8096\n",
      "Epoch [83/500], Average Training Loss: 0.4300\n",
      "Epoch [83/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8094\n",
      "Epoch [84/500], Average Training Loss: 0.4301\n",
      "Epoch [84/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8095\n",
      "Epoch [85/500], Average Training Loss: 0.4299\n",
      "Epoch [85/500], Average Validation Loss: 0.4331, Average Validation Accuracy: 0.8098\n",
      "Epoch [86/500], Average Training Loss: 0.4296\n",
      "Epoch [86/500], Average Validation Loss: 0.4331, Average Validation Accuracy: 0.8098\n",
      "Epoch [87/500], Average Training Loss: 0.4294\n",
      "Epoch [87/500], Average Validation Loss: 0.4330, Average Validation Accuracy: 0.8099\n",
      "Epoch [88/500], Average Training Loss: 0.4294\n",
      "Epoch [88/500], Average Validation Loss: 0.4329, Average Validation Accuracy: 0.8102\n",
      "Epoch [89/500], Average Training Loss: 0.4295\n",
      "Epoch [89/500], Average Validation Loss: 0.4328, Average Validation Accuracy: 0.8101\n",
      "Epoch [90/500], Average Training Loss: 0.4295\n",
      "Epoch [90/500], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8104\n",
      "Epoch [91/500], Average Training Loss: 0.4296\n",
      "Epoch [91/500], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8100\n",
      "Epoch [92/500], Average Training Loss: 0.4296\n",
      "Epoch [92/500], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8108\n",
      "Epoch [93/500], Average Training Loss: 0.4293\n",
      "Epoch [93/500], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8107\n",
      "Epoch [94/500], Average Training Loss: 0.4290\n",
      "Epoch [94/500], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8106\n",
      "Epoch [95/500], Average Training Loss: 0.4294\n",
      "Epoch [95/500], Average Validation Loss: 0.4324, Average Validation Accuracy: 0.8108\n",
      "Epoch [96/500], Average Training Loss: 0.4292\n",
      "Epoch [96/500], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8111\n",
      "Epoch [97/500], Average Training Loss: 0.4290\n",
      "Epoch [97/500], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8111\n",
      "Epoch [98/500], Average Training Loss: 0.4290\n",
      "Epoch [98/500], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8104\n",
      "Epoch [99/500], Average Training Loss: 0.4288\n",
      "Epoch [99/500], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8110\n",
      "Epoch [100/500], Average Training Loss: 0.4288\n",
      "Epoch [100/500], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8107\n",
      "Epoch [101/500], Average Training Loss: 0.4291\n",
      "Epoch [101/500], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8106\n",
      "Epoch [102/500], Average Training Loss: 0.4287\n",
      "Epoch [102/500], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8102\n",
      "Epoch [103/500], Average Training Loss: 0.4287\n",
      "Epoch [103/500], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8106\n",
      "Epoch [104/500], Average Training Loss: 0.4287\n",
      "Epoch [104/500], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8115\n",
      "Epoch [105/500], Average Training Loss: 0.4284\n",
      "Epoch [105/500], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8101\n",
      "Epoch [106/500], Average Training Loss: 0.4286\n",
      "Epoch [106/500], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8115\n",
      "Epoch [107/500], Average Training Loss: 0.4284\n",
      "Epoch [107/500], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8103\n",
      "Epoch [108/500], Average Training Loss: 0.4286\n",
      "Epoch [108/500], Average Validation Loss: 0.4317, Average Validation Accuracy: 0.8114\n",
      "Epoch [109/500], Average Training Loss: 0.4287\n",
      "Epoch [109/500], Average Validation Loss: 0.4317, Average Validation Accuracy: 0.8110\n",
      "Epoch [110/500], Average Training Loss: 0.4283\n",
      "Epoch [110/500], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8115\n",
      "Epoch [111/500], Average Training Loss: 0.4283\n",
      "Epoch [111/500], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8116\n",
      "Epoch [112/500], Average Training Loss: 0.4283\n",
      "Epoch [112/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8116\n",
      "Epoch [113/500], Average Training Loss: 0.4283\n",
      "Epoch [113/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8114\n",
      "Epoch [114/500], Average Training Loss: 0.4281\n",
      "Epoch [114/500], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8117\n",
      "Epoch [115/500], Average Training Loss: 0.4280\n",
      "Epoch [115/500], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8117\n",
      "Epoch [116/500], Average Training Loss: 0.4278\n",
      "Epoch [116/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8115\n",
      "Epoch [117/500], Average Training Loss: 0.4282\n",
      "Epoch [117/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8114\n",
      "Epoch [118/500], Average Training Loss: 0.4281\n",
      "Epoch [118/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8117\n",
      "Epoch [119/500], Average Training Loss: 0.4280\n",
      "Epoch [119/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8109\n",
      "Epoch [120/500], Average Training Loss: 0.4278\n",
      "Epoch [120/500], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8113\n",
      "Epoch [121/500], Average Training Loss: 0.4277\n",
      "Epoch [121/500], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8113\n",
      "Epoch [122/500], Average Training Loss: 0.4279\n",
      "Epoch [122/500], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8121\n",
      "Epoch [123/500], Average Training Loss: 0.4278\n",
      "Epoch [123/500], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8121\n",
      "Epoch [124/500], Average Training Loss: 0.4275\n",
      "Epoch [124/500], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8117\n",
      "Epoch [125/500], Average Training Loss: 0.4280\n",
      "Epoch [125/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8116\n",
      "Epoch [126/500], Average Training Loss: 0.4278\n",
      "Epoch [126/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8116\n",
      "Epoch [127/500], Average Training Loss: 0.4276\n",
      "Epoch [127/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8118\n",
      "Epoch [128/500], Average Training Loss: 0.4276\n",
      "Epoch [128/500], Average Validation Loss: 0.4308, Average Validation Accuracy: 0.8114\n",
      "Epoch [129/500], Average Training Loss: 0.4276\n",
      "Epoch [129/500], Average Validation Loss: 0.4308, Average Validation Accuracy: 0.8114\n",
      "Epoch [130/500], Average Training Loss: 0.4276\n",
      "Epoch [130/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8113\n",
      "Epoch [131/500], Average Training Loss: 0.4275\n",
      "Epoch [131/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8114\n",
      "Epoch [132/500], Average Training Loss: 0.4274\n",
      "Epoch [132/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8113\n",
      "Epoch [133/500], Average Training Loss: 0.4274\n",
      "Epoch [133/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8116\n",
      "Epoch [134/500], Average Training Loss: 0.4276\n",
      "Epoch [134/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8116\n",
      "Epoch [135/500], Average Training Loss: 0.4271\n",
      "Epoch [135/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8117\n",
      "Epoch [136/500], Average Training Loss: 0.4272\n",
      "Epoch [136/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8115\n",
      "Epoch [137/500], Average Training Loss: 0.4270\n",
      "Epoch [137/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8115\n",
      "Epoch [138/500], Average Training Loss: 0.4271\n",
      "Epoch [138/500], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8114\n",
      "Epoch [139/500], Average Training Loss: 0.4269\n",
      "Epoch [139/500], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8117\n",
      "Epoch [140/500], Average Training Loss: 0.4270\n",
      "Epoch [140/500], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8115\n",
      "Epoch [141/500], Average Training Loss: 0.4273\n",
      "Epoch [141/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8116\n",
      "Epoch [142/500], Average Training Loss: 0.4271\n",
      "Epoch [142/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8118\n",
      "Epoch [143/500], Average Training Loss: 0.4268\n",
      "Epoch [143/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8120\n",
      "Epoch [144/500], Average Training Loss: 0.4270\n",
      "Epoch [144/500], Average Validation Loss: 0.4302, Average Validation Accuracy: 0.8116\n",
      "Epoch [145/500], Average Training Loss: 0.4268\n",
      "Epoch [145/500], Average Validation Loss: 0.4302, Average Validation Accuracy: 0.8118\n",
      "Epoch [146/500], Average Training Loss: 0.4269\n",
      "Epoch [146/500], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8119\n",
      "Epoch [147/500], Average Training Loss: 0.4269\n",
      "Epoch [147/500], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8121\n",
      "Epoch [148/500], Average Training Loss: 0.4268\n",
      "Epoch [148/500], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8119\n",
      "Epoch [149/500], Average Training Loss: 0.4268\n",
      "Epoch [149/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8116\n",
      "Epoch [150/500], Average Training Loss: 0.4268\n",
      "Epoch [150/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8117\n",
      "Epoch [151/500], Average Training Loss: 0.4266\n",
      "Epoch [151/500], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8117\n",
      "Epoch [152/500], Average Training Loss: 0.4266\n",
      "Epoch [152/500], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8121\n",
      "Epoch [153/500], Average Training Loss: 0.4264\n",
      "Epoch [153/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8120\n",
      "Epoch [154/500], Average Training Loss: 0.4266\n",
      "Epoch [154/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8119\n",
      "Epoch [155/500], Average Training Loss: 0.4265\n",
      "Epoch [155/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8119\n",
      "Epoch [156/500], Average Training Loss: 0.4263\n",
      "Epoch [156/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8118\n",
      "Epoch [157/500], Average Training Loss: 0.4263\n",
      "Epoch [157/500], Average Validation Loss: 0.4297, Average Validation Accuracy: 0.8120\n",
      "Epoch [158/500], Average Training Loss: 0.4262\n",
      "Epoch [158/500], Average Validation Loss: 0.4297, Average Validation Accuracy: 0.8121\n",
      "Epoch [159/500], Average Training Loss: 0.4261\n",
      "Epoch [159/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8124\n",
      "Epoch [160/500], Average Training Loss: 0.4262\n",
      "Epoch [160/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8119\n",
      "Epoch [161/500], Average Training Loss: 0.4261\n",
      "Epoch [161/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8124\n",
      "Epoch [162/500], Average Training Loss: 0.4262\n",
      "Epoch [162/500], Average Validation Loss: 0.4295, Average Validation Accuracy: 0.8122\n",
      "Epoch [163/500], Average Training Loss: 0.4260\n",
      "Epoch [163/500], Average Validation Loss: 0.4295, Average Validation Accuracy: 0.8122\n",
      "Epoch [164/500], Average Training Loss: 0.4260\n",
      "Epoch [164/500], Average Validation Loss: 0.4295, Average Validation Accuracy: 0.8122\n",
      "Epoch [165/500], Average Training Loss: 0.4262\n",
      "Epoch [165/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8115\n",
      "Epoch [166/500], Average Training Loss: 0.4257\n",
      "Epoch [166/500], Average Validation Loss: 0.4295, Average Validation Accuracy: 0.8117\n",
      "Epoch [167/500], Average Training Loss: 0.4259\n",
      "Epoch [167/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8125\n",
      "Epoch [168/500], Average Training Loss: 0.4259\n",
      "Epoch [168/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8118\n",
      "Epoch [169/500], Average Training Loss: 0.4258\n",
      "Epoch [169/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8121\n",
      "Epoch [170/500], Average Training Loss: 0.4261\n",
      "Epoch [170/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8115\n",
      "Epoch [171/500], Average Training Loss: 0.4255\n",
      "Epoch [171/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8121\n",
      "Epoch [172/500], Average Training Loss: 0.4259\n",
      "Epoch [172/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8122\n",
      "Epoch [173/500], Average Training Loss: 0.4256\n",
      "Epoch [173/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8123\n",
      "Epoch [174/500], Average Training Loss: 0.4256\n",
      "Epoch [174/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8122\n",
      "Epoch [175/500], Average Training Loss: 0.4257\n",
      "Epoch [175/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8123\n",
      "Epoch [176/500], Average Training Loss: 0.4257\n",
      "Epoch [176/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8120\n",
      "Epoch [177/500], Average Training Loss: 0.4258\n",
      "Epoch [177/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8122\n",
      "Epoch [178/500], Average Training Loss: 0.4257\n",
      "Epoch [178/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8115\n",
      "Epoch [179/500], Average Training Loss: 0.4257\n",
      "Epoch [179/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8116\n",
      "Epoch [180/500], Average Training Loss: 0.4254\n",
      "Epoch [180/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8119\n",
      "Epoch [181/500], Average Training Loss: 0.4254\n",
      "Epoch [181/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8118\n",
      "Epoch [182/500], Average Training Loss: 0.4254\n",
      "Epoch [182/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8118\n",
      "Epoch [183/500], Average Training Loss: 0.4253\n",
      "Epoch [183/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8118\n",
      "Epoch [184/500], Average Training Loss: 0.4254\n",
      "Epoch [184/500], Average Validation Loss: 0.4289, Average Validation Accuracy: 0.8119\n",
      "Epoch [185/500], Average Training Loss: 0.4249\n",
      "Epoch [185/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8124\n",
      "Epoch [186/500], Average Training Loss: 0.4252\n",
      "Epoch [186/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8120\n",
      "Epoch [187/500], Average Training Loss: 0.4251\n",
      "Epoch [187/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8120\n",
      "Epoch [188/500], Average Training Loss: 0.4253\n",
      "Epoch [188/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8120\n",
      "Epoch [189/500], Average Training Loss: 0.4251\n",
      "Epoch [189/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8124\n",
      "Epoch [190/500], Average Training Loss: 0.4253\n",
      "Epoch [190/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8116\n",
      "Epoch [191/500], Average Training Loss: 0.4252\n",
      "Epoch [191/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8119\n",
      "Epoch [192/500], Average Training Loss: 0.4251\n",
      "Epoch [192/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8119\n",
      "Epoch [193/500], Average Training Loss: 0.4249\n",
      "Epoch [193/500], Average Validation Loss: 0.4286, Average Validation Accuracy: 0.8118\n",
      "Epoch [194/500], Average Training Loss: 0.4247\n",
      "Epoch [194/500], Average Validation Loss: 0.4286, Average Validation Accuracy: 0.8119\n",
      "Epoch [195/500], Average Training Loss: 0.4248\n",
      "Epoch [195/500], Average Validation Loss: 0.4286, Average Validation Accuracy: 0.8121\n",
      "Epoch [196/500], Average Training Loss: 0.4247\n",
      "Epoch [196/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8119\n",
      "Epoch [197/500], Average Training Loss: 0.4248\n",
      "Epoch [197/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8121\n",
      "Epoch [198/500], Average Training Loss: 0.4247\n",
      "Epoch [198/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8122\n",
      "Epoch [199/500], Average Training Loss: 0.4245\n",
      "Epoch [199/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8125\n",
      "Epoch [200/500], Average Training Loss: 0.4245\n",
      "Epoch [200/500], Average Validation Loss: 0.4284, Average Validation Accuracy: 0.8122\n",
      "Epoch [201/500], Average Training Loss: 0.4245\n",
      "Epoch [201/500], Average Validation Loss: 0.4284, Average Validation Accuracy: 0.8122\n",
      "Epoch [202/500], Average Training Loss: 0.4247\n",
      "Epoch [202/500], Average Validation Loss: 0.4284, Average Validation Accuracy: 0.8120\n",
      "Epoch [203/500], Average Training Loss: 0.4245\n",
      "Epoch [203/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8124\n",
      "Epoch [204/500], Average Training Loss: 0.4249\n",
      "Epoch [204/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8122\n",
      "Epoch [205/500], Average Training Loss: 0.4244\n",
      "Epoch [205/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8120\n",
      "Epoch [206/500], Average Training Loss: 0.4247\n",
      "Epoch [206/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8119\n",
      "Epoch [207/500], Average Training Loss: 0.4245\n",
      "Epoch [207/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8122\n",
      "Epoch [208/500], Average Training Loss: 0.4244\n",
      "Epoch [208/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8119\n",
      "Epoch [209/500], Average Training Loss: 0.4244\n",
      "Epoch [209/500], Average Validation Loss: 0.4282, Average Validation Accuracy: 0.8121\n",
      "Epoch [210/500], Average Training Loss: 0.4245\n",
      "Epoch [210/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8123\n",
      "Epoch [211/500], Average Training Loss: 0.4244\n",
      "Epoch [211/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8122\n",
      "Epoch [212/500], Average Training Loss: 0.4242\n",
      "Epoch [212/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8123\n",
      "Epoch [213/500], Average Training Loss: 0.4243\n",
      "Epoch [213/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8122\n",
      "Epoch [214/500], Average Training Loss: 0.4244\n",
      "Epoch [214/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8119\n",
      "Epoch [215/500], Average Training Loss: 0.4243\n",
      "Epoch [215/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8121\n",
      "Epoch [216/500], Average Training Loss: 0.4240\n",
      "Epoch [216/500], Average Validation Loss: 0.4280, Average Validation Accuracy: 0.8121\n",
      "Epoch [217/500], Average Training Loss: 0.4240\n",
      "Epoch [217/500], Average Validation Loss: 0.4280, Average Validation Accuracy: 0.8121\n",
      "Epoch [218/500], Average Training Loss: 0.4241\n",
      "Epoch [218/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8125\n",
      "Epoch [219/500], Average Training Loss: 0.4240\n",
      "Epoch [219/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8121\n",
      "Epoch [220/500], Average Training Loss: 0.4240\n",
      "Epoch [220/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8121\n",
      "Epoch [221/500], Average Training Loss: 0.4241\n",
      "Epoch [221/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8123\n",
      "Epoch [222/500], Average Training Loss: 0.4239\n",
      "Epoch [222/500], Average Validation Loss: 0.4278, Average Validation Accuracy: 0.8125\n",
      "Epoch [223/500], Average Training Loss: 0.4241\n",
      "Epoch [223/500], Average Validation Loss: 0.4278, Average Validation Accuracy: 0.8123\n",
      "Epoch [224/500], Average Training Loss: 0.4236\n",
      "Epoch [224/500], Average Validation Loss: 0.4278, Average Validation Accuracy: 0.8125\n",
      "Epoch [225/500], Average Training Loss: 0.4239\n",
      "Epoch [225/500], Average Validation Loss: 0.4278, Average Validation Accuracy: 0.8123\n",
      "Epoch [226/500], Average Training Loss: 0.4239\n",
      "Epoch [226/500], Average Validation Loss: 0.4278, Average Validation Accuracy: 0.8122\n",
      "Epoch [227/500], Average Training Loss: 0.4237\n",
      "Epoch [227/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8124\n",
      "Epoch [228/500], Average Training Loss: 0.4235\n",
      "Epoch [228/500], Average Validation Loss: 0.4278, Average Validation Accuracy: 0.8122\n",
      "Epoch [229/500], Average Training Loss: 0.4237\n",
      "Epoch [229/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8121\n",
      "Epoch [230/500], Average Training Loss: 0.4236\n",
      "Epoch [230/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8125\n",
      "Epoch [231/500], Average Training Loss: 0.4235\n",
      "Epoch [231/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8124\n",
      "Epoch [232/500], Average Training Loss: 0.4236\n",
      "Epoch [232/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8122\n",
      "Epoch [233/500], Average Training Loss: 0.4235\n",
      "Epoch [233/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8122\n",
      "Epoch [234/500], Average Training Loss: 0.4236\n",
      "Epoch [234/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8126\n",
      "Epoch [235/500], Average Training Loss: 0.4235\n",
      "Epoch [235/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8122\n",
      "Epoch [236/500], Average Training Loss: 0.4233\n",
      "Epoch [236/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8127\n",
      "Epoch [237/500], Average Training Loss: 0.4235\n",
      "Epoch [237/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8125\n",
      "Epoch [238/500], Average Training Loss: 0.4234\n",
      "Epoch [238/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8124\n",
      "Epoch [239/500], Average Training Loss: 0.4234\n",
      "Epoch [239/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8127\n",
      "Epoch [240/500], Average Training Loss: 0.4230\n",
      "Epoch [240/500], Average Validation Loss: 0.4274, Average Validation Accuracy: 0.8123\n",
      "Epoch [241/500], Average Training Loss: 0.4233\n",
      "Epoch [241/500], Average Validation Loss: 0.4274, Average Validation Accuracy: 0.8125\n",
      "Epoch [242/500], Average Training Loss: 0.4231\n",
      "Epoch [242/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8123\n",
      "Epoch [243/500], Average Training Loss: 0.4231\n",
      "Epoch [243/500], Average Validation Loss: 0.4274, Average Validation Accuracy: 0.8126\n",
      "Epoch [244/500], Average Training Loss: 0.4233\n",
      "Epoch [244/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8125\n",
      "Epoch [245/500], Average Training Loss: 0.4234\n",
      "Epoch [245/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8124\n",
      "Epoch [246/500], Average Training Loss: 0.4234\n",
      "Epoch [246/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8123\n",
      "Epoch [247/500], Average Training Loss: 0.4228\n",
      "Epoch [247/500], Average Validation Loss: 0.4272, Average Validation Accuracy: 0.8126\n",
      "Epoch [248/500], Average Training Loss: 0.4231\n",
      "Epoch [248/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8128\n",
      "Epoch [249/500], Average Training Loss: 0.4229\n",
      "Epoch [249/500], Average Validation Loss: 0.4272, Average Validation Accuracy: 0.8122\n",
      "Epoch [250/500], Average Training Loss: 0.4228\n",
      "Epoch [250/500], Average Validation Loss: 0.4272, Average Validation Accuracy: 0.8125\n",
      "Epoch [251/500], Average Training Loss: 0.4227\n",
      "Epoch [251/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8122\n",
      "Epoch [252/500], Average Training Loss: 0.4228\n",
      "Epoch [252/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8123\n",
      "Epoch [253/500], Average Training Loss: 0.4230\n",
      "Epoch [253/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8123\n",
      "Epoch [254/500], Average Training Loss: 0.4227\n",
      "Epoch [254/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8124\n",
      "Epoch [255/500], Average Training Loss: 0.4228\n",
      "Epoch [255/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8124\n",
      "Epoch [256/500], Average Training Loss: 0.4227\n",
      "Epoch [256/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8120\n",
      "Epoch [257/500], Average Training Loss: 0.4227\n",
      "Epoch [257/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8124\n",
      "Epoch [258/500], Average Training Loss: 0.4226\n",
      "Epoch [258/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8126\n",
      "Epoch [259/500], Average Training Loss: 0.4225\n",
      "Epoch [259/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8125\n",
      "Epoch [260/500], Average Training Loss: 0.4229\n",
      "Epoch [260/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8125\n",
      "Epoch [261/500], Average Training Loss: 0.4223\n",
      "Epoch [261/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8127\n",
      "Epoch [262/500], Average Training Loss: 0.4227\n",
      "Epoch [262/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8123\n",
      "Epoch [263/500], Average Training Loss: 0.4226\n",
      "Epoch [263/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8126\n",
      "Epoch [264/500], Average Training Loss: 0.4227\n",
      "Epoch [264/500], Average Validation Loss: 0.4268, Average Validation Accuracy: 0.8123\n",
      "Epoch [265/500], Average Training Loss: 0.4226\n",
      "Epoch [265/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8124\n",
      "Epoch [266/500], Average Training Loss: 0.4224\n",
      "Epoch [266/500], Average Validation Loss: 0.4268, Average Validation Accuracy: 0.8124\n",
      "Epoch [267/500], Average Training Loss: 0.4224\n",
      "Epoch [267/500], Average Validation Loss: 0.4268, Average Validation Accuracy: 0.8124\n",
      "Epoch [268/500], Average Training Loss: 0.4224\n",
      "Epoch [268/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8120\n",
      "Epoch [269/500], Average Training Loss: 0.4224\n",
      "Epoch [269/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8125\n",
      "Epoch [270/500], Average Training Loss: 0.4224\n",
      "Epoch [270/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8125\n",
      "Epoch [271/500], Average Training Loss: 0.4226\n",
      "Epoch [271/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8127\n",
      "Epoch [272/500], Average Training Loss: 0.4223\n",
      "Epoch [272/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8125\n",
      "Epoch [273/500], Average Training Loss: 0.4222\n",
      "Epoch [273/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8126\n",
      "Epoch [274/500], Average Training Loss: 0.4222\n",
      "Epoch [274/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8126\n",
      "Epoch [275/500], Average Training Loss: 0.4222\n",
      "Epoch [275/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8125\n",
      "Epoch [276/500], Average Training Loss: 0.4222\n",
      "Epoch [276/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8122\n",
      "Epoch [277/500], Average Training Loss: 0.4224\n",
      "Epoch [277/500], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8128\n",
      "Epoch [278/500], Average Training Loss: 0.4219\n",
      "Epoch [278/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8128\n",
      "Epoch [279/500], Average Training Loss: 0.4219\n",
      "Epoch [279/500], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8126\n",
      "Epoch [280/500], Average Training Loss: 0.4221\n",
      "Epoch [280/500], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8127\n",
      "Epoch [281/500], Average Training Loss: 0.4222\n",
      "Epoch [281/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8126\n",
      "Epoch [282/500], Average Training Loss: 0.4219\n",
      "Epoch [282/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8125\n",
      "Epoch [283/500], Average Training Loss: 0.4218\n",
      "Epoch [283/500], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8129\n",
      "Epoch [284/500], Average Training Loss: 0.4219\n",
      "Epoch [284/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8127\n",
      "Epoch [285/500], Average Training Loss: 0.4219\n",
      "Epoch [285/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8125\n",
      "Epoch [286/500], Average Training Loss: 0.4223\n",
      "Epoch [286/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8131\n",
      "Epoch [287/500], Average Training Loss: 0.4217\n",
      "Epoch [287/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8128\n",
      "Epoch [288/500], Average Training Loss: 0.4221\n",
      "Epoch [288/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8126\n",
      "Epoch [289/500], Average Training Loss: 0.4218\n",
      "Epoch [289/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8128\n",
      "Epoch [290/500], Average Training Loss: 0.4220\n",
      "Epoch [290/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8131\n",
      "Epoch [291/500], Average Training Loss: 0.4218\n",
      "Epoch [291/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8128\n",
      "Epoch [292/500], Average Training Loss: 0.4218\n",
      "Epoch [292/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8129\n",
      "Epoch [293/500], Average Training Loss: 0.4216\n",
      "Epoch [293/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8126\n",
      "Epoch [294/500], Average Training Loss: 0.4221\n",
      "Epoch [294/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8127\n",
      "Epoch [295/500], Average Training Loss: 0.4217\n",
      "Epoch [295/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8131\n",
      "Epoch [296/500], Average Training Loss: 0.4216\n",
      "Epoch [296/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8128\n",
      "Epoch [297/500], Average Training Loss: 0.4216\n",
      "Epoch [297/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8128\n",
      "Epoch [298/500], Average Training Loss: 0.4216\n",
      "Epoch [298/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8134\n",
      "Epoch [299/500], Average Training Loss: 0.4219\n",
      "Epoch [299/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8125\n",
      "Epoch [300/500], Average Training Loss: 0.4218\n",
      "Epoch [300/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8128\n",
      "Epoch [301/500], Average Training Loss: 0.4216\n",
      "Epoch [301/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8134\n",
      "Epoch [302/500], Average Training Loss: 0.4220\n",
      "Epoch [302/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8128\n",
      "Epoch [303/500], Average Training Loss: 0.4215\n",
      "Epoch [303/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8129\n",
      "Epoch [304/500], Average Training Loss: 0.4217\n",
      "Epoch [304/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8131\n",
      "Epoch [305/500], Average Training Loss: 0.4214\n",
      "Epoch [305/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8131\n",
      "Epoch [306/500], Average Training Loss: 0.4215\n",
      "Epoch [306/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8126\n",
      "Epoch [307/500], Average Training Loss: 0.4215\n",
      "Epoch [307/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8128\n",
      "Epoch [308/500], Average Training Loss: 0.4216\n",
      "Epoch [308/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8131\n",
      "Epoch [309/500], Average Training Loss: 0.4215\n",
      "Epoch [309/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8128\n",
      "Epoch [310/500], Average Training Loss: 0.4215\n",
      "Epoch [310/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8128\n",
      "Epoch [311/500], Average Training Loss: 0.4214\n",
      "Epoch [311/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8130\n",
      "Epoch [312/500], Average Training Loss: 0.4214\n",
      "Epoch [312/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8133\n",
      "Epoch [313/500], Average Training Loss: 0.4210\n",
      "Epoch [313/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8133\n",
      "Epoch [314/500], Average Training Loss: 0.4212\n",
      "Epoch [314/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8134\n",
      "Epoch [315/500], Average Training Loss: 0.4213\n",
      "Epoch [315/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8133\n",
      "Epoch [316/500], Average Training Loss: 0.4213\n",
      "Epoch [316/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8130\n",
      "Epoch [317/500], Average Training Loss: 0.4214\n",
      "Epoch [317/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8128\n",
      "Epoch [318/500], Average Training Loss: 0.4211\n",
      "Epoch [318/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8132\n",
      "Epoch [319/500], Average Training Loss: 0.4217\n",
      "Epoch [319/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8129\n",
      "Epoch [320/500], Average Training Loss: 0.4212\n",
      "Epoch [320/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8133\n",
      "Epoch [321/500], Average Training Loss: 0.4208\n",
      "Epoch [321/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8128\n",
      "Epoch [322/500], Average Training Loss: 0.4214\n",
      "Epoch [322/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8127\n",
      "Epoch [323/500], Average Training Loss: 0.4209\n",
      "Epoch [323/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8127\n",
      "Epoch [324/500], Average Training Loss: 0.4212\n",
      "Epoch [324/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8135\n",
      "Epoch [325/500], Average Training Loss: 0.4212\n",
      "Epoch [325/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8135\n",
      "Epoch [326/500], Average Training Loss: 0.4211\n",
      "Epoch [326/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8132\n",
      "Epoch [327/500], Average Training Loss: 0.4212\n",
      "Epoch [327/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8135\n",
      "Epoch [328/500], Average Training Loss: 0.4209\n",
      "Epoch [328/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8134\n",
      "Epoch [329/500], Average Training Loss: 0.4209\n",
      "Epoch [329/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8127\n",
      "Epoch [330/500], Average Training Loss: 0.4211\n",
      "Epoch [330/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8132\n",
      "Epoch [331/500], Average Training Loss: 0.4211\n",
      "Epoch [331/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8136\n",
      "Epoch [332/500], Average Training Loss: 0.4211\n",
      "Epoch [332/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8137\n",
      "Epoch [333/500], Average Training Loss: 0.4210\n",
      "Epoch [333/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8133\n",
      "Epoch [334/500], Average Training Loss: 0.4209\n",
      "Epoch [334/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8136\n",
      "Epoch [335/500], Average Training Loss: 0.4209\n",
      "Epoch [335/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8127\n",
      "Epoch [336/500], Average Training Loss: 0.4207\n",
      "Epoch [336/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8136\n",
      "Epoch [337/500], Average Training Loss: 0.4210\n",
      "Epoch [337/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8128\n",
      "Epoch [338/500], Average Training Loss: 0.4209\n",
      "Epoch [338/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8136\n",
      "Epoch [339/500], Average Training Loss: 0.4210\n",
      "Epoch [339/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8136\n",
      "Epoch [340/500], Average Training Loss: 0.4208\n",
      "Epoch [340/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8130\n",
      "Epoch [341/500], Average Training Loss: 0.4208\n",
      "Epoch [341/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8136\n",
      "Epoch [342/500], Average Training Loss: 0.4207\n",
      "Epoch [342/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8129\n",
      "Epoch [343/500], Average Training Loss: 0.4207\n",
      "Epoch [343/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8136\n",
      "Epoch [344/500], Average Training Loss: 0.4208\n",
      "Epoch [344/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8132\n",
      "Epoch [345/500], Average Training Loss: 0.4210\n",
      "Epoch [345/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8132\n",
      "Epoch [346/500], Average Training Loss: 0.4207\n",
      "Epoch [346/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8136\n",
      "Epoch [347/500], Average Training Loss: 0.4207\n",
      "Epoch [347/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8131\n",
      "Epoch [348/500], Average Training Loss: 0.4205\n",
      "Epoch [348/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8131\n",
      "Epoch [349/500], Average Training Loss: 0.4205\n",
      "Epoch [349/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8132\n",
      "Epoch [350/500], Average Training Loss: 0.4205\n",
      "Epoch [350/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8130\n",
      "Epoch [351/500], Average Training Loss: 0.4207\n",
      "Epoch [351/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8137\n",
      "Epoch [352/500], Average Training Loss: 0.4207\n",
      "Epoch [352/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8132\n",
      "Epoch [353/500], Average Training Loss: 0.4208\n",
      "Epoch [353/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8135\n",
      "Epoch [354/500], Average Training Loss: 0.4207\n",
      "Epoch [354/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8135\n",
      "Epoch [355/500], Average Training Loss: 0.4205\n",
      "Epoch [355/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8136\n",
      "Epoch [356/500], Average Training Loss: 0.4205\n",
      "Epoch [356/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8136\n",
      "Epoch [357/500], Average Training Loss: 0.4205\n",
      "Epoch [357/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8129\n",
      "Epoch [358/500], Average Training Loss: 0.4204\n",
      "Epoch [358/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8133\n",
      "Epoch [359/500], Average Training Loss: 0.4205\n",
      "Epoch [359/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8135\n",
      "Epoch [360/500], Average Training Loss: 0.4207\n",
      "Epoch [360/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8132\n",
      "Epoch [361/500], Average Training Loss: 0.4204\n",
      "Epoch [361/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8136\n",
      "Epoch [362/500], Average Training Loss: 0.4203\n",
      "Epoch [362/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8136\n",
      "Epoch [363/500], Average Training Loss: 0.4206\n",
      "Epoch [363/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8136\n",
      "Epoch [364/500], Average Training Loss: 0.4204\n",
      "Epoch [364/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8132\n",
      "Epoch [365/500], Average Training Loss: 0.4203\n",
      "Epoch [365/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8136\n",
      "Epoch [366/500], Average Training Loss: 0.4203\n",
      "Epoch [366/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8132\n",
      "Epoch [367/500], Average Training Loss: 0.4207\n",
      "Epoch [367/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8134\n",
      "Epoch [368/500], Average Training Loss: 0.4202\n",
      "Epoch [368/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8133\n",
      "Epoch [369/500], Average Training Loss: 0.4204\n",
      "Epoch [369/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8137\n",
      "Epoch [370/500], Average Training Loss: 0.4201\n",
      "Epoch [370/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8137\n",
      "Epoch [371/500], Average Training Loss: 0.4206\n",
      "Epoch [371/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8133\n",
      "Epoch [372/500], Average Training Loss: 0.4202\n",
      "Epoch [372/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8142\n",
      "Epoch [373/500], Average Training Loss: 0.4206\n",
      "Epoch [373/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8139\n",
      "Epoch [374/500], Average Training Loss: 0.4203\n",
      "Epoch [374/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8133\n",
      "Epoch [375/500], Average Training Loss: 0.4203\n",
      "Epoch [375/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8138\n",
      "Epoch [376/500], Average Training Loss: 0.4203\n",
      "Epoch [376/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8136\n",
      "Epoch [377/500], Average Training Loss: 0.4202\n",
      "Epoch [377/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8138\n",
      "Epoch [378/500], Average Training Loss: 0.4203\n",
      "Epoch [378/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8138\n",
      "Epoch [379/500], Average Training Loss: 0.4201\n",
      "Epoch [379/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8142\n",
      "Epoch [380/500], Average Training Loss: 0.4203\n",
      "Epoch [380/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8141\n",
      "Epoch [381/500], Average Training Loss: 0.4200\n",
      "Epoch [381/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8143\n",
      "Epoch [382/500], Average Training Loss: 0.4202\n",
      "Epoch [382/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8141\n",
      "Epoch [383/500], Average Training Loss: 0.4201\n",
      "Epoch [383/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8135\n",
      "Epoch [384/500], Average Training Loss: 0.4201\n",
      "Epoch [384/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8135\n",
      "Epoch [385/500], Average Training Loss: 0.4202\n",
      "Epoch [385/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8135\n",
      "Epoch [386/500], Average Training Loss: 0.4202\n",
      "Epoch [386/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8138\n",
      "Epoch [387/500], Average Training Loss: 0.4202\n",
      "Epoch [387/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8140\n",
      "Epoch [388/500], Average Training Loss: 0.4203\n",
      "Epoch [388/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8141\n",
      "Epoch [389/500], Average Training Loss: 0.4199\n",
      "Epoch [389/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8138\n",
      "Epoch [390/500], Average Training Loss: 0.4200\n",
      "Epoch [390/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8138\n",
      "Epoch [391/500], Average Training Loss: 0.4199\n",
      "Epoch [391/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8136\n",
      "Epoch [392/500], Average Training Loss: 0.4203\n",
      "Epoch [392/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8141\n",
      "Epoch [393/500], Average Training Loss: 0.4198\n",
      "Epoch [393/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8139\n",
      "Epoch [394/500], Average Training Loss: 0.4201\n",
      "Epoch [394/500], Average Validation Loss: 0.4245, Average Validation Accuracy: 0.8140\n",
      "Epoch [395/500], Average Training Loss: 0.4200\n",
      "Epoch [395/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8134\n",
      "Epoch [396/500], Average Training Loss: 0.4199\n",
      "Epoch [396/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8132\n",
      "Epoch [397/500], Average Training Loss: 0.4198\n",
      "Epoch [397/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8141\n",
      "Epoch [398/500], Average Training Loss: 0.4199\n",
      "Epoch [398/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8140\n",
      "Epoch [399/500], Average Training Loss: 0.4199\n",
      "Epoch [399/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8142\n",
      "Epoch [400/500], Average Training Loss: 0.4199\n",
      "Epoch [400/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8142\n",
      "Epoch [401/500], Average Training Loss: 0.4197\n",
      "Epoch [401/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8145\n",
      "Epoch [402/500], Average Training Loss: 0.4202\n",
      "Epoch [402/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8141\n",
      "Epoch [403/500], Average Training Loss: 0.4198\n",
      "Epoch [403/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8141\n",
      "Epoch [404/500], Average Training Loss: 0.4195\n",
      "Epoch [404/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8135\n",
      "Epoch [405/500], Average Training Loss: 0.4197\n",
      "Epoch [405/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8143\n",
      "Epoch [406/500], Average Training Loss: 0.4198\n",
      "Epoch [406/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8145\n",
      "Epoch [407/500], Average Training Loss: 0.4199\n",
      "Epoch [407/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8136\n",
      "Epoch [408/500], Average Training Loss: 0.4197\n",
      "Epoch [408/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8137\n",
      "Epoch [409/500], Average Training Loss: 0.4198\n",
      "Epoch [409/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8143\n",
      "Epoch [410/500], Average Training Loss: 0.4197\n",
      "Epoch [410/500], Average Validation Loss: 0.4242, Average Validation Accuracy: 0.8142\n",
      "Epoch [411/500], Average Training Loss: 0.4195\n",
      "Epoch [411/500], Average Validation Loss: 0.4242, Average Validation Accuracy: 0.8143\n",
      "Epoch [412/500], Average Training Loss: 0.4198\n",
      "Epoch [412/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8145\n",
      "Epoch [413/500], Average Training Loss: 0.4198\n",
      "Epoch [413/500], Average Validation Loss: 0.4242, Average Validation Accuracy: 0.8136\n",
      "Epoch [414/500], Average Training Loss: 0.4195\n",
      "Epoch [414/500], Average Validation Loss: 0.4242, Average Validation Accuracy: 0.8141\n",
      "Epoch [415/500], Average Training Loss: 0.4199\n",
      "Epoch [415/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8145\n",
      "Epoch [416/500], Average Training Loss: 0.4195\n",
      "Epoch [416/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8141\n",
      "Epoch [417/500], Average Training Loss: 0.4195\n",
      "Epoch [417/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8138\n",
      "Epoch [418/500], Average Training Loss: 0.4197\n",
      "Epoch [418/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8135\n",
      "Epoch [419/500], Average Training Loss: 0.4195\n",
      "Epoch [419/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8135\n",
      "Epoch [420/500], Average Training Loss: 0.4194\n",
      "Epoch [420/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8146\n",
      "Epoch [421/500], Average Training Loss: 0.4196\n",
      "Epoch [421/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8141\n",
      "Epoch [422/500], Average Training Loss: 0.4195\n",
      "Epoch [422/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8136\n",
      "Epoch [423/500], Average Training Loss: 0.4194\n",
      "Epoch [423/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8145\n",
      "Epoch [424/500], Average Training Loss: 0.4194\n",
      "Epoch [424/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8136\n",
      "Epoch [425/500], Average Training Loss: 0.4192\n",
      "Epoch [425/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8137\n",
      "Epoch [426/500], Average Training Loss: 0.4194\n",
      "Epoch [426/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8138\n",
      "Epoch [427/500], Average Training Loss: 0.4193\n",
      "Epoch [427/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8143\n",
      "Epoch [428/500], Average Training Loss: 0.4195\n",
      "Epoch [428/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8139\n",
      "Epoch [429/500], Average Training Loss: 0.4196\n",
      "Epoch [429/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8142\n",
      "Epoch [430/500], Average Training Loss: 0.4195\n",
      "Epoch [430/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8147\n",
      "Epoch [431/500], Average Training Loss: 0.4194\n",
      "Epoch [431/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8141\n",
      "Epoch [432/500], Average Training Loss: 0.4191\n",
      "Epoch [432/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8143\n",
      "Epoch [433/500], Average Training Loss: 0.4197\n",
      "Epoch [433/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8138\n",
      "Epoch [434/500], Average Training Loss: 0.4193\n",
      "Epoch [434/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8144\n",
      "Epoch [435/500], Average Training Loss: 0.4196\n",
      "Epoch [435/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8146\n",
      "Epoch [436/500], Average Training Loss: 0.4194\n",
      "Epoch [436/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8147\n",
      "Epoch [437/500], Average Training Loss: 0.4194\n",
      "Epoch [437/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8149\n",
      "Epoch [438/500], Average Training Loss: 0.4193\n",
      "Epoch [438/500], Average Validation Loss: 0.4237, Average Validation Accuracy: 0.8139\n",
      "Epoch [439/500], Average Training Loss: 0.4196\n",
      "Epoch [439/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8136\n",
      "Epoch [440/500], Average Training Loss: 0.4193\n",
      "Epoch [440/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8135\n",
      "Epoch [441/500], Average Training Loss: 0.4191\n",
      "Epoch [441/500], Average Validation Loss: 0.4237, Average Validation Accuracy: 0.8148\n",
      "Epoch [442/500], Average Training Loss: 0.4192\n",
      "Epoch [442/500], Average Validation Loss: 0.4237, Average Validation Accuracy: 0.8139\n",
      "Epoch [443/500], Average Training Loss: 0.4193\n",
      "Epoch [443/500], Average Validation Loss: 0.4237, Average Validation Accuracy: 0.8145\n",
      "Epoch [444/500], Average Training Loss: 0.4192\n",
      "Epoch [444/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8144\n",
      "Epoch [445/500], Average Training Loss: 0.4189\n",
      "Epoch [445/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8149\n",
      "Epoch [446/500], Average Training Loss: 0.4189\n",
      "Epoch [446/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8140\n",
      "Epoch [447/500], Average Training Loss: 0.4191\n",
      "Epoch [447/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8146\n",
      "Epoch [448/500], Average Training Loss: 0.4190\n",
      "Epoch [448/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8140\n",
      "Epoch [449/500], Average Training Loss: 0.4193\n",
      "Epoch [449/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8145\n",
      "Epoch [450/500], Average Training Loss: 0.4190\n",
      "Epoch [450/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8141\n",
      "Epoch [451/500], Average Training Loss: 0.4190\n",
      "Epoch [451/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8146\n",
      "Epoch [452/500], Average Training Loss: 0.4190\n",
      "Epoch [452/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8145\n",
      "Epoch [453/500], Average Training Loss: 0.4187\n",
      "Epoch [453/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8142\n",
      "Epoch [454/500], Average Training Loss: 0.4193\n",
      "Epoch [454/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8143\n",
      "Epoch [455/500], Average Training Loss: 0.4190\n",
      "Epoch [455/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8147\n",
      "Epoch [456/500], Average Training Loss: 0.4188\n",
      "Epoch [456/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8142\n",
      "Epoch [457/500], Average Training Loss: 0.4188\n",
      "Epoch [457/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8151\n",
      "Epoch [458/500], Average Training Loss: 0.4189\n",
      "Epoch [458/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8148\n",
      "Epoch [459/500], Average Training Loss: 0.4189\n",
      "Epoch [459/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8143\n",
      "Epoch [460/500], Average Training Loss: 0.4189\n",
      "Epoch [460/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8145\n",
      "Epoch [461/500], Average Training Loss: 0.4187\n",
      "Epoch [461/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8148\n",
      "Epoch [462/500], Average Training Loss: 0.4186\n",
      "Epoch [462/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8150\n",
      "Epoch [463/500], Average Training Loss: 0.4188\n",
      "Epoch [463/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8144\n",
      "Epoch [464/500], Average Training Loss: 0.4184\n",
      "Epoch [464/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8145\n",
      "Epoch [465/500], Average Training Loss: 0.4186\n",
      "Epoch [465/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8145\n",
      "Epoch [466/500], Average Training Loss: 0.4191\n",
      "Epoch [466/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8147\n",
      "Epoch [467/500], Average Training Loss: 0.4186\n",
      "Epoch [467/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8146\n",
      "Epoch [468/500], Average Training Loss: 0.4187\n",
      "Epoch [468/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8146\n",
      "Epoch [469/500], Average Training Loss: 0.4188\n",
      "Epoch [469/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8146\n",
      "Epoch [470/500], Average Training Loss: 0.4186\n",
      "Epoch [470/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8148\n",
      "Epoch [471/500], Average Training Loss: 0.4187\n",
      "Epoch [471/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8146\n",
      "Epoch [472/500], Average Training Loss: 0.4187\n",
      "Epoch [472/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8145\n",
      "Epoch [473/500], Average Training Loss: 0.4185\n",
      "Epoch [473/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8145\n",
      "Epoch [474/500], Average Training Loss: 0.4185\n",
      "Epoch [474/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8145\n",
      "Epoch [475/500], Average Training Loss: 0.4186\n",
      "Epoch [475/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8146\n",
      "Epoch [476/500], Average Training Loss: 0.4185\n",
      "Epoch [476/500], Average Validation Loss: 0.4230, Average Validation Accuracy: 0.8148\n",
      "Epoch [477/500], Average Training Loss: 0.4184\n",
      "Epoch [477/500], Average Validation Loss: 0.4230, Average Validation Accuracy: 0.8148\n",
      "Epoch [478/500], Average Training Loss: 0.4186\n",
      "Epoch [478/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8146\n",
      "Epoch [479/500], Average Training Loss: 0.4186\n",
      "Epoch [479/500], Average Validation Loss: 0.4230, Average Validation Accuracy: 0.8147\n",
      "Epoch [480/500], Average Training Loss: 0.4183\n",
      "Epoch [480/500], Average Validation Loss: 0.4230, Average Validation Accuracy: 0.8145\n",
      "Epoch [481/500], Average Training Loss: 0.4186\n",
      "Epoch [481/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8148\n",
      "Epoch [482/500], Average Training Loss: 0.4185\n",
      "Epoch [482/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8148\n",
      "Epoch [483/500], Average Training Loss: 0.4184\n",
      "Epoch [483/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8149\n",
      "Epoch [484/500], Average Training Loss: 0.4185\n",
      "Epoch [484/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8146\n",
      "Epoch [485/500], Average Training Loss: 0.4184\n",
      "Epoch [485/500], Average Validation Loss: 0.4228, Average Validation Accuracy: 0.8147\n",
      "Epoch [486/500], Average Training Loss: 0.4184\n",
      "Epoch [486/500], Average Validation Loss: 0.4228, Average Validation Accuracy: 0.8149\n",
      "Epoch [487/500], Average Training Loss: 0.4180\n",
      "Epoch [487/500], Average Validation Loss: 0.4228, Average Validation Accuracy: 0.8149\n",
      "Epoch [488/500], Average Training Loss: 0.4182\n",
      "Epoch [488/500], Average Validation Loss: 0.4228, Average Validation Accuracy: 0.8150\n",
      "Epoch [489/500], Average Training Loss: 0.4183\n",
      "Epoch [489/500], Average Validation Loss: 0.4227, Average Validation Accuracy: 0.8148\n",
      "Epoch [490/500], Average Training Loss: 0.4183\n",
      "Epoch [490/500], Average Validation Loss: 0.4227, Average Validation Accuracy: 0.8147\n",
      "Epoch [491/500], Average Training Loss: 0.4182\n",
      "Epoch [491/500], Average Validation Loss: 0.4227, Average Validation Accuracy: 0.8151\n",
      "Epoch [492/500], Average Training Loss: 0.4181\n",
      "Epoch [492/500], Average Validation Loss: 0.4227, Average Validation Accuracy: 0.8146\n",
      "Epoch [493/500], Average Training Loss: 0.4183\n",
      "Epoch [493/500], Average Validation Loss: 0.4227, Average Validation Accuracy: 0.8148\n",
      "Epoch [494/500], Average Training Loss: 0.4182\n",
      "Epoch [494/500], Average Validation Loss: 0.4227, Average Validation Accuracy: 0.8148\n",
      "Epoch [495/500], Average Training Loss: 0.4182\n",
      "Epoch [495/500], Average Validation Loss: 0.4227, Average Validation Accuracy: 0.8141\n",
      "Epoch [496/500], Average Training Loss: 0.4182\n",
      "Epoch [496/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8146\n",
      "Epoch [497/500], Average Training Loss: 0.4182\n",
      "Epoch [497/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8147\n",
      "Epoch [498/500], Average Training Loss: 0.4180\n",
      "Epoch [498/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8149\n",
      "Epoch [499/500], Average Training Loss: 0.4182\n",
      "Epoch [499/500], Average Validation Loss: 0.4225, Average Validation Accuracy: 0.8148\n",
      "Epoch [500/500], Average Training Loss: 0.4178\n",
      "Epoch [500/500], Average Validation Loss: 0.4225, Average Validation Accuracy: 0.8149\n",
      "Best Validation Accuracy: 0.8151 at epoch 457 for trial 14\n",
      "Epoch [1/500], Average Training Loss: 0.5258\n",
      "Epoch [1/500], Average Validation Loss: 0.4544, Average Validation Accuracy: 0.7958\n",
      "Epoch [2/500], Average Training Loss: 0.4459\n",
      "Epoch [2/500], Average Validation Loss: 0.4454, Average Validation Accuracy: 0.8009\n",
      "Epoch [3/500], Average Training Loss: 0.4394\n",
      "Epoch [3/500], Average Validation Loss: 0.4403, Average Validation Accuracy: 0.8035\n",
      "Epoch [4/500], Average Training Loss: 0.4352\n",
      "Epoch [4/500], Average Validation Loss: 0.4369, Average Validation Accuracy: 0.8056\n",
      "Epoch [5/500], Average Training Loss: 0.4326\n",
      "Epoch [5/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8081\n",
      "Epoch [6/500], Average Training Loss: 0.4310\n",
      "Epoch [6/500], Average Validation Loss: 0.4331, Average Validation Accuracy: 0.8093\n",
      "Epoch [7/500], Average Training Loss: 0.4301\n",
      "Epoch [7/500], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8106\n",
      "Epoch [8/500], Average Training Loss: 0.4293\n",
      "Epoch [8/500], Average Validation Loss: 0.4329, Average Validation Accuracy: 0.8107\n",
      "Epoch [9/500], Average Training Loss: 0.4286\n",
      "Epoch [9/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8116\n",
      "Epoch [10/500], Average Training Loss: 0.4280\n",
      "Epoch [10/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8119\n",
      "Epoch [11/500], Average Training Loss: 0.4275\n",
      "Epoch [11/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8109\n",
      "Epoch [12/500], Average Training Loss: 0.4270\n",
      "Epoch [12/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8117\n",
      "Epoch [13/500], Average Training Loss: 0.4266\n",
      "Epoch [13/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8117\n",
      "Epoch [14/500], Average Training Loss: 0.4260\n",
      "Epoch [14/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8111\n",
      "Epoch [15/500], Average Training Loss: 0.4256\n",
      "Epoch [15/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8121\n",
      "Epoch [16/500], Average Training Loss: 0.4250\n",
      "Epoch [16/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8125\n",
      "Epoch [17/500], Average Training Loss: 0.4243\n",
      "Epoch [17/500], Average Validation Loss: 0.4272, Average Validation Accuracy: 0.8124\n",
      "Epoch [18/500], Average Training Loss: 0.4236\n",
      "Epoch [18/500], Average Validation Loss: 0.4268, Average Validation Accuracy: 0.8125\n",
      "Epoch [19/500], Average Training Loss: 0.4231\n",
      "Epoch [19/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8129\n",
      "Epoch [20/500], Average Training Loss: 0.4227\n",
      "Epoch [20/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8128\n",
      "Epoch [21/500], Average Training Loss: 0.4224\n",
      "Epoch [21/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8134\n",
      "Epoch [22/500], Average Training Loss: 0.4221\n",
      "Epoch [22/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8125\n",
      "Epoch [23/500], Average Training Loss: 0.4216\n",
      "Epoch [23/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8128\n",
      "Epoch [24/500], Average Training Loss: 0.4214\n",
      "Epoch [24/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8122\n",
      "Epoch [25/500], Average Training Loss: 0.4212\n",
      "Epoch [25/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8127\n",
      "Epoch [26/500], Average Training Loss: 0.4208\n",
      "Epoch [26/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8131\n",
      "Epoch [27/500], Average Training Loss: 0.4206\n",
      "Epoch [27/500], Average Validation Loss: 0.4242, Average Validation Accuracy: 0.8134\n",
      "Epoch [28/500], Average Training Loss: 0.4203\n",
      "Epoch [28/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8133\n",
      "Epoch [29/500], Average Training Loss: 0.4202\n",
      "Epoch [29/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8140\n",
      "Epoch [30/500], Average Training Loss: 0.4200\n",
      "Epoch [30/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8138\n",
      "Epoch [31/500], Average Training Loss: 0.4197\n",
      "Epoch [31/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8142\n",
      "Epoch [32/500], Average Training Loss: 0.4194\n",
      "Epoch [32/500], Average Validation Loss: 0.4231, Average Validation Accuracy: 0.8147\n",
      "Epoch [33/500], Average Training Loss: 0.4192\n",
      "Epoch [33/500], Average Validation Loss: 0.4229, Average Validation Accuracy: 0.8151\n",
      "Epoch [34/500], Average Training Loss: 0.4187\n",
      "Epoch [34/500], Average Validation Loss: 0.4228, Average Validation Accuracy: 0.8153\n",
      "Epoch [35/500], Average Training Loss: 0.4185\n",
      "Epoch [35/500], Average Validation Loss: 0.4237, Average Validation Accuracy: 0.8143\n",
      "Epoch [36/500], Average Training Loss: 0.4180\n",
      "Epoch [36/500], Average Validation Loss: 0.4219, Average Validation Accuracy: 0.8148\n",
      "Epoch [37/500], Average Training Loss: 0.4176\n",
      "Epoch [37/500], Average Validation Loss: 0.4218, Average Validation Accuracy: 0.8141\n",
      "Epoch [38/500], Average Training Loss: 0.4173\n",
      "Epoch [38/500], Average Validation Loss: 0.4211, Average Validation Accuracy: 0.8152\n",
      "Epoch [39/500], Average Training Loss: 0.4169\n",
      "Epoch [39/500], Average Validation Loss: 0.4210, Average Validation Accuracy: 0.8153\n",
      "Epoch [40/500], Average Training Loss: 0.4168\n",
      "Epoch [40/500], Average Validation Loss: 0.4204, Average Validation Accuracy: 0.8157\n",
      "Epoch [41/500], Average Training Loss: 0.4164\n",
      "Epoch [41/500], Average Validation Loss: 0.4198, Average Validation Accuracy: 0.8171\n",
      "Epoch [42/500], Average Training Loss: 0.4159\n",
      "Epoch [42/500], Average Validation Loss: 0.4196, Average Validation Accuracy: 0.8166\n",
      "Epoch [43/500], Average Training Loss: 0.4158\n",
      "Epoch [43/500], Average Validation Loss: 0.4198, Average Validation Accuracy: 0.8163\n",
      "Epoch [44/500], Average Training Loss: 0.4153\n",
      "Epoch [44/500], Average Validation Loss: 0.4198, Average Validation Accuracy: 0.8158\n",
      "Epoch [45/500], Average Training Loss: 0.4152\n",
      "Epoch [45/500], Average Validation Loss: 0.4187, Average Validation Accuracy: 0.8174\n",
      "Epoch [46/500], Average Training Loss: 0.4149\n",
      "Epoch [46/500], Average Validation Loss: 0.4189, Average Validation Accuracy: 0.8183\n",
      "Epoch [47/500], Average Training Loss: 0.4147\n",
      "Epoch [47/500], Average Validation Loss: 0.4182, Average Validation Accuracy: 0.8178\n",
      "Epoch [48/500], Average Training Loss: 0.4146\n",
      "Epoch [48/500], Average Validation Loss: 0.4187, Average Validation Accuracy: 0.8165\n",
      "Epoch [49/500], Average Training Loss: 0.4146\n",
      "Epoch [49/500], Average Validation Loss: 0.4184, Average Validation Accuracy: 0.8178\n",
      "Epoch [50/500], Average Training Loss: 0.4143\n",
      "Epoch [50/500], Average Validation Loss: 0.4179, Average Validation Accuracy: 0.8184\n",
      "Epoch [51/500], Average Training Loss: 0.4142\n",
      "Epoch [51/500], Average Validation Loss: 0.4176, Average Validation Accuracy: 0.8179\n",
      "Epoch [52/500], Average Training Loss: 0.4139\n",
      "Epoch [52/500], Average Validation Loss: 0.4176, Average Validation Accuracy: 0.8182\n",
      "Epoch [53/500], Average Training Loss: 0.4137\n",
      "Epoch [53/500], Average Validation Loss: 0.4173, Average Validation Accuracy: 0.8192\n",
      "Epoch [54/500], Average Training Loss: 0.4137\n",
      "Epoch [54/500], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8190\n",
      "Epoch [55/500], Average Training Loss: 0.4136\n",
      "Epoch [55/500], Average Validation Loss: 0.4168, Average Validation Accuracy: 0.8189\n",
      "Epoch [56/500], Average Training Loss: 0.4134\n",
      "Epoch [56/500], Average Validation Loss: 0.4167, Average Validation Accuracy: 0.8183\n",
      "Epoch [57/500], Average Training Loss: 0.4131\n",
      "Epoch [57/500], Average Validation Loss: 0.4169, Average Validation Accuracy: 0.8177\n",
      "Epoch [58/500], Average Training Loss: 0.4129\n",
      "Epoch [58/500], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8177\n",
      "Epoch [59/500], Average Training Loss: 0.4131\n",
      "Epoch [59/500], Average Validation Loss: 0.4166, Average Validation Accuracy: 0.8185\n",
      "Epoch [60/500], Average Training Loss: 0.4128\n",
      "Epoch [60/500], Average Validation Loss: 0.4168, Average Validation Accuracy: 0.8169\n",
      "Epoch [61/500], Average Training Loss: 0.4126\n",
      "Epoch [61/500], Average Validation Loss: 0.4159, Average Validation Accuracy: 0.8192\n",
      "Epoch [62/500], Average Training Loss: 0.4126\n",
      "Epoch [62/500], Average Validation Loss: 0.4159, Average Validation Accuracy: 0.8186\n",
      "Epoch [63/500], Average Training Loss: 0.4125\n",
      "Epoch [63/500], Average Validation Loss: 0.4154, Average Validation Accuracy: 0.8191\n",
      "Epoch [64/500], Average Training Loss: 0.4122\n",
      "Epoch [64/500], Average Validation Loss: 0.4153, Average Validation Accuracy: 0.8199\n",
      "Epoch [65/500], Average Training Loss: 0.4122\n",
      "Epoch [65/500], Average Validation Loss: 0.4154, Average Validation Accuracy: 0.8191\n",
      "Epoch [66/500], Average Training Loss: 0.4119\n",
      "Epoch [66/500], Average Validation Loss: 0.4168, Average Validation Accuracy: 0.8170\n",
      "Epoch [67/500], Average Training Loss: 0.4119\n",
      "Epoch [67/500], Average Validation Loss: 0.4151, Average Validation Accuracy: 0.8193\n",
      "Epoch [68/500], Average Training Loss: 0.4119\n",
      "Epoch [68/500], Average Validation Loss: 0.4150, Average Validation Accuracy: 0.8195\n",
      "Epoch [69/500], Average Training Loss: 0.4117\n",
      "Epoch [69/500], Average Validation Loss: 0.4148, Average Validation Accuracy: 0.8195\n",
      "Epoch [70/500], Average Training Loss: 0.4118\n",
      "Epoch [70/500], Average Validation Loss: 0.4156, Average Validation Accuracy: 0.8191\n",
      "Epoch [71/500], Average Training Loss: 0.4115\n",
      "Epoch [71/500], Average Validation Loss: 0.4148, Average Validation Accuracy: 0.8189\n",
      "Epoch [72/500], Average Training Loss: 0.4114\n",
      "Epoch [72/500], Average Validation Loss: 0.4151, Average Validation Accuracy: 0.8192\n",
      "Epoch [73/500], Average Training Loss: 0.4114\n",
      "Epoch [73/500], Average Validation Loss: 0.4155, Average Validation Accuracy: 0.8192\n",
      "Epoch [74/500], Average Training Loss: 0.4116\n",
      "Epoch [74/500], Average Validation Loss: 0.4147, Average Validation Accuracy: 0.8195\n",
      "Epoch [75/500], Average Training Loss: 0.4111\n",
      "Epoch [75/500], Average Validation Loss: 0.4161, Average Validation Accuracy: 0.8178\n",
      "Epoch [76/500], Average Training Loss: 0.4112\n",
      "Epoch [76/500], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8179\n",
      "Epoch [77/500], Average Training Loss: 0.4111\n",
      "Epoch [77/500], Average Validation Loss: 0.4142, Average Validation Accuracy: 0.8203\n",
      "Epoch [78/500], Average Training Loss: 0.4111\n",
      "Epoch [78/500], Average Validation Loss: 0.4143, Average Validation Accuracy: 0.8200\n",
      "Epoch [79/500], Average Training Loss: 0.4110\n",
      "Epoch [79/500], Average Validation Loss: 0.4143, Average Validation Accuracy: 0.8190\n",
      "Epoch [80/500], Average Training Loss: 0.4109\n",
      "Epoch [80/500], Average Validation Loss: 0.4145, Average Validation Accuracy: 0.8197\n",
      "Epoch [81/500], Average Training Loss: 0.4108\n",
      "Epoch [81/500], Average Validation Loss: 0.4142, Average Validation Accuracy: 0.8195\n",
      "Epoch [82/500], Average Training Loss: 0.4109\n",
      "Epoch [82/500], Average Validation Loss: 0.4141, Average Validation Accuracy: 0.8192\n",
      "Epoch [83/500], Average Training Loss: 0.4109\n",
      "Epoch [83/500], Average Validation Loss: 0.4138, Average Validation Accuracy: 0.8203\n",
      "Epoch [84/500], Average Training Loss: 0.4106\n",
      "Epoch [84/500], Average Validation Loss: 0.4137, Average Validation Accuracy: 0.8200\n",
      "Epoch [85/500], Average Training Loss: 0.4105\n",
      "Epoch [85/500], Average Validation Loss: 0.4140, Average Validation Accuracy: 0.8198\n",
      "Epoch [86/500], Average Training Loss: 0.4104\n",
      "Epoch [86/500], Average Validation Loss: 0.4140, Average Validation Accuracy: 0.8202\n",
      "Epoch [87/500], Average Training Loss: 0.4103\n",
      "Epoch [87/500], Average Validation Loss: 0.4137, Average Validation Accuracy: 0.8196\n",
      "Epoch [88/500], Average Training Loss: 0.4101\n",
      "Epoch [88/500], Average Validation Loss: 0.4136, Average Validation Accuracy: 0.8200\n",
      "Epoch [89/500], Average Training Loss: 0.4101\n",
      "Epoch [89/500], Average Validation Loss: 0.4152, Average Validation Accuracy: 0.8175\n",
      "Epoch [90/500], Average Training Loss: 0.4102\n",
      "Epoch [90/500], Average Validation Loss: 0.4135, Average Validation Accuracy: 0.8203\n",
      "Epoch [91/500], Average Training Loss: 0.4102\n",
      "Epoch [91/500], Average Validation Loss: 0.4137, Average Validation Accuracy: 0.8199\n",
      "Epoch [92/500], Average Training Loss: 0.4100\n",
      "Epoch [92/500], Average Validation Loss: 0.4137, Average Validation Accuracy: 0.8189\n",
      "Epoch [93/500], Average Training Loss: 0.4100\n",
      "Epoch [93/500], Average Validation Loss: 0.4133, Average Validation Accuracy: 0.8199\n",
      "Epoch [94/500], Average Training Loss: 0.4098\n",
      "Epoch [94/500], Average Validation Loss: 0.4133, Average Validation Accuracy: 0.8199\n",
      "Epoch [95/500], Average Training Loss: 0.4099\n",
      "Epoch [95/500], Average Validation Loss: 0.4132, Average Validation Accuracy: 0.8196\n",
      "Epoch [96/500], Average Training Loss: 0.4096\n",
      "Epoch [96/500], Average Validation Loss: 0.4130, Average Validation Accuracy: 0.8203\n",
      "Epoch [97/500], Average Training Loss: 0.4094\n",
      "Epoch [97/500], Average Validation Loss: 0.4134, Average Validation Accuracy: 0.8198\n",
      "Epoch [98/500], Average Training Loss: 0.4096\n",
      "Epoch [98/500], Average Validation Loss: 0.4131, Average Validation Accuracy: 0.8200\n",
      "Epoch [99/500], Average Training Loss: 0.4095\n",
      "Epoch [99/500], Average Validation Loss: 0.4149, Average Validation Accuracy: 0.8191\n",
      "Epoch [100/500], Average Training Loss: 0.4094\n",
      "Epoch [100/500], Average Validation Loss: 0.4127, Average Validation Accuracy: 0.8206\n",
      "Epoch [101/500], Average Training Loss: 0.4092\n",
      "Epoch [101/500], Average Validation Loss: 0.4127, Average Validation Accuracy: 0.8198\n",
      "Epoch [102/500], Average Training Loss: 0.4092\n",
      "Epoch [102/500], Average Validation Loss: 0.4138, Average Validation Accuracy: 0.8193\n",
      "Epoch [103/500], Average Training Loss: 0.4090\n",
      "Epoch [103/500], Average Validation Loss: 0.4130, Average Validation Accuracy: 0.8193\n",
      "Epoch [104/500], Average Training Loss: 0.4087\n",
      "Epoch [104/500], Average Validation Loss: 0.4123, Average Validation Accuracy: 0.8210\n",
      "Epoch [105/500], Average Training Loss: 0.4086\n",
      "Epoch [105/500], Average Validation Loss: 0.4124, Average Validation Accuracy: 0.8204\n",
      "Epoch [106/500], Average Training Loss: 0.4089\n",
      "Epoch [106/500], Average Validation Loss: 0.4137, Average Validation Accuracy: 0.8192\n",
      "Epoch [107/500], Average Training Loss: 0.4084\n",
      "Epoch [107/500], Average Validation Loss: 0.4126, Average Validation Accuracy: 0.8200\n",
      "Epoch [108/500], Average Training Loss: 0.4083\n",
      "Epoch [108/500], Average Validation Loss: 0.4121, Average Validation Accuracy: 0.8196\n",
      "Epoch [109/500], Average Training Loss: 0.4081\n",
      "Epoch [109/500], Average Validation Loss: 0.4127, Average Validation Accuracy: 0.8197\n",
      "Epoch [110/500], Average Training Loss: 0.4081\n",
      "Epoch [110/500], Average Validation Loss: 0.4119, Average Validation Accuracy: 0.8203\n",
      "Epoch [111/500], Average Training Loss: 0.4080\n",
      "Epoch [111/500], Average Validation Loss: 0.4117, Average Validation Accuracy: 0.8214\n",
      "Epoch [112/500], Average Training Loss: 0.4079\n",
      "Epoch [112/500], Average Validation Loss: 0.4118, Average Validation Accuracy: 0.8209\n",
      "Epoch [113/500], Average Training Loss: 0.4076\n",
      "Epoch [113/500], Average Validation Loss: 0.4131, Average Validation Accuracy: 0.8206\n",
      "Epoch [114/500], Average Training Loss: 0.4075\n",
      "Epoch [114/500], Average Validation Loss: 0.4117, Average Validation Accuracy: 0.8211\n",
      "Epoch [115/500], Average Training Loss: 0.4074\n",
      "Epoch [115/500], Average Validation Loss: 0.4113, Average Validation Accuracy: 0.8212\n",
      "Epoch [116/500], Average Training Loss: 0.4072\n",
      "Epoch [116/500], Average Validation Loss: 0.4110, Average Validation Accuracy: 0.8209\n",
      "Epoch [117/500], Average Training Loss: 0.4072\n",
      "Epoch [117/500], Average Validation Loss: 0.4115, Average Validation Accuracy: 0.8206\n",
      "Epoch [118/500], Average Training Loss: 0.4072\n",
      "Epoch [118/500], Average Validation Loss: 0.4108, Average Validation Accuracy: 0.8197\n",
      "Epoch [119/500], Average Training Loss: 0.4069\n",
      "Epoch [119/500], Average Validation Loss: 0.4111, Average Validation Accuracy: 0.8211\n",
      "Epoch [120/500], Average Training Loss: 0.4066\n",
      "Epoch [120/500], Average Validation Loss: 0.4111, Average Validation Accuracy: 0.8207\n",
      "Epoch [121/500], Average Training Loss: 0.4067\n",
      "Epoch [121/500], Average Validation Loss: 0.4106, Average Validation Accuracy: 0.8211\n",
      "Epoch [122/500], Average Training Loss: 0.4066\n",
      "Epoch [122/500], Average Validation Loss: 0.4105, Average Validation Accuracy: 0.8213\n",
      "Epoch [123/500], Average Training Loss: 0.4064\n",
      "Epoch [123/500], Average Validation Loss: 0.4104, Average Validation Accuracy: 0.8213\n",
      "Epoch [124/500], Average Training Loss: 0.4065\n",
      "Epoch [124/500], Average Validation Loss: 0.4103, Average Validation Accuracy: 0.8216\n",
      "Epoch [125/500], Average Training Loss: 0.4062\n",
      "Epoch [125/500], Average Validation Loss: 0.4107, Average Validation Accuracy: 0.8209\n",
      "Epoch [126/500], Average Training Loss: 0.4060\n",
      "Epoch [126/500], Average Validation Loss: 0.4101, Average Validation Accuracy: 0.8215\n",
      "Epoch [127/500], Average Training Loss: 0.4060\n",
      "Epoch [127/500], Average Validation Loss: 0.4098, Average Validation Accuracy: 0.8217\n",
      "Epoch [128/500], Average Training Loss: 0.4057\n",
      "Epoch [128/500], Average Validation Loss: 0.4099, Average Validation Accuracy: 0.8214\n",
      "Epoch [129/500], Average Training Loss: 0.4056\n",
      "Epoch [129/500], Average Validation Loss: 0.4098, Average Validation Accuracy: 0.8218\n",
      "Epoch [130/500], Average Training Loss: 0.4056\n",
      "Epoch [130/500], Average Validation Loss: 0.4096, Average Validation Accuracy: 0.8214\n",
      "Epoch [131/500], Average Training Loss: 0.4052\n",
      "Epoch [131/500], Average Validation Loss: 0.4095, Average Validation Accuracy: 0.8210\n",
      "Epoch [132/500], Average Training Loss: 0.4054\n",
      "Epoch [132/500], Average Validation Loss: 0.4096, Average Validation Accuracy: 0.8210\n",
      "Epoch [133/500], Average Training Loss: 0.4052\n",
      "Epoch [133/500], Average Validation Loss: 0.4105, Average Validation Accuracy: 0.8206\n",
      "Epoch [134/500], Average Training Loss: 0.4051\n",
      "Epoch [134/500], Average Validation Loss: 0.4107, Average Validation Accuracy: 0.8206\n",
      "Epoch [135/500], Average Training Loss: 0.4051\n",
      "Epoch [135/500], Average Validation Loss: 0.4090, Average Validation Accuracy: 0.8214\n",
      "Epoch [136/500], Average Training Loss: 0.4048\n",
      "Epoch [136/500], Average Validation Loss: 0.4096, Average Validation Accuracy: 0.8212\n",
      "Epoch [137/500], Average Training Loss: 0.4048\n",
      "Epoch [137/500], Average Validation Loss: 0.4094, Average Validation Accuracy: 0.8217\n",
      "Epoch [138/500], Average Training Loss: 0.4046\n",
      "Epoch [138/500], Average Validation Loss: 0.4090, Average Validation Accuracy: 0.8226\n",
      "Epoch [139/500], Average Training Loss: 0.4045\n",
      "Epoch [139/500], Average Validation Loss: 0.4093, Average Validation Accuracy: 0.8214\n",
      "Epoch [140/500], Average Training Loss: 0.4044\n",
      "Epoch [140/500], Average Validation Loss: 0.4084, Average Validation Accuracy: 0.8220\n",
      "Epoch [141/500], Average Training Loss: 0.4044\n",
      "Epoch [141/500], Average Validation Loss: 0.4086, Average Validation Accuracy: 0.8217\n",
      "Epoch [142/500], Average Training Loss: 0.4043\n",
      "Epoch [142/500], Average Validation Loss: 0.4083, Average Validation Accuracy: 0.8227\n",
      "Epoch [143/500], Average Training Loss: 0.4041\n",
      "Epoch [143/500], Average Validation Loss: 0.4086, Average Validation Accuracy: 0.8220\n",
      "Epoch [144/500], Average Training Loss: 0.4039\n",
      "Epoch [144/500], Average Validation Loss: 0.4084, Average Validation Accuracy: 0.8220\n",
      "Epoch [145/500], Average Training Loss: 0.4041\n",
      "Epoch [145/500], Average Validation Loss: 0.4080, Average Validation Accuracy: 0.8234\n",
      "Epoch [146/500], Average Training Loss: 0.4040\n",
      "Epoch [146/500], Average Validation Loss: 0.4082, Average Validation Accuracy: 0.8226\n",
      "Epoch [147/500], Average Training Loss: 0.4039\n",
      "Epoch [147/500], Average Validation Loss: 0.4079, Average Validation Accuracy: 0.8218\n",
      "Epoch [148/500], Average Training Loss: 0.4036\n",
      "Epoch [148/500], Average Validation Loss: 0.4079, Average Validation Accuracy: 0.8226\n",
      "Epoch [149/500], Average Training Loss: 0.4038\n",
      "Epoch [149/500], Average Validation Loss: 0.4079, Average Validation Accuracy: 0.8228\n",
      "Epoch [150/500], Average Training Loss: 0.4036\n",
      "Epoch [150/500], Average Validation Loss: 0.4080, Average Validation Accuracy: 0.8227\n",
      "Epoch [151/500], Average Training Loss: 0.4035\n",
      "Epoch [151/500], Average Validation Loss: 0.4074, Average Validation Accuracy: 0.8232\n",
      "Epoch [152/500], Average Training Loss: 0.4035\n",
      "Epoch [152/500], Average Validation Loss: 0.4078, Average Validation Accuracy: 0.8235\n",
      "Epoch [153/500], Average Training Loss: 0.4033\n",
      "Epoch [153/500], Average Validation Loss: 0.4077, Average Validation Accuracy: 0.8233\n",
      "Epoch [154/500], Average Training Loss: 0.4033\n",
      "Epoch [154/500], Average Validation Loss: 0.4073, Average Validation Accuracy: 0.8236\n",
      "Epoch [155/500], Average Training Loss: 0.4029\n",
      "Epoch [155/500], Average Validation Loss: 0.4079, Average Validation Accuracy: 0.8227\n",
      "Epoch [156/500], Average Training Loss: 0.4030\n",
      "Epoch [156/500], Average Validation Loss: 0.4073, Average Validation Accuracy: 0.8237\n",
      "Epoch [157/500], Average Training Loss: 0.4029\n",
      "Epoch [157/500], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8231\n",
      "Epoch [158/500], Average Training Loss: 0.4028\n",
      "Epoch [158/500], Average Validation Loss: 0.4074, Average Validation Accuracy: 0.8232\n",
      "Epoch [159/500], Average Training Loss: 0.4029\n",
      "Epoch [159/500], Average Validation Loss: 0.4069, Average Validation Accuracy: 0.8237\n",
      "Epoch [160/500], Average Training Loss: 0.4026\n",
      "Epoch [160/500], Average Validation Loss: 0.4074, Average Validation Accuracy: 0.8224\n",
      "Epoch [161/500], Average Training Loss: 0.4025\n",
      "Epoch [161/500], Average Validation Loss: 0.4076, Average Validation Accuracy: 0.8234\n",
      "Epoch [162/500], Average Training Loss: 0.4026\n",
      "Epoch [162/500], Average Validation Loss: 0.4069, Average Validation Accuracy: 0.8239\n",
      "Epoch [163/500], Average Training Loss: 0.4024\n",
      "Epoch [163/500], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8223\n",
      "Epoch [164/500], Average Training Loss: 0.4023\n",
      "Epoch [164/500], Average Validation Loss: 0.4066, Average Validation Accuracy: 0.8236\n",
      "Epoch [165/500], Average Training Loss: 0.4024\n",
      "Epoch [165/500], Average Validation Loss: 0.4069, Average Validation Accuracy: 0.8238\n",
      "Epoch [166/500], Average Training Loss: 0.4021\n",
      "Epoch [166/500], Average Validation Loss: 0.4078, Average Validation Accuracy: 0.8236\n",
      "Epoch [167/500], Average Training Loss: 0.4022\n",
      "Epoch [167/500], Average Validation Loss: 0.4072, Average Validation Accuracy: 0.8234\n",
      "Epoch [168/500], Average Training Loss: 0.4020\n",
      "Epoch [168/500], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8235\n",
      "Epoch [169/500], Average Training Loss: 0.4020\n",
      "Epoch [169/500], Average Validation Loss: 0.4068, Average Validation Accuracy: 0.8243\n",
      "Epoch [170/500], Average Training Loss: 0.4018\n",
      "Epoch [170/500], Average Validation Loss: 0.4066, Average Validation Accuracy: 0.8238\n",
      "Epoch [171/500], Average Training Loss: 0.4018\n",
      "Epoch [171/500], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8238\n",
      "Epoch [172/500], Average Training Loss: 0.4018\n",
      "Epoch [172/500], Average Validation Loss: 0.4064, Average Validation Accuracy: 0.8237\n",
      "Epoch [173/500], Average Training Loss: 0.4017\n",
      "Epoch [173/500], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8238\n",
      "Epoch [174/500], Average Training Loss: 0.4016\n",
      "Epoch [174/500], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8238\n",
      "Epoch [175/500], Average Training Loss: 0.4015\n",
      "Epoch [175/500], Average Validation Loss: 0.4060, Average Validation Accuracy: 0.8239\n",
      "Epoch [176/500], Average Training Loss: 0.4014\n",
      "Epoch [176/500], Average Validation Loss: 0.4057, Average Validation Accuracy: 0.8240\n",
      "Epoch [177/500], Average Training Loss: 0.4013\n",
      "Epoch [177/500], Average Validation Loss: 0.4058, Average Validation Accuracy: 0.8246\n",
      "Epoch [178/500], Average Training Loss: 0.4015\n",
      "Epoch [178/500], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8249\n",
      "Epoch [179/500], Average Training Loss: 0.4013\n",
      "Epoch [179/500], Average Validation Loss: 0.4058, Average Validation Accuracy: 0.8247\n",
      "Epoch [180/500], Average Training Loss: 0.4011\n",
      "Epoch [180/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8242\n",
      "Epoch [181/500], Average Training Loss: 0.4011\n",
      "Epoch [181/500], Average Validation Loss: 0.4057, Average Validation Accuracy: 0.8240\n",
      "Epoch [182/500], Average Training Loss: 0.4012\n",
      "Epoch [182/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8245\n",
      "Epoch [183/500], Average Training Loss: 0.4010\n",
      "Epoch [183/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8250\n",
      "Epoch [184/500], Average Training Loss: 0.4008\n",
      "Epoch [184/500], Average Validation Loss: 0.4055, Average Validation Accuracy: 0.8239\n",
      "Epoch [185/500], Average Training Loss: 0.4009\n",
      "Epoch [185/500], Average Validation Loss: 0.4052, Average Validation Accuracy: 0.8247\n",
      "Epoch [186/500], Average Training Loss: 0.4007\n",
      "Epoch [186/500], Average Validation Loss: 0.4049, Average Validation Accuracy: 0.8245\n",
      "Epoch [187/500], Average Training Loss: 0.4007\n",
      "Epoch [187/500], Average Validation Loss: 0.4055, Average Validation Accuracy: 0.8246\n",
      "Epoch [188/500], Average Training Loss: 0.4005\n",
      "Epoch [188/500], Average Validation Loss: 0.4055, Average Validation Accuracy: 0.8242\n",
      "Epoch [189/500], Average Training Loss: 0.4006\n",
      "Epoch [189/500], Average Validation Loss: 0.4052, Average Validation Accuracy: 0.8246\n",
      "Epoch [190/500], Average Training Loss: 0.4005\n",
      "Epoch [190/500], Average Validation Loss: 0.4048, Average Validation Accuracy: 0.8249\n",
      "Epoch [191/500], Average Training Loss: 0.4004\n",
      "Epoch [191/500], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8236\n",
      "Epoch [192/500], Average Training Loss: 0.4004\n",
      "Epoch [192/500], Average Validation Loss: 0.4048, Average Validation Accuracy: 0.8252\n",
      "Epoch [193/500], Average Training Loss: 0.4003\n",
      "Epoch [193/500], Average Validation Loss: 0.4050, Average Validation Accuracy: 0.8246\n",
      "Epoch [194/500], Average Training Loss: 0.4001\n",
      "Epoch [194/500], Average Validation Loss: 0.4045, Average Validation Accuracy: 0.8246\n",
      "Epoch [195/500], Average Training Loss: 0.4001\n",
      "Epoch [195/500], Average Validation Loss: 0.4062, Average Validation Accuracy: 0.8246\n",
      "Epoch [196/500], Average Training Loss: 0.4001\n",
      "Epoch [196/500], Average Validation Loss: 0.4047, Average Validation Accuracy: 0.8254\n",
      "Epoch [197/500], Average Training Loss: 0.3999\n",
      "Epoch [197/500], Average Validation Loss: 0.4048, Average Validation Accuracy: 0.8245\n",
      "Epoch [198/500], Average Training Loss: 0.4001\n",
      "Epoch [198/500], Average Validation Loss: 0.4047, Average Validation Accuracy: 0.8250\n",
      "Epoch [199/500], Average Training Loss: 0.3999\n",
      "Epoch [199/500], Average Validation Loss: 0.4045, Average Validation Accuracy: 0.8254\n",
      "Epoch [200/500], Average Training Loss: 0.3997\n",
      "Epoch [200/500], Average Validation Loss: 0.4042, Average Validation Accuracy: 0.8249\n",
      "Epoch [201/500], Average Training Loss: 0.3996\n",
      "Epoch [201/500], Average Validation Loss: 0.4044, Average Validation Accuracy: 0.8251\n",
      "Epoch [202/500], Average Training Loss: 0.3996\n",
      "Epoch [202/500], Average Validation Loss: 0.4046, Average Validation Accuracy: 0.8246\n",
      "Epoch [203/500], Average Training Loss: 0.3996\n",
      "Epoch [203/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8239\n",
      "Epoch [204/500], Average Training Loss: 0.3995\n",
      "Epoch [204/500], Average Validation Loss: 0.4043, Average Validation Accuracy: 0.8248\n",
      "Epoch [205/500], Average Training Loss: 0.3994\n",
      "Epoch [205/500], Average Validation Loss: 0.4044, Average Validation Accuracy: 0.8244\n",
      "Epoch [206/500], Average Training Loss: 0.3993\n",
      "Epoch [206/500], Average Validation Loss: 0.4043, Average Validation Accuracy: 0.8256\n",
      "Epoch [207/500], Average Training Loss: 0.3993\n",
      "Epoch [207/500], Average Validation Loss: 0.4041, Average Validation Accuracy: 0.8248\n",
      "Epoch [208/500], Average Training Loss: 0.3993\n",
      "Epoch [208/500], Average Validation Loss: 0.4043, Average Validation Accuracy: 0.8251\n",
      "Epoch [209/500], Average Training Loss: 0.3991\n",
      "Epoch [209/500], Average Validation Loss: 0.4045, Average Validation Accuracy: 0.8249\n",
      "Epoch [210/500], Average Training Loss: 0.3991\n",
      "Epoch [210/500], Average Validation Loss: 0.4041, Average Validation Accuracy: 0.8252\n",
      "Epoch [211/500], Average Training Loss: 0.3991\n",
      "Epoch [211/500], Average Validation Loss: 0.4042, Average Validation Accuracy: 0.8256\n",
      "Epoch [212/500], Average Training Loss: 0.3990\n",
      "Epoch [212/500], Average Validation Loss: 0.4039, Average Validation Accuracy: 0.8244\n",
      "Epoch [213/500], Average Training Loss: 0.3991\n",
      "Epoch [213/500], Average Validation Loss: 0.4036, Average Validation Accuracy: 0.8256\n",
      "Epoch [214/500], Average Training Loss: 0.3988\n",
      "Epoch [214/500], Average Validation Loss: 0.4041, Average Validation Accuracy: 0.8245\n",
      "Epoch [215/500], Average Training Loss: 0.3988\n",
      "Epoch [215/500], Average Validation Loss: 0.4036, Average Validation Accuracy: 0.8252\n",
      "Epoch [216/500], Average Training Loss: 0.3988\n",
      "Epoch [216/500], Average Validation Loss: 0.4038, Average Validation Accuracy: 0.8254\n",
      "Epoch [217/500], Average Training Loss: 0.3988\n",
      "Epoch [217/500], Average Validation Loss: 0.4040, Average Validation Accuracy: 0.8262\n",
      "Epoch [218/500], Average Training Loss: 0.3985\n",
      "Epoch [218/500], Average Validation Loss: 0.4039, Average Validation Accuracy: 0.8250\n",
      "Epoch [219/500], Average Training Loss: 0.3985\n",
      "Epoch [219/500], Average Validation Loss: 0.4037, Average Validation Accuracy: 0.8250\n",
      "Epoch [220/500], Average Training Loss: 0.3985\n",
      "Epoch [220/500], Average Validation Loss: 0.4036, Average Validation Accuracy: 0.8249\n",
      "Epoch [221/500], Average Training Loss: 0.3985\n",
      "Epoch [221/500], Average Validation Loss: 0.4034, Average Validation Accuracy: 0.8255\n",
      "Epoch [222/500], Average Training Loss: 0.3983\n",
      "Epoch [222/500], Average Validation Loss: 0.4040, Average Validation Accuracy: 0.8258\n",
      "Epoch [223/500], Average Training Loss: 0.3983\n",
      "Epoch [223/500], Average Validation Loss: 0.4038, Average Validation Accuracy: 0.8242\n",
      "Epoch [224/500], Average Training Loss: 0.3983\n",
      "Epoch [224/500], Average Validation Loss: 0.4038, Average Validation Accuracy: 0.8238\n",
      "Epoch [225/500], Average Training Loss: 0.3983\n",
      "Epoch [225/500], Average Validation Loss: 0.4035, Average Validation Accuracy: 0.8238\n",
      "Epoch [226/500], Average Training Loss: 0.3981\n",
      "Epoch [226/500], Average Validation Loss: 0.4047, Average Validation Accuracy: 0.8245\n",
      "Epoch [227/500], Average Training Loss: 0.3981\n",
      "Epoch [227/500], Average Validation Loss: 0.4038, Average Validation Accuracy: 0.8244\n",
      "Epoch [228/500], Average Training Loss: 0.3980\n",
      "Epoch [228/500], Average Validation Loss: 0.4036, Average Validation Accuracy: 0.8252\n",
      "Epoch [229/500], Average Training Loss: 0.3978\n",
      "Epoch [229/500], Average Validation Loss: 0.4037, Average Validation Accuracy: 0.8260\n",
      "Epoch [230/500], Average Training Loss: 0.3977\n",
      "Epoch [230/500], Average Validation Loss: 0.4034, Average Validation Accuracy: 0.8246\n",
      "Epoch [231/500], Average Training Loss: 0.3979\n",
      "Epoch [231/500], Average Validation Loss: 0.4032, Average Validation Accuracy: 0.8257\n",
      "Epoch [232/500], Average Training Loss: 0.3978\n",
      "Epoch [232/500], Average Validation Loss: 0.4030, Average Validation Accuracy: 0.8251\n",
      "Epoch [233/500], Average Training Loss: 0.3978\n",
      "Epoch [233/500], Average Validation Loss: 0.4032, Average Validation Accuracy: 0.8254\n",
      "Epoch [234/500], Average Training Loss: 0.3976\n",
      "Epoch [234/500], Average Validation Loss: 0.4036, Average Validation Accuracy: 0.8257\n",
      "Epoch [235/500], Average Training Loss: 0.3977\n",
      "Epoch [235/500], Average Validation Loss: 0.4036, Average Validation Accuracy: 0.8259\n",
      "Epoch [236/500], Average Training Loss: 0.3976\n",
      "Epoch [236/500], Average Validation Loss: 0.4033, Average Validation Accuracy: 0.8263\n",
      "Epoch [237/500], Average Training Loss: 0.3977\n",
      "Epoch [237/500], Average Validation Loss: 0.4038, Average Validation Accuracy: 0.8238\n",
      "Epoch [238/500], Average Training Loss: 0.3975\n",
      "Epoch [238/500], Average Validation Loss: 0.4031, Average Validation Accuracy: 0.8246\n",
      "Epoch [239/500], Average Training Loss: 0.3974\n",
      "Epoch [239/500], Average Validation Loss: 0.4031, Average Validation Accuracy: 0.8251\n",
      "Epoch [240/500], Average Training Loss: 0.3973\n",
      "Epoch [240/500], Average Validation Loss: 0.4030, Average Validation Accuracy: 0.8256\n",
      "Epoch [241/500], Average Training Loss: 0.3973\n",
      "Epoch [241/500], Average Validation Loss: 0.4028, Average Validation Accuracy: 0.8256\n",
      "Epoch [242/500], Average Training Loss: 0.3974\n",
      "Epoch [242/500], Average Validation Loss: 0.4032, Average Validation Accuracy: 0.8245\n",
      "Epoch [243/500], Average Training Loss: 0.3972\n",
      "Epoch [243/500], Average Validation Loss: 0.4031, Average Validation Accuracy: 0.8254\n",
      "Epoch [244/500], Average Training Loss: 0.3971\n",
      "Epoch [244/500], Average Validation Loss: 0.4027, Average Validation Accuracy: 0.8256\n",
      "Epoch [245/500], Average Training Loss: 0.3972\n",
      "Epoch [245/500], Average Validation Loss: 0.4029, Average Validation Accuracy: 0.8256\n",
      "Epoch [246/500], Average Training Loss: 0.3971\n",
      "Epoch [246/500], Average Validation Loss: 0.4034, Average Validation Accuracy: 0.8244\n",
      "Epoch [247/500], Average Training Loss: 0.3972\n",
      "Epoch [247/500], Average Validation Loss: 0.4031, Average Validation Accuracy: 0.8259\n",
      "Epoch [248/500], Average Training Loss: 0.3970\n",
      "Epoch [248/500], Average Validation Loss: 0.4029, Average Validation Accuracy: 0.8265\n",
      "Epoch [249/500], Average Training Loss: 0.3969\n",
      "Epoch [249/500], Average Validation Loss: 0.4028, Average Validation Accuracy: 0.8253\n",
      "Epoch [250/500], Average Training Loss: 0.3969\n",
      "Epoch [250/500], Average Validation Loss: 0.4027, Average Validation Accuracy: 0.8255\n",
      "Epoch [251/500], Average Training Loss: 0.3969\n",
      "Epoch [251/500], Average Validation Loss: 0.4031, Average Validation Accuracy: 0.8257\n",
      "Epoch [252/500], Average Training Loss: 0.3967\n",
      "Epoch [252/500], Average Validation Loss: 0.4032, Average Validation Accuracy: 0.8250\n",
      "Epoch [253/500], Average Training Loss: 0.3967\n",
      "Epoch [253/500], Average Validation Loss: 0.4029, Average Validation Accuracy: 0.8268\n",
      "Epoch [254/500], Average Training Loss: 0.3967\n",
      "Epoch [254/500], Average Validation Loss: 0.4030, Average Validation Accuracy: 0.8246\n",
      "Epoch [255/500], Average Training Loss: 0.3967\n",
      "Epoch [255/500], Average Validation Loss: 0.4028, Average Validation Accuracy: 0.8253\n",
      "Epoch [256/500], Average Training Loss: 0.3966\n",
      "Epoch [256/500], Average Validation Loss: 0.4034, Average Validation Accuracy: 0.8244\n",
      "Epoch [257/500], Average Training Loss: 0.3966\n",
      "Epoch [257/500], Average Validation Loss: 0.4027, Average Validation Accuracy: 0.8250\n",
      "Epoch [258/500], Average Training Loss: 0.3965\n",
      "Epoch [258/500], Average Validation Loss: 0.4032, Average Validation Accuracy: 0.8248\n",
      "Epoch [259/500], Average Training Loss: 0.3964\n",
      "Epoch [259/500], Average Validation Loss: 0.4026, Average Validation Accuracy: 0.8253\n",
      "Epoch [260/500], Average Training Loss: 0.3965\n",
      "Epoch [260/500], Average Validation Loss: 0.4025, Average Validation Accuracy: 0.8260\n",
      "Epoch [261/500], Average Training Loss: 0.3963\n",
      "Epoch [261/500], Average Validation Loss: 0.4030, Average Validation Accuracy: 0.8259\n",
      "Epoch [262/500], Average Training Loss: 0.3964\n",
      "Epoch [262/500], Average Validation Loss: 0.4027, Average Validation Accuracy: 0.8241\n",
      "Epoch [263/500], Average Training Loss: 0.3962\n",
      "Epoch [263/500], Average Validation Loss: 0.4026, Average Validation Accuracy: 0.8262\n",
      "Epoch [264/500], Average Training Loss: 0.3962\n",
      "Epoch [264/500], Average Validation Loss: 0.4034, Average Validation Accuracy: 0.8246\n",
      "Epoch [265/500], Average Training Loss: 0.3963\n",
      "Epoch [265/500], Average Validation Loss: 0.4025, Average Validation Accuracy: 0.8258\n",
      "Epoch [266/500], Average Training Loss: 0.3962\n",
      "Epoch [266/500], Average Validation Loss: 0.4028, Average Validation Accuracy: 0.8256\n",
      "Epoch [267/500], Average Training Loss: 0.3964\n",
      "Epoch [267/500], Average Validation Loss: 0.4027, Average Validation Accuracy: 0.8246\n",
      "Epoch [268/500], Average Training Loss: 0.3960\n",
      "Epoch [268/500], Average Validation Loss: 0.4026, Average Validation Accuracy: 0.8258\n",
      "Epoch [269/500], Average Training Loss: 0.3959\n",
      "Epoch [269/500], Average Validation Loss: 0.4030, Average Validation Accuracy: 0.8256\n",
      "Epoch [270/500], Average Training Loss: 0.3960\n",
      "Epoch [270/500], Average Validation Loss: 0.4030, Average Validation Accuracy: 0.8246\n",
      "Epoch [271/500], Average Training Loss: 0.3958\n",
      "Early stopping at epoch 270. Best loss was 0.4025\n",
      "Best Validation Accuracy: 0.8268 at epoch 253 for trial 15\n",
      "Epoch [1/50], Average Training Loss: 0.4491\n",
      "Epoch [1/50], Average Validation Loss: 0.4734, Average Validation Accuracy: 0.7804\n",
      "Epoch [2/50], Average Training Loss: 0.4312\n",
      "Epoch [2/50], Average Validation Loss: 0.4342, Average Validation Accuracy: 0.8088\n",
      "Epoch [3/50], Average Training Loss: 0.4268\n",
      "Epoch [3/50], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8068\n",
      "Epoch [4/50], Average Training Loss: 0.4239\n",
      "Epoch [4/50], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8119\n",
      "Epoch [5/50], Average Training Loss: 0.4228\n",
      "Epoch [5/50], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8082\n",
      "Epoch [6/50], Average Training Loss: 0.4199\n",
      "Epoch [6/50], Average Validation Loss: 0.4209, Average Validation Accuracy: 0.8161\n",
      "Epoch [7/50], Average Training Loss: 0.4175\n",
      "Epoch [7/50], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8125\n",
      "Epoch [8/50], Average Training Loss: 0.4150\n",
      "Epoch [8/50], Average Validation Loss: 0.4192, Average Validation Accuracy: 0.8172\n",
      "Epoch [9/50], Average Training Loss: 0.4144\n",
      "Epoch [9/50], Average Validation Loss: 0.4192, Average Validation Accuracy: 0.8187\n",
      "Epoch [10/50], Average Training Loss: 0.4130\n",
      "Epoch [10/50], Average Validation Loss: 0.4209, Average Validation Accuracy: 0.8179\n",
      "Epoch [11/50], Average Training Loss: 0.4121\n",
      "Epoch [11/50], Average Validation Loss: 0.4149, Average Validation Accuracy: 0.8192\n",
      "Epoch [12/50], Average Training Loss: 0.4108\n",
      "Epoch [12/50], Average Validation Loss: 0.4136, Average Validation Accuracy: 0.8183\n",
      "Epoch [13/50], Average Training Loss: 0.4100\n",
      "Epoch [13/50], Average Validation Loss: 0.4268, Average Validation Accuracy: 0.8108\n",
      "Epoch [14/50], Average Training Loss: 0.4094\n",
      "Epoch [14/50], Average Validation Loss: 0.4178, Average Validation Accuracy: 0.8189\n",
      "Epoch [15/50], Average Training Loss: 0.4091\n",
      "Epoch [15/50], Average Validation Loss: 0.4119, Average Validation Accuracy: 0.8203\n",
      "Epoch [16/50], Average Training Loss: 0.4084\n",
      "Epoch [16/50], Average Validation Loss: 0.4135, Average Validation Accuracy: 0.8188\n",
      "Epoch [17/50], Average Training Loss: 0.4079\n",
      "Epoch [17/50], Average Validation Loss: 0.4109, Average Validation Accuracy: 0.8227\n",
      "Epoch [18/50], Average Training Loss: 0.4070\n",
      "Epoch [18/50], Average Validation Loss: 0.4114, Average Validation Accuracy: 0.8212\n",
      "Epoch [19/50], Average Training Loss: 0.4071\n",
      "Epoch [19/50], Average Validation Loss: 0.4107, Average Validation Accuracy: 0.8223\n",
      "Epoch [20/50], Average Training Loss: 0.4072\n",
      "Epoch [20/50], Average Validation Loss: 0.4119, Average Validation Accuracy: 0.8229\n",
      "Epoch [21/50], Average Training Loss: 0.4066\n",
      "Epoch [21/50], Average Validation Loss: 0.4123, Average Validation Accuracy: 0.8218\n",
      "Epoch [22/50], Average Training Loss: 0.4059\n",
      "Epoch [22/50], Average Validation Loss: 0.4163, Average Validation Accuracy: 0.8196\n",
      "Epoch [23/50], Average Training Loss: 0.4054\n",
      "Epoch [23/50], Average Validation Loss: 0.4152, Average Validation Accuracy: 0.8214\n",
      "Epoch [24/50], Average Training Loss: 0.4056\n",
      "Epoch [24/50], Average Validation Loss: 0.4079, Average Validation Accuracy: 0.8224\n",
      "Epoch [25/50], Average Training Loss: 0.4046\n",
      "Epoch [25/50], Average Validation Loss: 0.4084, Average Validation Accuracy: 0.8227\n",
      "Epoch [26/50], Average Training Loss: 0.4044\n",
      "Epoch [26/50], Average Validation Loss: 0.4074, Average Validation Accuracy: 0.8237\n",
      "Epoch [27/50], Average Training Loss: 0.4038\n",
      "Epoch [27/50], Average Validation Loss: 0.4081, Average Validation Accuracy: 0.8237\n",
      "Epoch [28/50], Average Training Loss: 0.4034\n",
      "Epoch [28/50], Average Validation Loss: 0.4090, Average Validation Accuracy: 0.8228\n",
      "Epoch [29/50], Average Training Loss: 0.4030\n",
      "Epoch [29/50], Average Validation Loss: 0.4074, Average Validation Accuracy: 0.8244\n",
      "Epoch [30/50], Average Training Loss: 0.4027\n",
      "Epoch [30/50], Average Validation Loss: 0.4064, Average Validation Accuracy: 0.8233\n",
      "Epoch [31/50], Average Training Loss: 0.4024\n",
      "Epoch [31/50], Average Validation Loss: 0.4137, Average Validation Accuracy: 0.8185\n",
      "Epoch [32/50], Average Training Loss: 0.4021\n",
      "Epoch [32/50], Average Validation Loss: 0.4088, Average Validation Accuracy: 0.8209\n",
      "Epoch [33/50], Average Training Loss: 0.4012\n",
      "Epoch [33/50], Average Validation Loss: 0.4118, Average Validation Accuracy: 0.8216\n",
      "Epoch [34/50], Average Training Loss: 0.4013\n",
      "Epoch [34/50], Average Validation Loss: 0.4106, Average Validation Accuracy: 0.8207\n",
      "Epoch [35/50], Average Training Loss: 0.4010\n",
      "Epoch [35/50], Average Validation Loss: 0.4085, Average Validation Accuracy: 0.8218\n",
      "Epoch [36/50], Average Training Loss: 0.4005\n",
      "Epoch [36/50], Average Validation Loss: 0.4072, Average Validation Accuracy: 0.8237\n",
      "Epoch [37/50], Average Training Loss: 0.4008\n",
      "Epoch [37/50], Average Validation Loss: 0.4072, Average Validation Accuracy: 0.8240\n",
      "Epoch [38/50], Average Training Loss: 0.4001\n",
      "Epoch [38/50], Average Validation Loss: 0.4077, Average Validation Accuracy: 0.8210\n",
      "Epoch [39/50], Average Training Loss: 0.3997\n",
      "Epoch [39/50], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8234\n",
      "Epoch [40/50], Average Training Loss: 0.3992\n",
      "Epoch [40/50], Average Validation Loss: 0.4055, Average Validation Accuracy: 0.8252\n",
      "Epoch [41/50], Average Training Loss: 0.3988\n",
      "Epoch [41/50], Average Validation Loss: 0.4047, Average Validation Accuracy: 0.8246\n",
      "Epoch [42/50], Average Training Loss: 0.3993\n",
      "Epoch [42/50], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8247\n",
      "Epoch [43/50], Average Training Loss: 0.3986\n",
      "Epoch [43/50], Average Validation Loss: 0.4065, Average Validation Accuracy: 0.8241\n",
      "Epoch [44/50], Average Training Loss: 0.3979\n",
      "Epoch [44/50], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8236\n",
      "Epoch [45/50], Average Training Loss: 0.3981\n",
      "Epoch [45/50], Average Validation Loss: 0.4069, Average Validation Accuracy: 0.8233\n",
      "Epoch [46/50], Average Training Loss: 0.3971\n",
      "Epoch [46/50], Average Validation Loss: 0.4076, Average Validation Accuracy: 0.8243\n",
      "Epoch [47/50], Average Training Loss: 0.3972\n",
      "Epoch [47/50], Average Validation Loss: 0.4060, Average Validation Accuracy: 0.8239\n",
      "Epoch [48/50], Average Training Loss: 0.3965\n",
      "Epoch [48/50], Average Validation Loss: 0.4177, Average Validation Accuracy: 0.8148\n",
      "Epoch [49/50], Average Training Loss: 0.3968\n",
      "Epoch [49/50], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8250\n",
      "Epoch [50/50], Average Training Loss: 0.3967\n",
      "Epoch [50/50], Average Validation Loss: 0.4157, Average Validation Accuracy: 0.8166\n",
      "Best Validation Accuracy: 0.8252 at epoch 40 for trial 16\n",
      "Epoch [1/500], Average Training Loss: 0.4901\n",
      "Epoch [1/500], Average Validation Loss: 0.4479, Average Validation Accuracy: 0.7996\n",
      "Epoch [2/500], Average Training Loss: 0.4407\n",
      "Epoch [2/500], Average Validation Loss: 0.4414, Average Validation Accuracy: 0.8033\n",
      "Epoch [3/500], Average Training Loss: 0.4356\n",
      "Epoch [3/500], Average Validation Loss: 0.4373, Average Validation Accuracy: 0.8052\n",
      "Epoch [4/500], Average Training Loss: 0.4327\n",
      "Epoch [4/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8075\n",
      "Epoch [5/500], Average Training Loss: 0.4310\n",
      "Epoch [5/500], Average Validation Loss: 0.4331, Average Validation Accuracy: 0.8098\n",
      "Epoch [6/500], Average Training Loss: 0.4300\n",
      "Epoch [6/500], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8106\n",
      "Epoch [7/500], Average Training Loss: 0.4291\n",
      "Epoch [7/500], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8114\n",
      "Epoch [8/500], Average Training Loss: 0.4287\n",
      "Epoch [8/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8103\n",
      "Epoch [9/500], Average Training Loss: 0.4281\n",
      "Epoch [9/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8121\n",
      "Epoch [10/500], Average Training Loss: 0.4277\n",
      "Epoch [10/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8116\n",
      "Epoch [11/500], Average Training Loss: 0.4275\n",
      "Epoch [11/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8123\n",
      "Epoch [12/500], Average Training Loss: 0.4269\n",
      "Epoch [12/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8116\n",
      "Epoch [13/500], Average Training Loss: 0.4267\n",
      "Epoch [13/500], Average Validation Loss: 0.4289, Average Validation Accuracy: 0.8123\n",
      "Epoch [14/500], Average Training Loss: 0.4260\n",
      "Epoch [14/500], Average Validation Loss: 0.4289, Average Validation Accuracy: 0.8121\n",
      "Epoch [15/500], Average Training Loss: 0.4257\n",
      "Epoch [15/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8128\n",
      "Epoch [16/500], Average Training Loss: 0.4254\n",
      "Epoch [16/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8136\n",
      "Epoch [17/500], Average Training Loss: 0.4247\n",
      "Epoch [17/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8134\n",
      "Epoch [18/500], Average Training Loss: 0.4244\n",
      "Epoch [18/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8129\n",
      "Epoch [19/500], Average Training Loss: 0.4239\n",
      "Epoch [19/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8130\n",
      "Epoch [20/500], Average Training Loss: 0.4233\n",
      "Epoch [20/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8128\n",
      "Epoch [21/500], Average Training Loss: 0.4228\n",
      "Epoch [21/500], Average Validation Loss: 0.4289, Average Validation Accuracy: 0.8105\n",
      "Epoch [22/500], Average Training Loss: 0.4224\n",
      "Epoch [22/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8123\n",
      "Epoch [23/500], Average Training Loss: 0.4219\n",
      "Epoch [23/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8134\n",
      "Epoch [24/500], Average Training Loss: 0.4213\n",
      "Epoch [24/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8133\n",
      "Epoch [25/500], Average Training Loss: 0.4210\n",
      "Epoch [25/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8122\n",
      "Epoch [26/500], Average Training Loss: 0.4205\n",
      "Epoch [26/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8135\n",
      "Epoch [27/500], Average Training Loss: 0.4204\n",
      "Epoch [27/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8135\n",
      "Epoch [28/500], Average Training Loss: 0.4200\n",
      "Epoch [28/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8141\n",
      "Epoch [29/500], Average Training Loss: 0.4197\n",
      "Epoch [29/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8145\n",
      "Epoch [30/500], Average Training Loss: 0.4195\n",
      "Epoch [30/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8129\n",
      "Epoch [31/500], Average Training Loss: 0.4192\n",
      "Epoch [31/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8129\n",
      "Epoch [32/500], Average Training Loss: 0.4189\n",
      "Epoch [32/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8127\n",
      "Epoch [33/500], Average Training Loss: 0.4186\n",
      "Epoch [33/500], Average Validation Loss: 0.4221, Average Validation Accuracy: 0.8143\n",
      "Epoch [34/500], Average Training Loss: 0.4182\n",
      "Epoch [34/500], Average Validation Loss: 0.4226, Average Validation Accuracy: 0.8140\n",
      "Epoch [35/500], Average Training Loss: 0.4180\n",
      "Epoch [35/500], Average Validation Loss: 0.4222, Average Validation Accuracy: 0.8144\n",
      "Epoch [36/500], Average Training Loss: 0.4176\n",
      "Epoch [36/500], Average Validation Loss: 0.4210, Average Validation Accuracy: 0.8153\n",
      "Epoch [37/500], Average Training Loss: 0.4173\n",
      "Epoch [37/500], Average Validation Loss: 0.4214, Average Validation Accuracy: 0.8146\n",
      "Epoch [38/500], Average Training Loss: 0.4169\n",
      "Epoch [38/500], Average Validation Loss: 0.4208, Average Validation Accuracy: 0.8149\n",
      "Epoch [39/500], Average Training Loss: 0.4167\n",
      "Epoch [39/500], Average Validation Loss: 0.4200, Average Validation Accuracy: 0.8154\n",
      "Epoch [40/500], Average Training Loss: 0.4163\n",
      "Epoch [40/500], Average Validation Loss: 0.4214, Average Validation Accuracy: 0.8156\n",
      "Epoch [41/500], Average Training Loss: 0.4158\n",
      "Epoch [41/500], Average Validation Loss: 0.4196, Average Validation Accuracy: 0.8160\n",
      "Epoch [42/500], Average Training Loss: 0.4157\n",
      "Epoch [42/500], Average Validation Loss: 0.4189, Average Validation Accuracy: 0.8163\n",
      "Epoch [43/500], Average Training Loss: 0.4153\n",
      "Epoch [43/500], Average Validation Loss: 0.4187, Average Validation Accuracy: 0.8163\n",
      "Epoch [44/500], Average Training Loss: 0.4150\n",
      "Epoch [44/500], Average Validation Loss: 0.4196, Average Validation Accuracy: 0.8158\n",
      "Epoch [45/500], Average Training Loss: 0.4148\n",
      "Epoch [45/500], Average Validation Loss: 0.4180, Average Validation Accuracy: 0.8176\n",
      "Epoch [46/500], Average Training Loss: 0.4144\n",
      "Epoch [46/500], Average Validation Loss: 0.4190, Average Validation Accuracy: 0.8167\n",
      "Epoch [47/500], Average Training Loss: 0.4142\n",
      "Epoch [47/500], Average Validation Loss: 0.4178, Average Validation Accuracy: 0.8181\n",
      "Epoch [48/500], Average Training Loss: 0.4138\n",
      "Epoch [48/500], Average Validation Loss: 0.4178, Average Validation Accuracy: 0.8174\n",
      "Epoch [49/500], Average Training Loss: 0.4135\n",
      "Epoch [49/500], Average Validation Loss: 0.4174, Average Validation Accuracy: 0.8181\n",
      "Epoch [50/500], Average Training Loss: 0.4134\n",
      "Epoch [50/500], Average Validation Loss: 0.4168, Average Validation Accuracy: 0.8173\n",
      "Epoch [51/500], Average Training Loss: 0.4130\n",
      "Epoch [51/500], Average Validation Loss: 0.4167, Average Validation Accuracy: 0.8183\n",
      "Epoch [52/500], Average Training Loss: 0.4129\n",
      "Epoch [52/500], Average Validation Loss: 0.4172, Average Validation Accuracy: 0.8177\n",
      "Epoch [53/500], Average Training Loss: 0.4126\n",
      "Epoch [53/500], Average Validation Loss: 0.4161, Average Validation Accuracy: 0.8179\n",
      "Epoch [54/500], Average Training Loss: 0.4124\n",
      "Epoch [54/500], Average Validation Loss: 0.4166, Average Validation Accuracy: 0.8173\n",
      "Epoch [55/500], Average Training Loss: 0.4125\n",
      "Epoch [55/500], Average Validation Loss: 0.4161, Average Validation Accuracy: 0.8180\n",
      "Epoch [56/500], Average Training Loss: 0.4121\n",
      "Epoch [56/500], Average Validation Loss: 0.4162, Average Validation Accuracy: 0.8174\n",
      "Epoch [57/500], Average Training Loss: 0.4119\n",
      "Epoch [57/500], Average Validation Loss: 0.4162, Average Validation Accuracy: 0.8183\n",
      "Epoch [58/500], Average Training Loss: 0.4119\n",
      "Epoch [58/500], Average Validation Loss: 0.4158, Average Validation Accuracy: 0.8175\n",
      "Epoch [59/500], Average Training Loss: 0.4116\n",
      "Epoch [59/500], Average Validation Loss: 0.4165, Average Validation Accuracy: 0.8179\n",
      "Epoch [60/500], Average Training Loss: 0.4117\n",
      "Epoch [60/500], Average Validation Loss: 0.4154, Average Validation Accuracy: 0.8194\n",
      "Epoch [61/500], Average Training Loss: 0.4115\n",
      "Epoch [61/500], Average Validation Loss: 0.4162, Average Validation Accuracy: 0.8177\n",
      "Epoch [62/500], Average Training Loss: 0.4114\n",
      "Epoch [62/500], Average Validation Loss: 0.4157, Average Validation Accuracy: 0.8182\n",
      "Epoch [63/500], Average Training Loss: 0.4112\n",
      "Epoch [63/500], Average Validation Loss: 0.4162, Average Validation Accuracy: 0.8181\n",
      "Epoch [64/500], Average Training Loss: 0.4111\n",
      "Epoch [64/500], Average Validation Loss: 0.4159, Average Validation Accuracy: 0.8167\n",
      "Epoch [65/500], Average Training Loss: 0.4112\n",
      "Epoch [65/500], Average Validation Loss: 0.4150, Average Validation Accuracy: 0.8185\n",
      "Epoch [66/500], Average Training Loss: 0.4108\n",
      "Epoch [66/500], Average Validation Loss: 0.4146, Average Validation Accuracy: 0.8184\n",
      "Epoch [67/500], Average Training Loss: 0.4108\n",
      "Epoch [67/500], Average Validation Loss: 0.4144, Average Validation Accuracy: 0.8200\n",
      "Epoch [68/500], Average Training Loss: 0.4105\n",
      "Epoch [68/500], Average Validation Loss: 0.4144, Average Validation Accuracy: 0.8194\n",
      "Epoch [69/500], Average Training Loss: 0.4103\n",
      "Epoch [69/500], Average Validation Loss: 0.4147, Average Validation Accuracy: 0.8184\n",
      "Epoch [70/500], Average Training Loss: 0.4103\n",
      "Epoch [70/500], Average Validation Loss: 0.4141, Average Validation Accuracy: 0.8189\n",
      "Epoch [71/500], Average Training Loss: 0.4102\n",
      "Epoch [71/500], Average Validation Loss: 0.4139, Average Validation Accuracy: 0.8194\n",
      "Epoch [72/500], Average Training Loss: 0.4101\n",
      "Epoch [72/500], Average Validation Loss: 0.4150, Average Validation Accuracy: 0.8178\n",
      "Epoch [73/500], Average Training Loss: 0.4099\n",
      "Epoch [73/500], Average Validation Loss: 0.4141, Average Validation Accuracy: 0.8202\n",
      "Epoch [74/500], Average Training Loss: 0.4098\n",
      "Epoch [74/500], Average Validation Loss: 0.4138, Average Validation Accuracy: 0.8197\n",
      "Epoch [75/500], Average Training Loss: 0.4096\n",
      "Epoch [75/500], Average Validation Loss: 0.4140, Average Validation Accuracy: 0.8185\n",
      "Epoch [76/500], Average Training Loss: 0.4096\n",
      "Epoch [76/500], Average Validation Loss: 0.4136, Average Validation Accuracy: 0.8189\n",
      "Epoch [77/500], Average Training Loss: 0.4096\n",
      "Epoch [77/500], Average Validation Loss: 0.4147, Average Validation Accuracy: 0.8181\n",
      "Epoch [78/500], Average Training Loss: 0.4094\n",
      "Epoch [78/500], Average Validation Loss: 0.4133, Average Validation Accuracy: 0.8193\n",
      "Epoch [79/500], Average Training Loss: 0.4094\n",
      "Epoch [79/500], Average Validation Loss: 0.4142, Average Validation Accuracy: 0.8196\n",
      "Epoch [80/500], Average Training Loss: 0.4091\n",
      "Epoch [80/500], Average Validation Loss: 0.4144, Average Validation Accuracy: 0.8199\n",
      "Epoch [81/500], Average Training Loss: 0.4090\n",
      "Epoch [81/500], Average Validation Loss: 0.4135, Average Validation Accuracy: 0.8192\n",
      "Epoch [82/500], Average Training Loss: 0.4090\n",
      "Epoch [82/500], Average Validation Loss: 0.4134, Average Validation Accuracy: 0.8192\n",
      "Epoch [83/500], Average Training Loss: 0.4089\n",
      "Epoch [83/500], Average Validation Loss: 0.4132, Average Validation Accuracy: 0.8187\n",
      "Epoch [84/500], Average Training Loss: 0.4088\n",
      "Epoch [84/500], Average Validation Loss: 0.4131, Average Validation Accuracy: 0.8200\n",
      "Epoch [85/500], Average Training Loss: 0.4086\n",
      "Epoch [85/500], Average Validation Loss: 0.4131, Average Validation Accuracy: 0.8207\n",
      "Epoch [86/500], Average Training Loss: 0.4086\n",
      "Epoch [86/500], Average Validation Loss: 0.4131, Average Validation Accuracy: 0.8185\n",
      "Epoch [87/500], Average Training Loss: 0.4084\n",
      "Epoch [87/500], Average Validation Loss: 0.4145, Average Validation Accuracy: 0.8185\n",
      "Epoch [88/500], Average Training Loss: 0.4082\n",
      "Epoch [88/500], Average Validation Loss: 0.4130, Average Validation Accuracy: 0.8203\n",
      "Epoch [89/500], Average Training Loss: 0.4083\n",
      "Epoch [89/500], Average Validation Loss: 0.4129, Average Validation Accuracy: 0.8197\n",
      "Epoch [90/500], Average Training Loss: 0.4083\n",
      "Epoch [90/500], Average Validation Loss: 0.4124, Average Validation Accuracy: 0.8206\n",
      "Epoch [91/500], Average Training Loss: 0.4080\n",
      "Epoch [91/500], Average Validation Loss: 0.4127, Average Validation Accuracy: 0.8196\n",
      "Epoch [92/500], Average Training Loss: 0.4080\n",
      "Epoch [92/500], Average Validation Loss: 0.4121, Average Validation Accuracy: 0.8205\n",
      "Epoch [93/500], Average Training Loss: 0.4078\n",
      "Epoch [93/500], Average Validation Loss: 0.4127, Average Validation Accuracy: 0.8195\n",
      "Epoch [94/500], Average Training Loss: 0.4079\n",
      "Epoch [94/500], Average Validation Loss: 0.4119, Average Validation Accuracy: 0.8201\n",
      "Epoch [95/500], Average Training Loss: 0.4077\n",
      "Epoch [95/500], Average Validation Loss: 0.4122, Average Validation Accuracy: 0.8212\n",
      "Epoch [96/500], Average Training Loss: 0.4076\n",
      "Epoch [96/500], Average Validation Loss: 0.4121, Average Validation Accuracy: 0.8207\n",
      "Epoch [97/500], Average Training Loss: 0.4075\n",
      "Epoch [97/500], Average Validation Loss: 0.4128, Average Validation Accuracy: 0.8200\n",
      "Epoch [98/500], Average Training Loss: 0.4075\n",
      "Epoch [98/500], Average Validation Loss: 0.4119, Average Validation Accuracy: 0.8216\n",
      "Epoch [99/500], Average Training Loss: 0.4075\n",
      "Epoch [99/500], Average Validation Loss: 0.4117, Average Validation Accuracy: 0.8206\n",
      "Epoch [100/500], Average Training Loss: 0.4074\n",
      "Epoch [100/500], Average Validation Loss: 0.4122, Average Validation Accuracy: 0.8207\n",
      "Epoch [101/500], Average Training Loss: 0.4072\n",
      "Epoch [101/500], Average Validation Loss: 0.4117, Average Validation Accuracy: 0.8214\n",
      "Epoch [102/500], Average Training Loss: 0.4071\n",
      "Epoch [102/500], Average Validation Loss: 0.4114, Average Validation Accuracy: 0.8205\n",
      "Epoch [103/500], Average Training Loss: 0.4071\n",
      "Epoch [103/500], Average Validation Loss: 0.4122, Average Validation Accuracy: 0.8214\n",
      "Epoch [104/500], Average Training Loss: 0.4071\n",
      "Epoch [104/500], Average Validation Loss: 0.4113, Average Validation Accuracy: 0.8220\n",
      "Epoch [105/500], Average Training Loss: 0.4069\n",
      "Epoch [105/500], Average Validation Loss: 0.4117, Average Validation Accuracy: 0.8209\n",
      "Epoch [106/500], Average Training Loss: 0.4068\n",
      "Epoch [106/500], Average Validation Loss: 0.4109, Average Validation Accuracy: 0.8215\n",
      "Epoch [107/500], Average Training Loss: 0.4067\n",
      "Epoch [107/500], Average Validation Loss: 0.4107, Average Validation Accuracy: 0.8224\n",
      "Epoch [108/500], Average Training Loss: 0.4065\n",
      "Epoch [108/500], Average Validation Loss: 0.4116, Average Validation Accuracy: 0.8206\n",
      "Epoch [109/500], Average Training Loss: 0.4066\n",
      "Epoch [109/500], Average Validation Loss: 0.4111, Average Validation Accuracy: 0.8222\n",
      "Epoch [110/500], Average Training Loss: 0.4064\n",
      "Epoch [110/500], Average Validation Loss: 0.4108, Average Validation Accuracy: 0.8216\n",
      "Epoch [111/500], Average Training Loss: 0.4064\n",
      "Epoch [111/500], Average Validation Loss: 0.4115, Average Validation Accuracy: 0.8208\n",
      "Epoch [112/500], Average Training Loss: 0.4063\n",
      "Epoch [112/500], Average Validation Loss: 0.4107, Average Validation Accuracy: 0.8217\n",
      "Epoch [113/500], Average Training Loss: 0.4061\n",
      "Epoch [113/500], Average Validation Loss: 0.4109, Average Validation Accuracy: 0.8206\n",
      "Epoch [114/500], Average Training Loss: 0.4062\n",
      "Epoch [114/500], Average Validation Loss: 0.4109, Average Validation Accuracy: 0.8209\n",
      "Epoch [115/500], Average Training Loss: 0.4061\n",
      "Epoch [115/500], Average Validation Loss: 0.4105, Average Validation Accuracy: 0.8224\n",
      "Epoch [116/500], Average Training Loss: 0.4059\n",
      "Epoch [116/500], Average Validation Loss: 0.4102, Average Validation Accuracy: 0.8225\n",
      "Epoch [117/500], Average Training Loss: 0.4058\n",
      "Epoch [117/500], Average Validation Loss: 0.4101, Average Validation Accuracy: 0.8217\n",
      "Epoch [118/500], Average Training Loss: 0.4059\n",
      "Epoch [118/500], Average Validation Loss: 0.4103, Average Validation Accuracy: 0.8222\n",
      "Epoch [119/500], Average Training Loss: 0.4057\n",
      "Epoch [119/500], Average Validation Loss: 0.4100, Average Validation Accuracy: 0.8225\n",
      "Epoch [120/500], Average Training Loss: 0.4057\n",
      "Epoch [120/500], Average Validation Loss: 0.4100, Average Validation Accuracy: 0.8224\n",
      "Epoch [121/500], Average Training Loss: 0.4055\n",
      "Epoch [121/500], Average Validation Loss: 0.4102, Average Validation Accuracy: 0.8232\n",
      "Epoch [122/500], Average Training Loss: 0.4055\n",
      "Epoch [122/500], Average Validation Loss: 0.4097, Average Validation Accuracy: 0.8227\n",
      "Epoch [123/500], Average Training Loss: 0.4054\n",
      "Epoch [123/500], Average Validation Loss: 0.4094, Average Validation Accuracy: 0.8228\n",
      "Epoch [124/500], Average Training Loss: 0.4054\n",
      "Epoch [124/500], Average Validation Loss: 0.4099, Average Validation Accuracy: 0.8222\n",
      "Epoch [125/500], Average Training Loss: 0.4052\n",
      "Epoch [125/500], Average Validation Loss: 0.4094, Average Validation Accuracy: 0.8221\n",
      "Epoch [126/500], Average Training Loss: 0.4052\n",
      "Epoch [126/500], Average Validation Loss: 0.4092, Average Validation Accuracy: 0.8226\n",
      "Epoch [127/500], Average Training Loss: 0.4051\n",
      "Epoch [127/500], Average Validation Loss: 0.4091, Average Validation Accuracy: 0.8227\n",
      "Epoch [128/500], Average Training Loss: 0.4049\n",
      "Epoch [128/500], Average Validation Loss: 0.4091, Average Validation Accuracy: 0.8234\n",
      "Epoch [129/500], Average Training Loss: 0.4050\n",
      "Epoch [129/500], Average Validation Loss: 0.4100, Average Validation Accuracy: 0.8221\n",
      "Epoch [130/500], Average Training Loss: 0.4049\n",
      "Epoch [130/500], Average Validation Loss: 0.4094, Average Validation Accuracy: 0.8226\n",
      "Epoch [131/500], Average Training Loss: 0.4049\n",
      "Epoch [131/500], Average Validation Loss: 0.4089, Average Validation Accuracy: 0.8232\n",
      "Epoch [132/500], Average Training Loss: 0.4048\n",
      "Epoch [132/500], Average Validation Loss: 0.4089, Average Validation Accuracy: 0.8230\n",
      "Epoch [133/500], Average Training Loss: 0.4047\n",
      "Epoch [133/500], Average Validation Loss: 0.4102, Average Validation Accuracy: 0.8221\n",
      "Epoch [134/500], Average Training Loss: 0.4046\n",
      "Epoch [134/500], Average Validation Loss: 0.4095, Average Validation Accuracy: 0.8226\n",
      "Epoch [135/500], Average Training Loss: 0.4046\n",
      "Epoch [135/500], Average Validation Loss: 0.4088, Average Validation Accuracy: 0.8224\n",
      "Epoch [136/500], Average Training Loss: 0.4044\n",
      "Epoch [136/500], Average Validation Loss: 0.4085, Average Validation Accuracy: 0.8230\n",
      "Epoch [137/500], Average Training Loss: 0.4043\n",
      "Epoch [137/500], Average Validation Loss: 0.4083, Average Validation Accuracy: 0.8235\n",
      "Epoch [138/500], Average Training Loss: 0.4042\n",
      "Epoch [138/500], Average Validation Loss: 0.4084, Average Validation Accuracy: 0.8232\n",
      "Epoch [139/500], Average Training Loss: 0.4043\n",
      "Epoch [139/500], Average Validation Loss: 0.4083, Average Validation Accuracy: 0.8227\n",
      "Epoch [140/500], Average Training Loss: 0.4042\n",
      "Epoch [140/500], Average Validation Loss: 0.4093, Average Validation Accuracy: 0.8222\n",
      "Epoch [141/500], Average Training Loss: 0.4041\n",
      "Epoch [141/500], Average Validation Loss: 0.4091, Average Validation Accuracy: 0.8230\n",
      "Epoch [142/500], Average Training Loss: 0.4039\n",
      "Epoch [142/500], Average Validation Loss: 0.4085, Average Validation Accuracy: 0.8234\n",
      "Epoch [143/500], Average Training Loss: 0.4039\n",
      "Epoch [143/500], Average Validation Loss: 0.4087, Average Validation Accuracy: 0.8229\n",
      "Epoch [144/500], Average Training Loss: 0.4039\n",
      "Epoch [144/500], Average Validation Loss: 0.4080, Average Validation Accuracy: 0.8232\n",
      "Epoch [145/500], Average Training Loss: 0.4037\n",
      "Epoch [145/500], Average Validation Loss: 0.4078, Average Validation Accuracy: 0.8234\n",
      "Epoch [146/500], Average Training Loss: 0.4036\n",
      "Epoch [146/500], Average Validation Loss: 0.4080, Average Validation Accuracy: 0.8234\n",
      "Epoch [147/500], Average Training Loss: 0.4037\n",
      "Epoch [147/500], Average Validation Loss: 0.4081, Average Validation Accuracy: 0.8220\n",
      "Epoch [148/500], Average Training Loss: 0.4036\n",
      "Epoch [148/500], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8234\n",
      "Epoch [149/500], Average Training Loss: 0.4035\n",
      "Epoch [149/500], Average Validation Loss: 0.4077, Average Validation Accuracy: 0.8235\n",
      "Epoch [150/500], Average Training Loss: 0.4033\n",
      "Epoch [150/500], Average Validation Loss: 0.4077, Average Validation Accuracy: 0.8236\n",
      "Epoch [151/500], Average Training Loss: 0.4034\n",
      "Epoch [151/500], Average Validation Loss: 0.4080, Average Validation Accuracy: 0.8229\n",
      "Epoch [152/500], Average Training Loss: 0.4032\n",
      "Epoch [152/500], Average Validation Loss: 0.4072, Average Validation Accuracy: 0.8237\n",
      "Epoch [153/500], Average Training Loss: 0.4033\n",
      "Epoch [153/500], Average Validation Loss: 0.4086, Average Validation Accuracy: 0.8230\n",
      "Epoch [154/500], Average Training Loss: 0.4032\n",
      "Epoch [154/500], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8238\n",
      "Epoch [155/500], Average Training Loss: 0.4030\n",
      "Epoch [155/500], Average Validation Loss: 0.4081, Average Validation Accuracy: 0.8236\n",
      "Epoch [156/500], Average Training Loss: 0.4029\n",
      "Epoch [156/500], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8236\n",
      "Epoch [157/500], Average Training Loss: 0.4029\n",
      "Epoch [157/500], Average Validation Loss: 0.4076, Average Validation Accuracy: 0.8234\n",
      "Epoch [158/500], Average Training Loss: 0.4029\n",
      "Epoch [158/500], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8237\n",
      "Epoch [159/500], Average Training Loss: 0.4029\n",
      "Epoch [159/500], Average Validation Loss: 0.4072, Average Validation Accuracy: 0.8239\n",
      "Epoch [160/500], Average Training Loss: 0.4027\n",
      "Epoch [160/500], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8244\n",
      "Epoch [161/500], Average Training Loss: 0.4026\n",
      "Epoch [161/500], Average Validation Loss: 0.4076, Average Validation Accuracy: 0.8232\n",
      "Epoch [162/500], Average Training Loss: 0.4026\n",
      "Epoch [162/500], Average Validation Loss: 0.4075, Average Validation Accuracy: 0.8252\n",
      "Epoch [163/500], Average Training Loss: 0.4025\n",
      "Epoch [163/500], Average Validation Loss: 0.4070, Average Validation Accuracy: 0.8241\n",
      "Epoch [164/500], Average Training Loss: 0.4024\n",
      "Epoch [164/500], Average Validation Loss: 0.4068, Average Validation Accuracy: 0.8237\n",
      "Epoch [165/500], Average Training Loss: 0.4023\n",
      "Epoch [165/500], Average Validation Loss: 0.4068, Average Validation Accuracy: 0.8239\n",
      "Epoch [166/500], Average Training Loss: 0.4023\n",
      "Epoch [166/500], Average Validation Loss: 0.4066, Average Validation Accuracy: 0.8248\n",
      "Epoch [167/500], Average Training Loss: 0.4022\n",
      "Epoch [167/500], Average Validation Loss: 0.4071, Average Validation Accuracy: 0.8244\n",
      "Epoch [168/500], Average Training Loss: 0.4021\n",
      "Epoch [168/500], Average Validation Loss: 0.4065, Average Validation Accuracy: 0.8240\n",
      "Epoch [169/500], Average Training Loss: 0.4021\n",
      "Epoch [169/500], Average Validation Loss: 0.4073, Average Validation Accuracy: 0.8239\n",
      "Epoch [170/500], Average Training Loss: 0.4021\n",
      "Epoch [170/500], Average Validation Loss: 0.4065, Average Validation Accuracy: 0.8242\n",
      "Epoch [171/500], Average Training Loss: 0.4019\n",
      "Epoch [171/500], Average Validation Loss: 0.4069, Average Validation Accuracy: 0.8240\n",
      "Epoch [172/500], Average Training Loss: 0.4018\n",
      "Epoch [172/500], Average Validation Loss: 0.4087, Average Validation Accuracy: 0.8218\n",
      "Epoch [173/500], Average Training Loss: 0.4018\n",
      "Epoch [173/500], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8247\n",
      "Epoch [174/500], Average Training Loss: 0.4017\n",
      "Epoch [174/500], Average Validation Loss: 0.4065, Average Validation Accuracy: 0.8236\n",
      "Epoch [175/500], Average Training Loss: 0.4017\n",
      "Epoch [175/500], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8241\n",
      "Epoch [176/500], Average Training Loss: 0.4017\n",
      "Epoch [176/500], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8250\n",
      "Epoch [177/500], Average Training Loss: 0.4016\n",
      "Epoch [177/500], Average Validation Loss: 0.4065, Average Validation Accuracy: 0.8230\n",
      "Epoch [178/500], Average Training Loss: 0.4015\n",
      "Epoch [178/500], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8236\n",
      "Epoch [179/500], Average Training Loss: 0.4015\n",
      "Epoch [179/500], Average Validation Loss: 0.4059, Average Validation Accuracy: 0.8245\n",
      "Epoch [180/500], Average Training Loss: 0.4013\n",
      "Epoch [180/500], Average Validation Loss: 0.4064, Average Validation Accuracy: 0.8245\n",
      "Epoch [181/500], Average Training Loss: 0.4013\n",
      "Epoch [181/500], Average Validation Loss: 0.4065, Average Validation Accuracy: 0.8247\n",
      "Epoch [182/500], Average Training Loss: 0.4012\n",
      "Epoch [182/500], Average Validation Loss: 0.4059, Average Validation Accuracy: 0.8243\n",
      "Epoch [183/500], Average Training Loss: 0.4012\n",
      "Epoch [183/500], Average Validation Loss: 0.4064, Average Validation Accuracy: 0.8247\n",
      "Epoch [184/500], Average Training Loss: 0.4011\n",
      "Epoch [184/500], Average Validation Loss: 0.4065, Average Validation Accuracy: 0.8243\n",
      "Epoch [185/500], Average Training Loss: 0.4010\n",
      "Epoch [185/500], Average Validation Loss: 0.4057, Average Validation Accuracy: 0.8243\n",
      "Epoch [186/500], Average Training Loss: 0.4009\n",
      "Epoch [186/500], Average Validation Loss: 0.4081, Average Validation Accuracy: 0.8220\n",
      "Epoch [187/500], Average Training Loss: 0.4008\n",
      "Epoch [187/500], Average Validation Loss: 0.4063, Average Validation Accuracy: 0.8241\n",
      "Epoch [188/500], Average Training Loss: 0.4009\n",
      "Epoch [188/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8244\n",
      "Epoch [189/500], Average Training Loss: 0.4007\n",
      "Epoch [189/500], Average Validation Loss: 0.4060, Average Validation Accuracy: 0.8244\n",
      "Epoch [190/500], Average Training Loss: 0.4007\n",
      "Epoch [190/500], Average Validation Loss: 0.4062, Average Validation Accuracy: 0.8248\n",
      "Epoch [191/500], Average Training Loss: 0.4006\n",
      "Epoch [191/500], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8238\n",
      "Epoch [192/500], Average Training Loss: 0.4005\n",
      "Epoch [192/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8248\n",
      "Epoch [193/500], Average Training Loss: 0.4005\n",
      "Epoch [193/500], Average Validation Loss: 0.4057, Average Validation Accuracy: 0.8243\n",
      "Epoch [194/500], Average Training Loss: 0.4004\n",
      "Epoch [194/500], Average Validation Loss: 0.4059, Average Validation Accuracy: 0.8249\n",
      "Epoch [195/500], Average Training Loss: 0.4004\n",
      "Epoch [195/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8243\n",
      "Epoch [196/500], Average Training Loss: 0.4003\n",
      "Epoch [196/500], Average Validation Loss: 0.4052, Average Validation Accuracy: 0.8253\n",
      "Epoch [197/500], Average Training Loss: 0.4003\n",
      "Epoch [197/500], Average Validation Loss: 0.4051, Average Validation Accuracy: 0.8243\n",
      "Epoch [198/500], Average Training Loss: 0.4001\n",
      "Epoch [198/500], Average Validation Loss: 0.4055, Average Validation Accuracy: 0.8263\n",
      "Epoch [199/500], Average Training Loss: 0.4002\n",
      "Epoch [199/500], Average Validation Loss: 0.4059, Average Validation Accuracy: 0.8237\n",
      "Epoch [200/500], Average Training Loss: 0.4000\n",
      "Epoch [200/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8252\n",
      "Epoch [201/500], Average Training Loss: 0.3999\n",
      "Epoch [201/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8239\n",
      "Epoch [202/500], Average Training Loss: 0.4000\n",
      "Epoch [202/500], Average Validation Loss: 0.4058, Average Validation Accuracy: 0.8260\n",
      "Epoch [203/500], Average Training Loss: 0.3997\n",
      "Epoch [203/500], Average Validation Loss: 0.4052, Average Validation Accuracy: 0.8243\n",
      "Epoch [204/500], Average Training Loss: 0.4000\n",
      "Epoch [204/500], Average Validation Loss: 0.4053, Average Validation Accuracy: 0.8256\n",
      "Epoch [205/500], Average Training Loss: 0.3997\n",
      "Epoch [205/500], Average Validation Loss: 0.4049, Average Validation Accuracy: 0.8252\n",
      "Epoch [206/500], Average Training Loss: 0.3996\n",
      "Epoch [206/500], Average Validation Loss: 0.4061, Average Validation Accuracy: 0.8241\n",
      "Epoch [207/500], Average Training Loss: 0.3996\n",
      "Epoch [207/500], Average Validation Loss: 0.4050, Average Validation Accuracy: 0.8239\n",
      "Epoch [208/500], Average Training Loss: 0.3995\n",
      "Epoch [208/500], Average Validation Loss: 0.4049, Average Validation Accuracy: 0.8250\n",
      "Epoch [209/500], Average Training Loss: 0.3995\n",
      "Epoch [209/500], Average Validation Loss: 0.4051, Average Validation Accuracy: 0.8241\n",
      "Epoch [210/500], Average Training Loss: 0.3995\n",
      "Epoch [210/500], Average Validation Loss: 0.4060, Average Validation Accuracy: 0.8226\n",
      "Epoch [211/500], Average Training Loss: 0.3994\n",
      "Epoch [211/500], Average Validation Loss: 0.4053, Average Validation Accuracy: 0.8259\n",
      "Epoch [212/500], Average Training Loss: 0.3993\n",
      "Epoch [212/500], Average Validation Loss: 0.4047, Average Validation Accuracy: 0.8251\n",
      "Epoch [213/500], Average Training Loss: 0.3993\n",
      "Epoch [213/500], Average Validation Loss: 0.4049, Average Validation Accuracy: 0.8255\n",
      "Epoch [214/500], Average Training Loss: 0.3991\n",
      "Epoch [214/500], Average Validation Loss: 0.4057, Average Validation Accuracy: 0.8260\n",
      "Epoch [215/500], Average Training Loss: 0.3990\n",
      "Epoch [215/500], Average Validation Loss: 0.4047, Average Validation Accuracy: 0.8254\n",
      "Epoch [216/500], Average Training Loss: 0.3990\n",
      "Epoch [216/500], Average Validation Loss: 0.4054, Average Validation Accuracy: 0.8257\n",
      "Epoch [217/500], Average Training Loss: 0.3990\n",
      "Epoch [217/500], Average Validation Loss: 0.4046, Average Validation Accuracy: 0.8252\n",
      "Epoch [218/500], Average Training Loss: 0.3990\n",
      "Epoch [218/500], Average Validation Loss: 0.4046, Average Validation Accuracy: 0.8259\n",
      "Epoch [219/500], Average Training Loss: 0.3989\n",
      "Epoch [219/500], Average Validation Loss: 0.4046, Average Validation Accuracy: 0.8255\n",
      "Epoch [220/500], Average Training Loss: 0.3989\n",
      "Epoch [220/500], Average Validation Loss: 0.4044, Average Validation Accuracy: 0.8258\n",
      "Epoch [221/500], Average Training Loss: 0.3988\n",
      "Epoch [221/500], Average Validation Loss: 0.4051, Average Validation Accuracy: 0.8262\n",
      "Epoch [222/500], Average Training Loss: 0.3987\n",
      "Epoch [222/500], Average Validation Loss: 0.4047, Average Validation Accuracy: 0.8246\n",
      "Epoch [223/500], Average Training Loss: 0.3987\n",
      "Epoch [223/500], Average Validation Loss: 0.4045, Average Validation Accuracy: 0.8246\n",
      "Epoch [224/500], Average Training Loss: 0.3986\n",
      "Epoch [224/500], Average Validation Loss: 0.4046, Average Validation Accuracy: 0.8236\n",
      "Epoch [225/500], Average Training Loss: 0.3986\n",
      "Epoch [225/500], Average Validation Loss: 0.4041, Average Validation Accuracy: 0.8251\n",
      "Epoch [226/500], Average Training Loss: 0.3984\n",
      "Epoch [226/500], Average Validation Loss: 0.4052, Average Validation Accuracy: 0.8236\n",
      "Epoch [227/500], Average Training Loss: 0.3986\n",
      "Epoch [227/500], Average Validation Loss: 0.4041, Average Validation Accuracy: 0.8254\n",
      "Epoch [228/500], Average Training Loss: 0.3984\n",
      "Epoch [228/500], Average Validation Loss: 0.4049, Average Validation Accuracy: 0.8237\n",
      "Epoch [229/500], Average Training Loss: 0.3983\n",
      "Epoch [229/500], Average Validation Loss: 0.4044, Average Validation Accuracy: 0.8260\n",
      "Epoch [230/500], Average Training Loss: 0.3983\n",
      "Epoch [230/500], Average Validation Loss: 0.4043, Average Validation Accuracy: 0.8254\n",
      "Epoch [231/500], Average Training Loss: 0.3982\n",
      "Epoch [231/500], Average Validation Loss: 0.4051, Average Validation Accuracy: 0.8258\n",
      "Epoch [232/500], Average Training Loss: 0.3981\n",
      "Epoch [232/500], Average Validation Loss: 0.4055, Average Validation Accuracy: 0.8250\n",
      "Epoch [233/500], Average Training Loss: 0.3982\n",
      "Epoch [233/500], Average Validation Loss: 0.4040, Average Validation Accuracy: 0.8248\n",
      "Epoch [234/500], Average Training Loss: 0.3982\n",
      "Epoch [234/500], Average Validation Loss: 0.4040, Average Validation Accuracy: 0.8255\n",
      "Epoch [235/500], Average Training Loss: 0.3979\n",
      "Epoch [235/500], Average Validation Loss: 0.4040, Average Validation Accuracy: 0.8254\n",
      "Epoch [236/500], Average Training Loss: 0.3977\n",
      "Epoch [236/500], Average Validation Loss: 0.4051, Average Validation Accuracy: 0.8236\n",
      "Epoch [237/500], Average Training Loss: 0.3980\n",
      "Epoch [237/500], Average Validation Loss: 0.4041, Average Validation Accuracy: 0.8247\n",
      "Epoch [238/500], Average Training Loss: 0.3980\n",
      "Epoch [238/500], Average Validation Loss: 0.4045, Average Validation Accuracy: 0.8262\n",
      "Epoch [239/500], Average Training Loss: 0.3978\n",
      "Epoch [239/500], Average Validation Loss: 0.4045, Average Validation Accuracy: 0.8256\n",
      "Epoch [240/500], Average Training Loss: 0.3978\n",
      "Epoch [240/500], Average Validation Loss: 0.4042, Average Validation Accuracy: 0.8252\n",
      "Epoch [241/500], Average Training Loss: 0.3978\n",
      "Epoch [241/500], Average Validation Loss: 0.4040, Average Validation Accuracy: 0.8245\n",
      "Epoch [242/500], Average Training Loss: 0.3976\n",
      "Epoch [242/500], Average Validation Loss: 0.4039, Average Validation Accuracy: 0.8256\n",
      "Epoch [243/500], Average Training Loss: 0.3976\n",
      "Epoch [243/500], Average Validation Loss: 0.4038, Average Validation Accuracy: 0.8240\n",
      "Epoch [244/500], Average Training Loss: 0.3976\n",
      "Epoch [244/500], Average Validation Loss: 0.4043, Average Validation Accuracy: 0.8256\n",
      "Epoch [245/500], Average Training Loss: 0.3975\n",
      "Epoch [245/500], Average Validation Loss: 0.4041, Average Validation Accuracy: 0.8243\n",
      "Epoch [246/500], Average Training Loss: 0.3974\n",
      "Epoch [246/500], Average Validation Loss: 0.4049, Average Validation Accuracy: 0.8263\n",
      "Epoch [247/500], Average Training Loss: 0.3975\n",
      "Epoch [247/500], Average Validation Loss: 0.4050, Average Validation Accuracy: 0.8266\n",
      "Epoch [248/500], Average Training Loss: 0.3972\n",
      "Epoch [248/500], Average Validation Loss: 0.4040, Average Validation Accuracy: 0.8256\n",
      "Epoch [249/500], Average Training Loss: 0.3973\n",
      "Epoch [249/500], Average Validation Loss: 0.4040, Average Validation Accuracy: 0.8245\n",
      "Epoch [250/500], Average Training Loss: 0.3972\n",
      "Epoch [250/500], Average Validation Loss: 0.4039, Average Validation Accuracy: 0.8248\n",
      "Epoch [251/500], Average Training Loss: 0.3972\n",
      "Epoch [251/500], Average Validation Loss: 0.4041, Average Validation Accuracy: 0.8244\n",
      "Epoch [252/500], Average Training Loss: 0.3971\n",
      "Epoch [252/500], Average Validation Loss: 0.4040, Average Validation Accuracy: 0.8251\n",
      "Epoch [253/500], Average Training Loss: 0.3971\n",
      "Epoch [253/500], Average Validation Loss: 0.4039, Average Validation Accuracy: 0.8254\n",
      "Epoch [254/500], Average Training Loss: 0.3971\n",
      "Early stopping at epoch 253. Best loss was 0.4038\n",
      "Best Validation Accuracy: 0.8266 at epoch 247 for trial 17\n",
      "Epoch [1/200], Average Training Loss: 0.6890\n",
      "Epoch [1/200], Average Validation Loss: 0.6860, Average Validation Accuracy: 0.6101\n",
      "Epoch [2/200], Average Training Loss: 0.6832\n",
      "Epoch [2/200], Average Validation Loss: 0.6800, Average Validation Accuracy: 0.6303\n",
      "Epoch [3/200], Average Training Loss: 0.6767\n",
      "Epoch [3/200], Average Validation Loss: 0.6729, Average Validation Accuracy: 0.6611\n",
      "Epoch [4/200], Average Training Loss: 0.6687\n",
      "Epoch [4/200], Average Validation Loss: 0.6639, Average Validation Accuracy: 0.6923\n",
      "Epoch [5/200], Average Training Loss: 0.6584\n",
      "Epoch [5/200], Average Validation Loss: 0.6522, Average Validation Accuracy: 0.7102\n",
      "Epoch [6/200], Average Training Loss: 0.6448\n",
      "Epoch [6/200], Average Validation Loss: 0.6366, Average Validation Accuracy: 0.7176\n",
      "Epoch [7/200], Average Training Loss: 0.6268\n",
      "Epoch [7/200], Average Validation Loss: 0.6163, Average Validation Accuracy: 0.7241\n",
      "Epoch [8/200], Average Training Loss: 0.6039\n",
      "Epoch [8/200], Average Validation Loss: 0.5912, Average Validation Accuracy: 0.7338\n",
      "Epoch [9/200], Average Training Loss: 0.5767\n",
      "Epoch [9/200], Average Validation Loss: 0.5630, Average Validation Accuracy: 0.7453\n",
      "Epoch [10/200], Average Training Loss: 0.5478\n",
      "Epoch [10/200], Average Validation Loss: 0.5348, Average Validation Accuracy: 0.7571\n",
      "Epoch [11/200], Average Training Loss: 0.5207\n",
      "Epoch [11/200], Average Validation Loss: 0.5101, Average Validation Accuracy: 0.7698\n",
      "Epoch [12/200], Average Training Loss: 0.4981\n",
      "Epoch [12/200], Average Validation Loss: 0.4909, Average Validation Accuracy: 0.7790\n",
      "Epoch [13/200], Average Training Loss: 0.4814\n",
      "Epoch [13/200], Average Validation Loss: 0.4773, Average Validation Accuracy: 0.7854\n",
      "Epoch [14/200], Average Training Loss: 0.4698\n",
      "Epoch [14/200], Average Validation Loss: 0.4684, Average Validation Accuracy: 0.7888\n",
      "Epoch [15/200], Average Training Loss: 0.4624\n",
      "Epoch [15/200], Average Validation Loss: 0.4629, Average Validation Accuracy: 0.7912\n",
      "Epoch [16/200], Average Training Loss: 0.4579\n",
      "Epoch [16/200], Average Validation Loss: 0.4596, Average Validation Accuracy: 0.7922\n",
      "Epoch [17/200], Average Training Loss: 0.4550\n",
      "Epoch [17/200], Average Validation Loss: 0.4575, Average Validation Accuracy: 0.7923\n",
      "Epoch [18/200], Average Training Loss: 0.4531\n",
      "Epoch [18/200], Average Validation Loss: 0.4559, Average Validation Accuracy: 0.7936\n",
      "Epoch [19/200], Average Training Loss: 0.4517\n",
      "Epoch [19/200], Average Validation Loss: 0.4547, Average Validation Accuracy: 0.7947\n",
      "Epoch [20/200], Average Training Loss: 0.4505\n",
      "Epoch [20/200], Average Validation Loss: 0.4539, Average Validation Accuracy: 0.7948\n",
      "Epoch [21/200], Average Training Loss: 0.4496\n",
      "Epoch [21/200], Average Validation Loss: 0.4531, Average Validation Accuracy: 0.7951\n",
      "Epoch [22/200], Average Training Loss: 0.4489\n",
      "Epoch [22/200], Average Validation Loss: 0.4524, Average Validation Accuracy: 0.7956\n",
      "Epoch [23/200], Average Training Loss: 0.4483\n",
      "Epoch [23/200], Average Validation Loss: 0.4516, Average Validation Accuracy: 0.7962\n",
      "Epoch [24/200], Average Training Loss: 0.4475\n",
      "Epoch [24/200], Average Validation Loss: 0.4509, Average Validation Accuracy: 0.7966\n",
      "Epoch [25/200], Average Training Loss: 0.4468\n",
      "Epoch [25/200], Average Validation Loss: 0.4503, Average Validation Accuracy: 0.7970\n",
      "Epoch [26/200], Average Training Loss: 0.4463\n",
      "Epoch [26/200], Average Validation Loss: 0.4498, Average Validation Accuracy: 0.7972\n",
      "Epoch [27/200], Average Training Loss: 0.4457\n",
      "Epoch [27/200], Average Validation Loss: 0.4492, Average Validation Accuracy: 0.7984\n",
      "Epoch [28/200], Average Training Loss: 0.4452\n",
      "Epoch [28/200], Average Validation Loss: 0.4486, Average Validation Accuracy: 0.7974\n",
      "Epoch [29/200], Average Training Loss: 0.4445\n",
      "Epoch [29/200], Average Validation Loss: 0.4480, Average Validation Accuracy: 0.7983\n",
      "Epoch [30/200], Average Training Loss: 0.4440\n",
      "Epoch [30/200], Average Validation Loss: 0.4475, Average Validation Accuracy: 0.7984\n",
      "Epoch [31/200], Average Training Loss: 0.4433\n",
      "Epoch [31/200], Average Validation Loss: 0.4477, Average Validation Accuracy: 0.7972\n",
      "Epoch [32/200], Average Training Loss: 0.4431\n",
      "Epoch [32/200], Average Validation Loss: 0.4465, Average Validation Accuracy: 0.7997\n",
      "Epoch [33/200], Average Training Loss: 0.4425\n",
      "Epoch [33/200], Average Validation Loss: 0.4464, Average Validation Accuracy: 0.7986\n",
      "Epoch [34/200], Average Training Loss: 0.4422\n",
      "Epoch [34/200], Average Validation Loss: 0.4456, Average Validation Accuracy: 0.8008\n",
      "Epoch [35/200], Average Training Loss: 0.4416\n",
      "Epoch [35/200], Average Validation Loss: 0.4451, Average Validation Accuracy: 0.8007\n",
      "Epoch [36/200], Average Training Loss: 0.4413\n",
      "Epoch [36/200], Average Validation Loss: 0.4447, Average Validation Accuracy: 0.8010\n",
      "Epoch [37/200], Average Training Loss: 0.4408\n",
      "Epoch [37/200], Average Validation Loss: 0.4443, Average Validation Accuracy: 0.8010\n",
      "Epoch [38/200], Average Training Loss: 0.4404\n",
      "Epoch [38/200], Average Validation Loss: 0.4438, Average Validation Accuracy: 0.8017\n",
      "Epoch [39/200], Average Training Loss: 0.4400\n",
      "Epoch [39/200], Average Validation Loss: 0.4435, Average Validation Accuracy: 0.8020\n",
      "Epoch [40/200], Average Training Loss: 0.4397\n",
      "Epoch [40/200], Average Validation Loss: 0.4431, Average Validation Accuracy: 0.8017\n",
      "Epoch [41/200], Average Training Loss: 0.4392\n",
      "Epoch [41/200], Average Validation Loss: 0.4427, Average Validation Accuracy: 0.8025\n",
      "Epoch [42/200], Average Training Loss: 0.4389\n",
      "Epoch [42/200], Average Validation Loss: 0.4423, Average Validation Accuracy: 0.8026\n",
      "Epoch [43/200], Average Training Loss: 0.4387\n",
      "Epoch [43/200], Average Validation Loss: 0.4420, Average Validation Accuracy: 0.8028\n",
      "Epoch [44/200], Average Training Loss: 0.4382\n",
      "Epoch [44/200], Average Validation Loss: 0.4418, Average Validation Accuracy: 0.8036\n",
      "Epoch [45/200], Average Training Loss: 0.4380\n",
      "Epoch [45/200], Average Validation Loss: 0.4413, Average Validation Accuracy: 0.8030\n",
      "Epoch [46/200], Average Training Loss: 0.4376\n",
      "Epoch [46/200], Average Validation Loss: 0.4410, Average Validation Accuracy: 0.8032\n",
      "Epoch [47/200], Average Training Loss: 0.4372\n",
      "Epoch [47/200], Average Validation Loss: 0.4407, Average Validation Accuracy: 0.8036\n",
      "Epoch [48/200], Average Training Loss: 0.4369\n",
      "Epoch [48/200], Average Validation Loss: 0.4404, Average Validation Accuracy: 0.8042\n",
      "Epoch [49/200], Average Training Loss: 0.4367\n",
      "Epoch [49/200], Average Validation Loss: 0.4401, Average Validation Accuracy: 0.8043\n",
      "Epoch [50/200], Average Training Loss: 0.4364\n",
      "Epoch [50/200], Average Validation Loss: 0.4398, Average Validation Accuracy: 0.8044\n",
      "Epoch [51/200], Average Training Loss: 0.4362\n",
      "Epoch [51/200], Average Validation Loss: 0.4395, Average Validation Accuracy: 0.8048\n",
      "Epoch [52/200], Average Training Loss: 0.4359\n",
      "Epoch [52/200], Average Validation Loss: 0.4392, Average Validation Accuracy: 0.8050\n",
      "Epoch [53/200], Average Training Loss: 0.4356\n",
      "Epoch [53/200], Average Validation Loss: 0.4392, Average Validation Accuracy: 0.8052\n",
      "Epoch [54/200], Average Training Loss: 0.4353\n",
      "Epoch [54/200], Average Validation Loss: 0.4387, Average Validation Accuracy: 0.8053\n",
      "Epoch [55/200], Average Training Loss: 0.4352\n",
      "Epoch [55/200], Average Validation Loss: 0.4385, Average Validation Accuracy: 0.8052\n",
      "Epoch [56/200], Average Training Loss: 0.4349\n",
      "Epoch [56/200], Average Validation Loss: 0.4383, Average Validation Accuracy: 0.8051\n",
      "Epoch [57/200], Average Training Loss: 0.4347\n",
      "Epoch [57/200], Average Validation Loss: 0.4381, Average Validation Accuracy: 0.8056\n",
      "Epoch [58/200], Average Training Loss: 0.4344\n",
      "Epoch [58/200], Average Validation Loss: 0.4378, Average Validation Accuracy: 0.8055\n",
      "Epoch [59/200], Average Training Loss: 0.4343\n",
      "Epoch [59/200], Average Validation Loss: 0.4380, Average Validation Accuracy: 0.8045\n",
      "Epoch [60/200], Average Training Loss: 0.4341\n",
      "Epoch [60/200], Average Validation Loss: 0.4375, Average Validation Accuracy: 0.8064\n",
      "Epoch [61/200], Average Training Loss: 0.4339\n",
      "Epoch [61/200], Average Validation Loss: 0.4372, Average Validation Accuracy: 0.8061\n",
      "Epoch [62/200], Average Training Loss: 0.4338\n",
      "Epoch [62/200], Average Validation Loss: 0.4370, Average Validation Accuracy: 0.8058\n",
      "Epoch [63/200], Average Training Loss: 0.4334\n",
      "Epoch [63/200], Average Validation Loss: 0.4368, Average Validation Accuracy: 0.8064\n",
      "Epoch [64/200], Average Training Loss: 0.4333\n",
      "Epoch [64/200], Average Validation Loss: 0.4367, Average Validation Accuracy: 0.8065\n",
      "Epoch [65/200], Average Training Loss: 0.4331\n",
      "Epoch [65/200], Average Validation Loss: 0.4366, Average Validation Accuracy: 0.8072\n",
      "Epoch [66/200], Average Training Loss: 0.4329\n",
      "Epoch [66/200], Average Validation Loss: 0.4364, Average Validation Accuracy: 0.8065\n",
      "Epoch [67/200], Average Training Loss: 0.4328\n",
      "Epoch [67/200], Average Validation Loss: 0.4362, Average Validation Accuracy: 0.8075\n",
      "Epoch [68/200], Average Training Loss: 0.4327\n",
      "Epoch [68/200], Average Validation Loss: 0.4360, Average Validation Accuracy: 0.8073\n",
      "Epoch [69/200], Average Training Loss: 0.4325\n",
      "Epoch [69/200], Average Validation Loss: 0.4359, Average Validation Accuracy: 0.8077\n",
      "Epoch [70/200], Average Training Loss: 0.4324\n",
      "Epoch [70/200], Average Validation Loss: 0.4359, Average Validation Accuracy: 0.8073\n",
      "Epoch [71/200], Average Training Loss: 0.4324\n",
      "Epoch [71/200], Average Validation Loss: 0.4356, Average Validation Accuracy: 0.8078\n",
      "Epoch [72/200], Average Training Loss: 0.4321\n",
      "Epoch [72/200], Average Validation Loss: 0.4357, Average Validation Accuracy: 0.8075\n",
      "Epoch [73/200], Average Training Loss: 0.4321\n",
      "Epoch [73/200], Average Validation Loss: 0.4354, Average Validation Accuracy: 0.8081\n",
      "Epoch [74/200], Average Training Loss: 0.4319\n",
      "Epoch [74/200], Average Validation Loss: 0.4352, Average Validation Accuracy: 0.8084\n",
      "Epoch [75/200], Average Training Loss: 0.4319\n",
      "Epoch [75/200], Average Validation Loss: 0.4351, Average Validation Accuracy: 0.8088\n",
      "Epoch [76/200], Average Training Loss: 0.4318\n",
      "Epoch [76/200], Average Validation Loss: 0.4350, Average Validation Accuracy: 0.8090\n",
      "Epoch [77/200], Average Training Loss: 0.4316\n",
      "Epoch [77/200], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8092\n",
      "Epoch [78/200], Average Training Loss: 0.4315\n",
      "Epoch [78/200], Average Validation Loss: 0.4348, Average Validation Accuracy: 0.8089\n",
      "Epoch [79/200], Average Training Loss: 0.4315\n",
      "Epoch [79/200], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8094\n",
      "Epoch [80/200], Average Training Loss: 0.4314\n",
      "Epoch [80/200], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8095\n",
      "Epoch [81/200], Average Training Loss: 0.4313\n",
      "Epoch [81/200], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8096\n",
      "Epoch [82/200], Average Training Loss: 0.4312\n",
      "Epoch [82/200], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8089\n",
      "Epoch [83/200], Average Training Loss: 0.4311\n",
      "Epoch [83/200], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8095\n",
      "Epoch [84/200], Average Training Loss: 0.4310\n",
      "Epoch [84/200], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8090\n",
      "Epoch [85/200], Average Training Loss: 0.4308\n",
      "Epoch [85/200], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8088\n",
      "Epoch [86/200], Average Training Loss: 0.4309\n",
      "Epoch [86/200], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8095\n",
      "Epoch [87/200], Average Training Loss: 0.4308\n",
      "Epoch [87/200], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8090\n",
      "Epoch [88/200], Average Training Loss: 0.4307\n",
      "Epoch [88/200], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8099\n",
      "Epoch [89/200], Average Training Loss: 0.4305\n",
      "Epoch [89/200], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8101\n",
      "Epoch [90/200], Average Training Loss: 0.4306\n",
      "Epoch [90/200], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8093\n",
      "Epoch [91/200], Average Training Loss: 0.4304\n",
      "Epoch [91/200], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8094\n",
      "Epoch [92/200], Average Training Loss: 0.4304\n",
      "Epoch [92/200], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8095\n",
      "Epoch [93/200], Average Training Loss: 0.4305\n",
      "Epoch [93/200], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8099\n",
      "Epoch [94/200], Average Training Loss: 0.4303\n",
      "Epoch [94/200], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8097\n",
      "Epoch [95/200], Average Training Loss: 0.4303\n",
      "Epoch [95/200], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8097\n",
      "Epoch [96/200], Average Training Loss: 0.4301\n",
      "Epoch [96/200], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8108\n",
      "Epoch [97/200], Average Training Loss: 0.4301\n",
      "Epoch [97/200], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8106\n",
      "Epoch [98/200], Average Training Loss: 0.4300\n",
      "Epoch [98/200], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8114\n",
      "Epoch [99/200], Average Training Loss: 0.4302\n",
      "Epoch [99/200], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8108\n",
      "Epoch [100/200], Average Training Loss: 0.4300\n",
      "Epoch [100/200], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8113\n",
      "Epoch [101/200], Average Training Loss: 0.4300\n",
      "Epoch [101/200], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8096\n",
      "Epoch [102/200], Average Training Loss: 0.4300\n",
      "Epoch [102/200], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8098\n",
      "Epoch [103/200], Average Training Loss: 0.4300\n",
      "Epoch [103/200], Average Validation Loss: 0.4331, Average Validation Accuracy: 0.8109\n",
      "Epoch [104/200], Average Training Loss: 0.4298\n",
      "Epoch [104/200], Average Validation Loss: 0.4331, Average Validation Accuracy: 0.8117\n",
      "Epoch [105/200], Average Training Loss: 0.4298\n",
      "Epoch [105/200], Average Validation Loss: 0.4331, Average Validation Accuracy: 0.8122\n",
      "Epoch [106/200], Average Training Loss: 0.4297\n",
      "Epoch [106/200], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8108\n",
      "Epoch [107/200], Average Training Loss: 0.4298\n",
      "Epoch [107/200], Average Validation Loss: 0.4330, Average Validation Accuracy: 0.8115\n",
      "Epoch [108/200], Average Training Loss: 0.4295\n",
      "Epoch [108/200], Average Validation Loss: 0.4329, Average Validation Accuracy: 0.8121\n",
      "Epoch [109/200], Average Training Loss: 0.4296\n",
      "Epoch [109/200], Average Validation Loss: 0.4330, Average Validation Accuracy: 0.8111\n",
      "Epoch [110/200], Average Training Loss: 0.4296\n",
      "Epoch [110/200], Average Validation Loss: 0.4329, Average Validation Accuracy: 0.8115\n",
      "Epoch [111/200], Average Training Loss: 0.4295\n",
      "Epoch [111/200], Average Validation Loss: 0.4329, Average Validation Accuracy: 0.8103\n",
      "Epoch [112/200], Average Training Loss: 0.4295\n",
      "Epoch [112/200], Average Validation Loss: 0.4328, Average Validation Accuracy: 0.8115\n",
      "Epoch [113/200], Average Training Loss: 0.4294\n",
      "Epoch [113/200], Average Validation Loss: 0.4328, Average Validation Accuracy: 0.8118\n",
      "Epoch [114/200], Average Training Loss: 0.4294\n",
      "Epoch [114/200], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8111\n",
      "Epoch [115/200], Average Training Loss: 0.4293\n",
      "Epoch [115/200], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8117\n",
      "Epoch [116/200], Average Training Loss: 0.4295\n",
      "Epoch [116/200], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8110\n",
      "Epoch [117/200], Average Training Loss: 0.4292\n",
      "Epoch [117/200], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8118\n",
      "Epoch [118/200], Average Training Loss: 0.4292\n",
      "Epoch [118/200], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8109\n",
      "Epoch [119/200], Average Training Loss: 0.4293\n",
      "Epoch [119/200], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8116\n",
      "Epoch [120/200], Average Training Loss: 0.4292\n",
      "Epoch [120/200], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8107\n",
      "Epoch [121/200], Average Training Loss: 0.4292\n",
      "Epoch [121/200], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8115\n",
      "Epoch [122/200], Average Training Loss: 0.4292\n",
      "Epoch [122/200], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8114\n",
      "Epoch [123/200], Average Training Loss: 0.4292\n",
      "Epoch [123/200], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8116\n",
      "Epoch [124/200], Average Training Loss: 0.4290\n",
      "Epoch [124/200], Average Validation Loss: 0.4324, Average Validation Accuracy: 0.8115\n",
      "Epoch [125/200], Average Training Loss: 0.4291\n",
      "Epoch [125/200], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8114\n",
      "Epoch [126/200], Average Training Loss: 0.4290\n",
      "Epoch [126/200], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8112\n",
      "Epoch [127/200], Average Training Loss: 0.4290\n",
      "Epoch [127/200], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8114\n",
      "Epoch [128/200], Average Training Loss: 0.4291\n",
      "Epoch [128/200], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8114\n",
      "Epoch [129/200], Average Training Loss: 0.4290\n",
      "Epoch [129/200], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8113\n",
      "Epoch [130/200], Average Training Loss: 0.4288\n",
      "Epoch [130/200], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8113\n",
      "Epoch [131/200], Average Training Loss: 0.4288\n",
      "Epoch [131/200], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8117\n",
      "Epoch [132/200], Average Training Loss: 0.4288\n",
      "Epoch [132/200], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8116\n",
      "Epoch [133/200], Average Training Loss: 0.4288\n",
      "Epoch [133/200], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8119\n",
      "Epoch [134/200], Average Training Loss: 0.4287\n",
      "Epoch [134/200], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8109\n",
      "Epoch [135/200], Average Training Loss: 0.4288\n",
      "Epoch [135/200], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8116\n",
      "Epoch [136/200], Average Training Loss: 0.4287\n",
      "Epoch [136/200], Average Validation Loss: 0.4324, Average Validation Accuracy: 0.8114\n",
      "Epoch [137/200], Average Training Loss: 0.4286\n",
      "Epoch [137/200], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8116\n",
      "Epoch [138/200], Average Training Loss: 0.4286\n",
      "Epoch [138/200], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8115\n",
      "Epoch [139/200], Average Training Loss: 0.4286\n",
      "Epoch [139/200], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8118\n",
      "Epoch [140/200], Average Training Loss: 0.4286\n",
      "Epoch [140/200], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8114\n",
      "Epoch [141/200], Average Training Loss: 0.4285\n",
      "Epoch [141/200], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8111\n",
      "Epoch [142/200], Average Training Loss: 0.4286\n",
      "Epoch [142/200], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8116\n",
      "Epoch [143/200], Average Training Loss: 0.4285\n",
      "Epoch [143/200], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8115\n",
      "Epoch [144/200], Average Training Loss: 0.4284\n",
      "Epoch [144/200], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8116\n",
      "Epoch [145/200], Average Training Loss: 0.4285\n",
      "Epoch [145/200], Average Validation Loss: 0.4317, Average Validation Accuracy: 0.8117\n",
      "Epoch [146/200], Average Training Loss: 0.4284\n",
      "Epoch [146/200], Average Validation Loss: 0.4317, Average Validation Accuracy: 0.8117\n",
      "Epoch [147/200], Average Training Loss: 0.4284\n",
      "Epoch [147/200], Average Validation Loss: 0.4317, Average Validation Accuracy: 0.8115\n",
      "Epoch [148/200], Average Training Loss: 0.4282\n",
      "Epoch [148/200], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8115\n",
      "Epoch [149/200], Average Training Loss: 0.4282\n",
      "Epoch [149/200], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8116\n",
      "Epoch [150/200], Average Training Loss: 0.4283\n",
      "Epoch [150/200], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8114\n",
      "Epoch [151/200], Average Training Loss: 0.4282\n",
      "Epoch [151/200], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8118\n",
      "Epoch [152/200], Average Training Loss: 0.4283\n",
      "Epoch [152/200], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8113\n",
      "Epoch [153/200], Average Training Loss: 0.4281\n",
      "Epoch [153/200], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8117\n",
      "Epoch [154/200], Average Training Loss: 0.4281\n",
      "Epoch [154/200], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8117\n",
      "Epoch [155/200], Average Training Loss: 0.4280\n",
      "Epoch [155/200], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8114\n",
      "Epoch [156/200], Average Training Loss: 0.4280\n",
      "Epoch [156/200], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8104\n",
      "Epoch [157/200], Average Training Loss: 0.4280\n",
      "Epoch [157/200], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8116\n",
      "Epoch [158/200], Average Training Loss: 0.4280\n",
      "Epoch [158/200], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8116\n",
      "Epoch [159/200], Average Training Loss: 0.4279\n",
      "Epoch [159/200], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8117\n",
      "Epoch [160/200], Average Training Loss: 0.4279\n",
      "Epoch [160/200], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8117\n",
      "Epoch [161/200], Average Training Loss: 0.4280\n",
      "Epoch [161/200], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8119\n",
      "Epoch [162/200], Average Training Loss: 0.4278\n",
      "Epoch [162/200], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8117\n",
      "Epoch [163/200], Average Training Loss: 0.4278\n",
      "Epoch [163/200], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8117\n",
      "Epoch [164/200], Average Training Loss: 0.4279\n",
      "Epoch [164/200], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8118\n",
      "Epoch [165/200], Average Training Loss: 0.4277\n",
      "Epoch [165/200], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8111\n",
      "Epoch [166/200], Average Training Loss: 0.4277\n",
      "Epoch [166/200], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8122\n",
      "Epoch [167/200], Average Training Loss: 0.4277\n",
      "Epoch [167/200], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8104\n",
      "Epoch [168/200], Average Training Loss: 0.4277\n",
      "Epoch [168/200], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8116\n",
      "Epoch [169/200], Average Training Loss: 0.4277\n",
      "Epoch [169/200], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8121\n",
      "Epoch [170/200], Average Training Loss: 0.4276\n",
      "Epoch [170/200], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8115\n",
      "Epoch [171/200], Average Training Loss: 0.4277\n",
      "Epoch [171/200], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8115\n",
      "Epoch [172/200], Average Training Loss: 0.4276\n",
      "Epoch [172/200], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8115\n",
      "Epoch [173/200], Average Training Loss: 0.4276\n",
      "Epoch [173/200], Average Validation Loss: 0.4309, Average Validation Accuracy: 0.8117\n",
      "Epoch [174/200], Average Training Loss: 0.4275\n",
      "Epoch [174/200], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8115\n",
      "Epoch [175/200], Average Training Loss: 0.4275\n",
      "Epoch [175/200], Average Validation Loss: 0.4309, Average Validation Accuracy: 0.8117\n",
      "Epoch [176/200], Average Training Loss: 0.4274\n",
      "Epoch [176/200], Average Validation Loss: 0.4308, Average Validation Accuracy: 0.8120\n",
      "Epoch [177/200], Average Training Loss: 0.4274\n",
      "Epoch [177/200], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8111\n",
      "Epoch [178/200], Average Training Loss: 0.4274\n",
      "Epoch [178/200], Average Validation Loss: 0.4309, Average Validation Accuracy: 0.8116\n",
      "Epoch [179/200], Average Training Loss: 0.4274\n",
      "Epoch [179/200], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8119\n",
      "Epoch [180/200], Average Training Loss: 0.4273\n",
      "Epoch [180/200], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8115\n",
      "Epoch [181/200], Average Training Loss: 0.4274\n",
      "Epoch [181/200], Average Validation Loss: 0.4308, Average Validation Accuracy: 0.8117\n",
      "Epoch [182/200], Average Training Loss: 0.4272\n",
      "Epoch [182/200], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8115\n",
      "Epoch [183/200], Average Training Loss: 0.4271\n",
      "Epoch [183/200], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8118\n",
      "Epoch [184/200], Average Training Loss: 0.4272\n",
      "Epoch [184/200], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8118\n",
      "Epoch [185/200], Average Training Loss: 0.4272\n",
      "Epoch [185/200], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8119\n",
      "Epoch [186/200], Average Training Loss: 0.4271\n",
      "Epoch [186/200], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8117\n",
      "Epoch [187/200], Average Training Loss: 0.4270\n",
      "Epoch [187/200], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8121\n",
      "Epoch [188/200], Average Training Loss: 0.4272\n",
      "Epoch [188/200], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8114\n",
      "Epoch [189/200], Average Training Loss: 0.4271\n",
      "Epoch [189/200], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8115\n",
      "Epoch [190/200], Average Training Loss: 0.4270\n",
      "Epoch [190/200], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8119\n",
      "Epoch [191/200], Average Training Loss: 0.4269\n",
      "Epoch [191/200], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8119\n",
      "Epoch [192/200], Average Training Loss: 0.4268\n",
      "Epoch [192/200], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8116\n",
      "Epoch [193/200], Average Training Loss: 0.4269\n",
      "Epoch [193/200], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8119\n",
      "Epoch [194/200], Average Training Loss: 0.4269\n",
      "Epoch [194/200], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8115\n",
      "Epoch [195/200], Average Training Loss: 0.4268\n",
      "Epoch [195/200], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8119\n",
      "Epoch [196/200], Average Training Loss: 0.4269\n",
      "Epoch [196/200], Average Validation Loss: 0.4302, Average Validation Accuracy: 0.8116\n",
      "Epoch [197/200], Average Training Loss: 0.4268\n",
      "Epoch [197/200], Average Validation Loss: 0.4302, Average Validation Accuracy: 0.8118\n",
      "Epoch [198/200], Average Training Loss: 0.4267\n",
      "Epoch [198/200], Average Validation Loss: 0.4302, Average Validation Accuracy: 0.8123\n",
      "Epoch [199/200], Average Training Loss: 0.4268\n",
      "Epoch [199/200], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8121\n",
      "Epoch [200/200], Average Training Loss: 0.4267\n",
      "Epoch [200/200], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8118\n",
      "Best Validation Accuracy: 0.8123 at epoch 198 for trial 18\n",
      "Epoch [1/500], Average Training Loss: 0.6954\n",
      "Epoch [1/500], Average Validation Loss: 0.6917, Average Validation Accuracy: 0.5046\n",
      "Epoch [2/500], Average Training Loss: 0.6894\n",
      "Epoch [2/500], Average Validation Loss: 0.6864, Average Validation Accuracy: 0.5229\n",
      "Epoch [3/500], Average Training Loss: 0.6839\n",
      "Epoch [3/500], Average Validation Loss: 0.6807, Average Validation Accuracy: 0.6603\n",
      "Epoch [4/500], Average Training Loss: 0.6775\n",
      "Epoch [4/500], Average Validation Loss: 0.6738, Average Validation Accuracy: 0.7431\n",
      "Epoch [5/500], Average Training Loss: 0.6695\n",
      "Epoch [5/500], Average Validation Loss: 0.6647, Average Validation Accuracy: 0.7693\n",
      "Epoch [6/500], Average Training Loss: 0.6588\n",
      "Epoch [6/500], Average Validation Loss: 0.6523, Average Validation Accuracy: 0.7796\n",
      "Epoch [7/500], Average Training Loss: 0.6441\n",
      "Epoch [7/500], Average Validation Loss: 0.6352, Average Validation Accuracy: 0.7821\n",
      "Epoch [8/500], Average Training Loss: 0.6240\n",
      "Epoch [8/500], Average Validation Loss: 0.6120, Average Validation Accuracy: 0.7818\n",
      "Epoch [9/500], Average Training Loss: 0.5975\n",
      "Epoch [9/500], Average Validation Loss: 0.5827, Average Validation Accuracy: 0.7840\n",
      "Epoch [10/500], Average Training Loss: 0.5659\n",
      "Epoch [10/500], Average Validation Loss: 0.5500, Average Validation Accuracy: 0.7846\n",
      "Epoch [11/500], Average Training Loss: 0.5334\n",
      "Epoch [11/500], Average Validation Loss: 0.5194, Average Validation Accuracy: 0.7871\n",
      "Epoch [12/500], Average Training Loss: 0.5056\n",
      "Epoch [12/500], Average Validation Loss: 0.4956, Average Validation Accuracy: 0.7886\n",
      "Epoch [13/500], Average Training Loss: 0.4853\n",
      "Epoch [13/500], Average Validation Loss: 0.4795, Average Validation Accuracy: 0.7902\n",
      "Epoch [14/500], Average Training Loss: 0.4721\n",
      "Epoch [14/500], Average Validation Loss: 0.4696, Average Validation Accuracy: 0.7915\n",
      "Epoch [15/500], Average Training Loss: 0.4639\n",
      "Epoch [15/500], Average Validation Loss: 0.4637, Average Validation Accuracy: 0.7924\n",
      "Epoch [16/500], Average Training Loss: 0.4589\n",
      "Epoch [16/500], Average Validation Loss: 0.4601, Average Validation Accuracy: 0.7933\n",
      "Epoch [17/500], Average Training Loss: 0.4559\n",
      "Epoch [17/500], Average Validation Loss: 0.4578, Average Validation Accuracy: 0.7942\n",
      "Epoch [18/500], Average Training Loss: 0.4539\n",
      "Epoch [18/500], Average Validation Loss: 0.4563, Average Validation Accuracy: 0.7947\n",
      "Epoch [19/500], Average Training Loss: 0.4523\n",
      "Epoch [19/500], Average Validation Loss: 0.4552, Average Validation Accuracy: 0.7953\n",
      "Epoch [20/500], Average Training Loss: 0.4513\n",
      "Epoch [20/500], Average Validation Loss: 0.4543, Average Validation Accuracy: 0.7956\n",
      "Epoch [21/500], Average Training Loss: 0.4504\n",
      "Epoch [21/500], Average Validation Loss: 0.4536, Average Validation Accuracy: 0.7959\n",
      "Epoch [22/500], Average Training Loss: 0.4496\n",
      "Epoch [22/500], Average Validation Loss: 0.4529, Average Validation Accuracy: 0.7957\n",
      "Epoch [23/500], Average Training Loss: 0.4490\n",
      "Epoch [23/500], Average Validation Loss: 0.4523, Average Validation Accuracy: 0.7966\n",
      "Epoch [24/500], Average Training Loss: 0.4484\n",
      "Epoch [24/500], Average Validation Loss: 0.4518, Average Validation Accuracy: 0.7965\n",
      "Epoch [25/500], Average Training Loss: 0.4478\n",
      "Epoch [25/500], Average Validation Loss: 0.4513, Average Validation Accuracy: 0.7964\n",
      "Epoch [26/500], Average Training Loss: 0.4473\n",
      "Epoch [26/500], Average Validation Loss: 0.4507, Average Validation Accuracy: 0.7970\n",
      "Epoch [27/500], Average Training Loss: 0.4469\n",
      "Epoch [27/500], Average Validation Loss: 0.4503, Average Validation Accuracy: 0.7972\n",
      "Epoch [28/500], Average Training Loss: 0.4463\n",
      "Epoch [28/500], Average Validation Loss: 0.4498, Average Validation Accuracy: 0.7974\n",
      "Epoch [29/500], Average Training Loss: 0.4459\n",
      "Epoch [29/500], Average Validation Loss: 0.4494, Average Validation Accuracy: 0.7977\n",
      "Epoch [30/500], Average Training Loss: 0.4454\n",
      "Epoch [30/500], Average Validation Loss: 0.4490, Average Validation Accuracy: 0.7976\n",
      "Epoch [31/500], Average Training Loss: 0.4451\n",
      "Epoch [31/500], Average Validation Loss: 0.4485, Average Validation Accuracy: 0.7984\n",
      "Epoch [32/500], Average Training Loss: 0.4446\n",
      "Epoch [32/500], Average Validation Loss: 0.4482, Average Validation Accuracy: 0.7981\n",
      "Epoch [33/500], Average Training Loss: 0.4444\n",
      "Epoch [33/500], Average Validation Loss: 0.4477, Average Validation Accuracy: 0.7982\n",
      "Epoch [34/500], Average Training Loss: 0.4440\n",
      "Epoch [34/500], Average Validation Loss: 0.4474, Average Validation Accuracy: 0.7988\n",
      "Epoch [35/500], Average Training Loss: 0.4435\n",
      "Epoch [35/500], Average Validation Loss: 0.4470, Average Validation Accuracy: 0.7990\n",
      "Epoch [36/500], Average Training Loss: 0.4432\n",
      "Epoch [36/500], Average Validation Loss: 0.4467, Average Validation Accuracy: 0.7989\n",
      "Epoch [37/500], Average Training Loss: 0.4428\n",
      "Epoch [37/500], Average Validation Loss: 0.4463, Average Validation Accuracy: 0.7991\n",
      "Epoch [38/500], Average Training Loss: 0.4425\n",
      "Epoch [38/500], Average Validation Loss: 0.4459, Average Validation Accuracy: 0.7997\n",
      "Epoch [39/500], Average Training Loss: 0.4421\n",
      "Epoch [39/500], Average Validation Loss: 0.4456, Average Validation Accuracy: 0.7999\n",
      "Epoch [40/500], Average Training Loss: 0.4418\n",
      "Epoch [40/500], Average Validation Loss: 0.4452, Average Validation Accuracy: 0.8000\n",
      "Epoch [41/500], Average Training Loss: 0.4413\n",
      "Epoch [41/500], Average Validation Loss: 0.4449, Average Validation Accuracy: 0.8001\n",
      "Epoch [42/500], Average Training Loss: 0.4410\n",
      "Epoch [42/500], Average Validation Loss: 0.4445, Average Validation Accuracy: 0.8003\n",
      "Epoch [43/500], Average Training Loss: 0.4408\n",
      "Epoch [43/500], Average Validation Loss: 0.4442, Average Validation Accuracy: 0.8003\n",
      "Epoch [44/500], Average Training Loss: 0.4405\n",
      "Epoch [44/500], Average Validation Loss: 0.4439, Average Validation Accuracy: 0.8008\n",
      "Epoch [45/500], Average Training Loss: 0.4403\n",
      "Epoch [45/500], Average Validation Loss: 0.4436, Average Validation Accuracy: 0.8015\n",
      "Epoch [46/500], Average Training Loss: 0.4399\n",
      "Epoch [46/500], Average Validation Loss: 0.4433, Average Validation Accuracy: 0.8011\n",
      "Epoch [47/500], Average Training Loss: 0.4396\n",
      "Epoch [47/500], Average Validation Loss: 0.4430, Average Validation Accuracy: 0.8017\n",
      "Epoch [48/500], Average Training Loss: 0.4393\n",
      "Epoch [48/500], Average Validation Loss: 0.4427, Average Validation Accuracy: 0.8021\n",
      "Epoch [49/500], Average Training Loss: 0.4391\n",
      "Epoch [49/500], Average Validation Loss: 0.4424, Average Validation Accuracy: 0.8023\n",
      "Epoch [50/500], Average Training Loss: 0.4388\n",
      "Epoch [50/500], Average Validation Loss: 0.4421, Average Validation Accuracy: 0.8018\n",
      "Epoch [51/500], Average Training Loss: 0.4384\n",
      "Epoch [51/500], Average Validation Loss: 0.4419, Average Validation Accuracy: 0.8025\n",
      "Epoch [52/500], Average Training Loss: 0.4382\n",
      "Epoch [52/500], Average Validation Loss: 0.4416, Average Validation Accuracy: 0.8026\n",
      "Epoch [53/500], Average Training Loss: 0.4379\n",
      "Epoch [53/500], Average Validation Loss: 0.4413, Average Validation Accuracy: 0.8026\n",
      "Epoch [54/500], Average Training Loss: 0.4376\n",
      "Epoch [54/500], Average Validation Loss: 0.4412, Average Validation Accuracy: 0.8034\n",
      "Epoch [55/500], Average Training Loss: 0.4375\n",
      "Epoch [55/500], Average Validation Loss: 0.4408, Average Validation Accuracy: 0.8032\n",
      "Epoch [56/500], Average Training Loss: 0.4371\n",
      "Epoch [56/500], Average Validation Loss: 0.4405, Average Validation Accuracy: 0.8034\n",
      "Epoch [57/500], Average Training Loss: 0.4369\n",
      "Epoch [57/500], Average Validation Loss: 0.4403, Average Validation Accuracy: 0.8035\n",
      "Epoch [58/500], Average Training Loss: 0.4367\n",
      "Epoch [58/500], Average Validation Loss: 0.4401, Average Validation Accuracy: 0.8035\n",
      "Epoch [59/500], Average Training Loss: 0.4365\n",
      "Epoch [59/500], Average Validation Loss: 0.4398, Average Validation Accuracy: 0.8036\n",
      "Epoch [60/500], Average Training Loss: 0.4362\n",
      "Epoch [60/500], Average Validation Loss: 0.4396, Average Validation Accuracy: 0.8037\n",
      "Epoch [61/500], Average Training Loss: 0.4360\n",
      "Epoch [61/500], Average Validation Loss: 0.4394, Average Validation Accuracy: 0.8044\n",
      "Epoch [62/500], Average Training Loss: 0.4358\n",
      "Epoch [62/500], Average Validation Loss: 0.4392, Average Validation Accuracy: 0.8043\n",
      "Epoch [63/500], Average Training Loss: 0.4356\n",
      "Epoch [63/500], Average Validation Loss: 0.4389, Average Validation Accuracy: 0.8046\n",
      "Epoch [64/500], Average Training Loss: 0.4353\n",
      "Epoch [64/500], Average Validation Loss: 0.4387, Average Validation Accuracy: 0.8051\n",
      "Epoch [65/500], Average Training Loss: 0.4353\n",
      "Epoch [65/500], Average Validation Loss: 0.4385, Average Validation Accuracy: 0.8052\n",
      "Epoch [66/500], Average Training Loss: 0.4349\n",
      "Epoch [66/500], Average Validation Loss: 0.4383, Average Validation Accuracy: 0.8053\n",
      "Epoch [67/500], Average Training Loss: 0.4348\n",
      "Epoch [67/500], Average Validation Loss: 0.4381, Average Validation Accuracy: 0.8056\n",
      "Epoch [68/500], Average Training Loss: 0.4345\n",
      "Epoch [68/500], Average Validation Loss: 0.4384, Average Validation Accuracy: 0.8045\n",
      "Epoch [69/500], Average Training Loss: 0.4343\n",
      "Epoch [69/500], Average Validation Loss: 0.4381, Average Validation Accuracy: 0.8056\n",
      "Epoch [70/500], Average Training Loss: 0.4342\n",
      "Epoch [70/500], Average Validation Loss: 0.4378, Average Validation Accuracy: 0.8050\n",
      "Epoch [71/500], Average Training Loss: 0.4340\n",
      "Epoch [71/500], Average Validation Loss: 0.4373, Average Validation Accuracy: 0.8061\n",
      "Epoch [72/500], Average Training Loss: 0.4338\n",
      "Epoch [72/500], Average Validation Loss: 0.4372, Average Validation Accuracy: 0.8062\n",
      "Epoch [73/500], Average Training Loss: 0.4336\n",
      "Epoch [73/500], Average Validation Loss: 0.4370, Average Validation Accuracy: 0.8064\n",
      "Epoch [74/500], Average Training Loss: 0.4335\n",
      "Epoch [74/500], Average Validation Loss: 0.4368, Average Validation Accuracy: 0.8065\n",
      "Epoch [75/500], Average Training Loss: 0.4334\n",
      "Epoch [75/500], Average Validation Loss: 0.4367, Average Validation Accuracy: 0.8064\n",
      "Epoch [76/500], Average Training Loss: 0.4331\n",
      "Epoch [76/500], Average Validation Loss: 0.4365, Average Validation Accuracy: 0.8066\n",
      "Epoch [77/500], Average Training Loss: 0.4330\n",
      "Epoch [77/500], Average Validation Loss: 0.4363, Average Validation Accuracy: 0.8069\n",
      "Epoch [78/500], Average Training Loss: 0.4329\n",
      "Epoch [78/500], Average Validation Loss: 0.4362, Average Validation Accuracy: 0.8071\n",
      "Epoch [79/500], Average Training Loss: 0.4328\n",
      "Epoch [79/500], Average Validation Loss: 0.4363, Average Validation Accuracy: 0.8068\n",
      "Epoch [80/500], Average Training Loss: 0.4327\n",
      "Epoch [80/500], Average Validation Loss: 0.4360, Average Validation Accuracy: 0.8069\n",
      "Epoch [81/500], Average Training Loss: 0.4324\n",
      "Epoch [81/500], Average Validation Loss: 0.4358, Average Validation Accuracy: 0.8069\n",
      "Epoch [82/500], Average Training Loss: 0.4323\n",
      "Epoch [82/500], Average Validation Loss: 0.4356, Average Validation Accuracy: 0.8074\n",
      "Epoch [83/500], Average Training Loss: 0.4321\n",
      "Epoch [83/500], Average Validation Loss: 0.4355, Average Validation Accuracy: 0.8075\n",
      "Epoch [84/500], Average Training Loss: 0.4321\n",
      "Epoch [84/500], Average Validation Loss: 0.4354, Average Validation Accuracy: 0.8076\n",
      "Epoch [85/500], Average Training Loss: 0.4320\n",
      "Epoch [85/500], Average Validation Loss: 0.4353, Average Validation Accuracy: 0.8077\n",
      "Epoch [86/500], Average Training Loss: 0.4318\n",
      "Epoch [86/500], Average Validation Loss: 0.4351, Average Validation Accuracy: 0.8079\n",
      "Epoch [87/500], Average Training Loss: 0.4317\n",
      "Epoch [87/500], Average Validation Loss: 0.4350, Average Validation Accuracy: 0.8079\n",
      "Epoch [88/500], Average Training Loss: 0.4316\n",
      "Epoch [88/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8084\n",
      "Epoch [89/500], Average Training Loss: 0.4315\n",
      "Epoch [89/500], Average Validation Loss: 0.4349, Average Validation Accuracy: 0.8075\n",
      "Epoch [90/500], Average Training Loss: 0.4315\n",
      "Epoch [90/500], Average Validation Loss: 0.4347, Average Validation Accuracy: 0.8084\n",
      "Epoch [91/500], Average Training Loss: 0.4314\n",
      "Epoch [91/500], Average Validation Loss: 0.4346, Average Validation Accuracy: 0.8081\n",
      "Epoch [92/500], Average Training Loss: 0.4312\n",
      "Epoch [92/500], Average Validation Loss: 0.4345, Average Validation Accuracy: 0.8084\n",
      "Epoch [93/500], Average Training Loss: 0.4312\n",
      "Epoch [93/500], Average Validation Loss: 0.4344, Average Validation Accuracy: 0.8083\n",
      "Epoch [94/500], Average Training Loss: 0.4309\n",
      "Epoch [94/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8088\n",
      "Epoch [95/500], Average Training Loss: 0.4309\n",
      "Epoch [95/500], Average Validation Loss: 0.4343, Average Validation Accuracy: 0.8089\n",
      "Epoch [96/500], Average Training Loss: 0.4308\n",
      "Epoch [96/500], Average Validation Loss: 0.4341, Average Validation Accuracy: 0.8084\n",
      "Epoch [97/500], Average Training Loss: 0.4307\n",
      "Epoch [97/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8081\n",
      "Epoch [98/500], Average Training Loss: 0.4306\n",
      "Epoch [98/500], Average Validation Loss: 0.4340, Average Validation Accuracy: 0.8086\n",
      "Epoch [99/500], Average Training Loss: 0.4306\n",
      "Epoch [99/500], Average Validation Loss: 0.4339, Average Validation Accuracy: 0.8087\n",
      "Epoch [100/500], Average Training Loss: 0.4305\n",
      "Epoch [100/500], Average Validation Loss: 0.4338, Average Validation Accuracy: 0.8085\n",
      "Epoch [101/500], Average Training Loss: 0.4304\n",
      "Epoch [101/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8085\n",
      "Epoch [102/500], Average Training Loss: 0.4305\n",
      "Epoch [102/500], Average Validation Loss: 0.4337, Average Validation Accuracy: 0.8093\n",
      "Epoch [103/500], Average Training Loss: 0.4303\n",
      "Epoch [103/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8093\n",
      "Epoch [104/500], Average Training Loss: 0.4303\n",
      "Epoch [104/500], Average Validation Loss: 0.4336, Average Validation Accuracy: 0.8093\n",
      "Epoch [105/500], Average Training Loss: 0.4301\n",
      "Epoch [105/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8094\n",
      "Epoch [106/500], Average Training Loss: 0.4301\n",
      "Epoch [106/500], Average Validation Loss: 0.4335, Average Validation Accuracy: 0.8097\n",
      "Epoch [107/500], Average Training Loss: 0.4300\n",
      "Epoch [107/500], Average Validation Loss: 0.4334, Average Validation Accuracy: 0.8100\n",
      "Epoch [108/500], Average Training Loss: 0.4300\n",
      "Epoch [108/500], Average Validation Loss: 0.4333, Average Validation Accuracy: 0.8089\n",
      "Epoch [109/500], Average Training Loss: 0.4298\n",
      "Epoch [109/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8094\n",
      "Epoch [110/500], Average Training Loss: 0.4298\n",
      "Epoch [110/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8101\n",
      "Epoch [111/500], Average Training Loss: 0.4299\n",
      "Epoch [111/500], Average Validation Loss: 0.4332, Average Validation Accuracy: 0.8097\n",
      "Epoch [112/500], Average Training Loss: 0.4298\n",
      "Epoch [112/500], Average Validation Loss: 0.4330, Average Validation Accuracy: 0.8102\n",
      "Epoch [113/500], Average Training Loss: 0.4296\n",
      "Epoch [113/500], Average Validation Loss: 0.4330, Average Validation Accuracy: 0.8103\n",
      "Epoch [114/500], Average Training Loss: 0.4297\n",
      "Epoch [114/500], Average Validation Loss: 0.4329, Average Validation Accuracy: 0.8103\n",
      "Epoch [115/500], Average Training Loss: 0.4296\n",
      "Epoch [115/500], Average Validation Loss: 0.4331, Average Validation Accuracy: 0.8105\n",
      "Epoch [116/500], Average Training Loss: 0.4295\n",
      "Epoch [116/500], Average Validation Loss: 0.4328, Average Validation Accuracy: 0.8099\n",
      "Epoch [117/500], Average Training Loss: 0.4293\n",
      "Epoch [117/500], Average Validation Loss: 0.4328, Average Validation Accuracy: 0.8098\n",
      "Epoch [118/500], Average Training Loss: 0.4295\n",
      "Epoch [118/500], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8105\n",
      "Epoch [119/500], Average Training Loss: 0.4294\n",
      "Epoch [119/500], Average Validation Loss: 0.4327, Average Validation Accuracy: 0.8106\n",
      "Epoch [120/500], Average Training Loss: 0.4293\n",
      "Epoch [120/500], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8106\n",
      "Epoch [121/500], Average Training Loss: 0.4293\n",
      "Epoch [121/500], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8105\n",
      "Epoch [122/500], Average Training Loss: 0.4293\n",
      "Epoch [122/500], Average Validation Loss: 0.4326, Average Validation Accuracy: 0.8108\n",
      "Epoch [123/500], Average Training Loss: 0.4292\n",
      "Epoch [123/500], Average Validation Loss: 0.4328, Average Validation Accuracy: 0.8103\n",
      "Epoch [124/500], Average Training Loss: 0.4291\n",
      "Epoch [124/500], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8106\n",
      "Epoch [125/500], Average Training Loss: 0.4290\n",
      "Epoch [125/500], Average Validation Loss: 0.4324, Average Validation Accuracy: 0.8103\n",
      "Epoch [126/500], Average Training Loss: 0.4291\n",
      "Epoch [126/500], Average Validation Loss: 0.4324, Average Validation Accuracy: 0.8107\n",
      "Epoch [127/500], Average Training Loss: 0.4290\n",
      "Epoch [127/500], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8107\n",
      "Epoch [128/500], Average Training Loss: 0.4290\n",
      "Epoch [128/500], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8099\n",
      "Epoch [129/500], Average Training Loss: 0.4290\n",
      "Epoch [129/500], Average Validation Loss: 0.4323, Average Validation Accuracy: 0.8105\n",
      "Epoch [130/500], Average Training Loss: 0.4289\n",
      "Epoch [130/500], Average Validation Loss: 0.4325, Average Validation Accuracy: 0.8101\n",
      "Epoch [131/500], Average Training Loss: 0.4290\n",
      "Epoch [131/500], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8104\n",
      "Epoch [132/500], Average Training Loss: 0.4287\n",
      "Epoch [132/500], Average Validation Loss: 0.4322, Average Validation Accuracy: 0.8106\n",
      "Epoch [133/500], Average Training Loss: 0.4287\n",
      "Epoch [133/500], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8106\n",
      "Epoch [134/500], Average Training Loss: 0.4288\n",
      "Epoch [134/500], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8107\n",
      "Epoch [135/500], Average Training Loss: 0.4288\n",
      "Epoch [135/500], Average Validation Loss: 0.4321, Average Validation Accuracy: 0.8109\n",
      "Epoch [136/500], Average Training Loss: 0.4288\n",
      "Epoch [136/500], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8111\n",
      "Epoch [137/500], Average Training Loss: 0.4287\n",
      "Epoch [137/500], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8111\n",
      "Epoch [138/500], Average Training Loss: 0.4287\n",
      "Epoch [138/500], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8112\n",
      "Epoch [139/500], Average Training Loss: 0.4286\n",
      "Epoch [139/500], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8109\n",
      "Epoch [140/500], Average Training Loss: 0.4287\n",
      "Epoch [140/500], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8113\n",
      "Epoch [141/500], Average Training Loss: 0.4285\n",
      "Epoch [141/500], Average Validation Loss: 0.4320, Average Validation Accuracy: 0.8107\n",
      "Epoch [142/500], Average Training Loss: 0.4285\n",
      "Epoch [142/500], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8109\n",
      "Epoch [143/500], Average Training Loss: 0.4286\n",
      "Epoch [143/500], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8108\n",
      "Epoch [144/500], Average Training Loss: 0.4286\n",
      "Epoch [144/500], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8108\n",
      "Epoch [145/500], Average Training Loss: 0.4284\n",
      "Epoch [145/500], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8112\n",
      "Epoch [146/500], Average Training Loss: 0.4283\n",
      "Epoch [146/500], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8105\n",
      "Epoch [147/500], Average Training Loss: 0.4284\n",
      "Epoch [147/500], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8107\n",
      "Epoch [148/500], Average Training Loss: 0.4284\n",
      "Epoch [148/500], Average Validation Loss: 0.4319, Average Validation Accuracy: 0.8105\n",
      "Epoch [149/500], Average Training Loss: 0.4283\n",
      "Epoch [149/500], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8114\n",
      "Epoch [150/500], Average Training Loss: 0.4283\n",
      "Epoch [150/500], Average Validation Loss: 0.4318, Average Validation Accuracy: 0.8107\n",
      "Epoch [151/500], Average Training Loss: 0.4283\n",
      "Epoch [151/500], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8111\n",
      "Epoch [152/500], Average Training Loss: 0.4283\n",
      "Epoch [152/500], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8112\n",
      "Epoch [153/500], Average Training Loss: 0.4282\n",
      "Epoch [153/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8115\n",
      "Epoch [154/500], Average Training Loss: 0.4281\n",
      "Epoch [154/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8115\n",
      "Epoch [155/500], Average Training Loss: 0.4281\n",
      "Epoch [155/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8115\n",
      "Epoch [156/500], Average Training Loss: 0.4281\n",
      "Epoch [156/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8111\n",
      "Epoch [157/500], Average Training Loss: 0.4281\n",
      "Epoch [157/500], Average Validation Loss: 0.4316, Average Validation Accuracy: 0.8105\n",
      "Epoch [158/500], Average Training Loss: 0.4280\n",
      "Epoch [158/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8111\n",
      "Epoch [159/500], Average Training Loss: 0.4281\n",
      "Epoch [159/500], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8114\n",
      "Epoch [160/500], Average Training Loss: 0.4281\n",
      "Epoch [160/500], Average Validation Loss: 0.4315, Average Validation Accuracy: 0.8111\n",
      "Epoch [161/500], Average Training Loss: 0.4280\n",
      "Epoch [161/500], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8112\n",
      "Epoch [162/500], Average Training Loss: 0.4280\n",
      "Epoch [162/500], Average Validation Loss: 0.4314, Average Validation Accuracy: 0.8109\n",
      "Epoch [163/500], Average Training Loss: 0.4279\n",
      "Epoch [163/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8111\n",
      "Epoch [164/500], Average Training Loss: 0.4278\n",
      "Epoch [164/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8115\n",
      "Epoch [165/500], Average Training Loss: 0.4279\n",
      "Epoch [165/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8114\n",
      "Epoch [166/500], Average Training Loss: 0.4279\n",
      "Epoch [166/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8109\n",
      "Epoch [167/500], Average Training Loss: 0.4279\n",
      "Epoch [167/500], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8112\n",
      "Epoch [168/500], Average Training Loss: 0.4277\n",
      "Epoch [168/500], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8112\n",
      "Epoch [169/500], Average Training Loss: 0.4277\n",
      "Epoch [169/500], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8116\n",
      "Epoch [170/500], Average Training Loss: 0.4277\n",
      "Epoch [170/500], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8115\n",
      "Epoch [171/500], Average Training Loss: 0.4279\n",
      "Epoch [171/500], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8114\n",
      "Epoch [172/500], Average Training Loss: 0.4277\n",
      "Epoch [172/500], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8112\n",
      "Epoch [173/500], Average Training Loss: 0.4276\n",
      "Epoch [173/500], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8116\n",
      "Epoch [174/500], Average Training Loss: 0.4276\n",
      "Epoch [174/500], Average Validation Loss: 0.4312, Average Validation Accuracy: 0.8114\n",
      "Epoch [175/500], Average Training Loss: 0.4276\n",
      "Epoch [175/500], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8112\n",
      "Epoch [176/500], Average Training Loss: 0.4276\n",
      "Epoch [176/500], Average Validation Loss: 0.4311, Average Validation Accuracy: 0.8111\n",
      "Epoch [177/500], Average Training Loss: 0.4275\n",
      "Epoch [177/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8113\n",
      "Epoch [178/500], Average Training Loss: 0.4276\n",
      "Epoch [178/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8113\n",
      "Epoch [179/500], Average Training Loss: 0.4275\n",
      "Epoch [179/500], Average Validation Loss: 0.4313, Average Validation Accuracy: 0.8106\n",
      "Epoch [180/500], Average Training Loss: 0.4275\n",
      "Epoch [180/500], Average Validation Loss: 0.4309, Average Validation Accuracy: 0.8114\n",
      "Epoch [181/500], Average Training Loss: 0.4273\n",
      "Epoch [181/500], Average Validation Loss: 0.4309, Average Validation Accuracy: 0.8118\n",
      "Epoch [182/500], Average Training Loss: 0.4275\n",
      "Epoch [182/500], Average Validation Loss: 0.4309, Average Validation Accuracy: 0.8112\n",
      "Epoch [183/500], Average Training Loss: 0.4274\n",
      "Epoch [183/500], Average Validation Loss: 0.4309, Average Validation Accuracy: 0.8117\n",
      "Epoch [184/500], Average Training Loss: 0.4274\n",
      "Epoch [184/500], Average Validation Loss: 0.4310, Average Validation Accuracy: 0.8112\n",
      "Epoch [185/500], Average Training Loss: 0.4273\n",
      "Epoch [185/500], Average Validation Loss: 0.4308, Average Validation Accuracy: 0.8113\n",
      "Epoch [186/500], Average Training Loss: 0.4274\n",
      "Epoch [186/500], Average Validation Loss: 0.4308, Average Validation Accuracy: 0.8115\n",
      "Epoch [187/500], Average Training Loss: 0.4273\n",
      "Epoch [187/500], Average Validation Loss: 0.4308, Average Validation Accuracy: 0.8118\n",
      "Epoch [188/500], Average Training Loss: 0.4273\n",
      "Epoch [188/500], Average Validation Loss: 0.4308, Average Validation Accuracy: 0.8112\n",
      "Epoch [189/500], Average Training Loss: 0.4272\n",
      "Epoch [189/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8114\n",
      "Epoch [190/500], Average Training Loss: 0.4273\n",
      "Epoch [190/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8115\n",
      "Epoch [191/500], Average Training Loss: 0.4272\n",
      "Epoch [191/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8116\n",
      "Epoch [192/500], Average Training Loss: 0.4271\n",
      "Epoch [192/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8114\n",
      "Epoch [193/500], Average Training Loss: 0.4272\n",
      "Epoch [193/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8115\n",
      "Epoch [194/500], Average Training Loss: 0.4271\n",
      "Epoch [194/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8117\n",
      "Epoch [195/500], Average Training Loss: 0.4271\n",
      "Epoch [195/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8114\n",
      "Epoch [196/500], Average Training Loss: 0.4272\n",
      "Epoch [196/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8112\n",
      "Epoch [197/500], Average Training Loss: 0.4270\n",
      "Epoch [197/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8112\n",
      "Epoch [198/500], Average Training Loss: 0.4270\n",
      "Epoch [198/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8112\n",
      "Epoch [199/500], Average Training Loss: 0.4270\n",
      "Epoch [199/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8118\n",
      "Epoch [200/500], Average Training Loss: 0.4269\n",
      "Epoch [200/500], Average Validation Loss: 0.4307, Average Validation Accuracy: 0.8111\n",
      "Epoch [201/500], Average Training Loss: 0.4269\n",
      "Epoch [201/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8115\n",
      "Epoch [202/500], Average Training Loss: 0.4270\n",
      "Epoch [202/500], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8118\n",
      "Epoch [203/500], Average Training Loss: 0.4270\n",
      "Epoch [203/500], Average Validation Loss: 0.4305, Average Validation Accuracy: 0.8114\n",
      "Epoch [204/500], Average Training Loss: 0.4268\n",
      "Epoch [204/500], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8117\n",
      "Epoch [205/500], Average Training Loss: 0.4268\n",
      "Epoch [205/500], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8117\n",
      "Epoch [206/500], Average Training Loss: 0.4268\n",
      "Epoch [206/500], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8117\n",
      "Epoch [207/500], Average Training Loss: 0.4268\n",
      "Epoch [207/500], Average Validation Loss: 0.4304, Average Validation Accuracy: 0.8116\n",
      "Epoch [208/500], Average Training Loss: 0.4267\n",
      "Epoch [208/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8114\n",
      "Epoch [209/500], Average Training Loss: 0.4266\n",
      "Epoch [209/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8116\n",
      "Epoch [210/500], Average Training Loss: 0.4267\n",
      "Epoch [210/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8118\n",
      "Epoch [211/500], Average Training Loss: 0.4267\n",
      "Epoch [211/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8117\n",
      "Epoch [212/500], Average Training Loss: 0.4266\n",
      "Epoch [212/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8114\n",
      "Epoch [213/500], Average Training Loss: 0.4268\n",
      "Epoch [213/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8116\n",
      "Epoch [214/500], Average Training Loss: 0.4267\n",
      "Epoch [214/500], Average Validation Loss: 0.4302, Average Validation Accuracy: 0.8113\n",
      "Epoch [215/500], Average Training Loss: 0.4267\n",
      "Epoch [215/500], Average Validation Loss: 0.4302, Average Validation Accuracy: 0.8118\n",
      "Epoch [216/500], Average Training Loss: 0.4265\n",
      "Epoch [216/500], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8118\n",
      "Epoch [217/500], Average Training Loss: 0.4266\n",
      "Epoch [217/500], Average Validation Loss: 0.4303, Average Validation Accuracy: 0.8115\n",
      "Epoch [218/500], Average Training Loss: 0.4265\n",
      "Epoch [218/500], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8116\n",
      "Epoch [219/500], Average Training Loss: 0.4266\n",
      "Epoch [219/500], Average Validation Loss: 0.4302, Average Validation Accuracy: 0.8115\n",
      "Epoch [220/500], Average Training Loss: 0.4265\n",
      "Epoch [220/500], Average Validation Loss: 0.4306, Average Validation Accuracy: 0.8121\n",
      "Epoch [221/500], Average Training Loss: 0.4264\n",
      "Epoch [221/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8116\n",
      "Epoch [222/500], Average Training Loss: 0.4265\n",
      "Epoch [222/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8115\n",
      "Epoch [223/500], Average Training Loss: 0.4264\n",
      "Epoch [223/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8118\n",
      "Epoch [224/500], Average Training Loss: 0.4264\n",
      "Epoch [224/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8113\n",
      "Epoch [225/500], Average Training Loss: 0.4263\n",
      "Epoch [225/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8113\n",
      "Epoch [226/500], Average Training Loss: 0.4264\n",
      "Epoch [226/500], Average Validation Loss: 0.4301, Average Validation Accuracy: 0.8118\n",
      "Epoch [227/500], Average Training Loss: 0.4263\n",
      "Epoch [227/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8114\n",
      "Epoch [228/500], Average Training Loss: 0.4263\n",
      "Epoch [228/500], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8117\n",
      "Epoch [229/500], Average Training Loss: 0.4262\n",
      "Epoch [229/500], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8115\n",
      "Epoch [230/500], Average Training Loss: 0.4263\n",
      "Epoch [230/500], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8119\n",
      "Epoch [231/500], Average Training Loss: 0.4262\n",
      "Epoch [231/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8118\n",
      "Epoch [232/500], Average Training Loss: 0.4262\n",
      "Epoch [232/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8120\n",
      "Epoch [233/500], Average Training Loss: 0.4262\n",
      "Epoch [233/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8118\n",
      "Epoch [234/500], Average Training Loss: 0.4261\n",
      "Epoch [234/500], Average Validation Loss: 0.4299, Average Validation Accuracy: 0.8117\n",
      "Epoch [235/500], Average Training Loss: 0.4262\n",
      "Epoch [235/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8120\n",
      "Epoch [236/500], Average Training Loss: 0.4262\n",
      "Epoch [236/500], Average Validation Loss: 0.4298, Average Validation Accuracy: 0.8115\n",
      "Epoch [237/500], Average Training Loss: 0.4260\n",
      "Epoch [237/500], Average Validation Loss: 0.4297, Average Validation Accuracy: 0.8119\n",
      "Epoch [238/500], Average Training Loss: 0.4260\n",
      "Epoch [238/500], Average Validation Loss: 0.4300, Average Validation Accuracy: 0.8114\n",
      "Epoch [239/500], Average Training Loss: 0.4261\n",
      "Epoch [239/500], Average Validation Loss: 0.4297, Average Validation Accuracy: 0.8118\n",
      "Epoch [240/500], Average Training Loss: 0.4260\n",
      "Epoch [240/500], Average Validation Loss: 0.4297, Average Validation Accuracy: 0.8117\n",
      "Epoch [241/500], Average Training Loss: 0.4260\n",
      "Epoch [241/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8121\n",
      "Epoch [242/500], Average Training Loss: 0.4259\n",
      "Epoch [242/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8117\n",
      "Epoch [243/500], Average Training Loss: 0.4259\n",
      "Epoch [243/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8117\n",
      "Epoch [244/500], Average Training Loss: 0.4260\n",
      "Epoch [244/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8117\n",
      "Epoch [245/500], Average Training Loss: 0.4259\n",
      "Epoch [245/500], Average Validation Loss: 0.4297, Average Validation Accuracy: 0.8118\n",
      "Epoch [246/500], Average Training Loss: 0.4258\n",
      "Epoch [246/500], Average Validation Loss: 0.4295, Average Validation Accuracy: 0.8118\n",
      "Epoch [247/500], Average Training Loss: 0.4258\n",
      "Epoch [247/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8117\n",
      "Epoch [248/500], Average Training Loss: 0.4258\n",
      "Epoch [248/500], Average Validation Loss: 0.4295, Average Validation Accuracy: 0.8120\n",
      "Epoch [249/500], Average Training Loss: 0.4258\n",
      "Epoch [249/500], Average Validation Loss: 0.4296, Average Validation Accuracy: 0.8116\n",
      "Epoch [250/500], Average Training Loss: 0.4257\n",
      "Epoch [250/500], Average Validation Loss: 0.4295, Average Validation Accuracy: 0.8118\n",
      "Epoch [251/500], Average Training Loss: 0.4258\n",
      "Epoch [251/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8118\n",
      "Epoch [252/500], Average Training Loss: 0.4258\n",
      "Epoch [252/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8121\n",
      "Epoch [253/500], Average Training Loss: 0.4257\n",
      "Epoch [253/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8120\n",
      "Epoch [254/500], Average Training Loss: 0.4256\n",
      "Epoch [254/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8116\n",
      "Epoch [255/500], Average Training Loss: 0.4256\n",
      "Epoch [255/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8120\n",
      "Epoch [256/500], Average Training Loss: 0.4256\n",
      "Epoch [256/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8115\n",
      "Epoch [257/500], Average Training Loss: 0.4256\n",
      "Epoch [257/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8117\n",
      "Epoch [258/500], Average Training Loss: 0.4257\n",
      "Epoch [258/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8122\n",
      "Epoch [259/500], Average Training Loss: 0.4256\n",
      "Epoch [259/500], Average Validation Loss: 0.4294, Average Validation Accuracy: 0.8118\n",
      "Epoch [260/500], Average Training Loss: 0.4255\n",
      "Epoch [260/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8121\n",
      "Epoch [261/500], Average Training Loss: 0.4255\n",
      "Epoch [261/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8123\n",
      "Epoch [262/500], Average Training Loss: 0.4255\n",
      "Epoch [262/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8122\n",
      "Epoch [263/500], Average Training Loss: 0.4255\n",
      "Epoch [263/500], Average Validation Loss: 0.4293, Average Validation Accuracy: 0.8119\n",
      "Epoch [264/500], Average Training Loss: 0.4254\n",
      "Epoch [264/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8122\n",
      "Epoch [265/500], Average Training Loss: 0.4255\n",
      "Epoch [265/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8117\n",
      "Epoch [266/500], Average Training Loss: 0.4253\n",
      "Epoch [266/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8124\n",
      "Epoch [267/500], Average Training Loss: 0.4253\n",
      "Epoch [267/500], Average Validation Loss: 0.4292, Average Validation Accuracy: 0.8123\n",
      "Epoch [268/500], Average Training Loss: 0.4253\n",
      "Epoch [268/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8123\n",
      "Epoch [269/500], Average Training Loss: 0.4253\n",
      "Epoch [269/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8118\n",
      "Epoch [270/500], Average Training Loss: 0.4254\n",
      "Epoch [270/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8119\n",
      "Epoch [271/500], Average Training Loss: 0.4251\n",
      "Epoch [271/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8122\n",
      "Epoch [272/500], Average Training Loss: 0.4253\n",
      "Epoch [272/500], Average Validation Loss: 0.4291, Average Validation Accuracy: 0.8116\n",
      "Epoch [273/500], Average Training Loss: 0.4251\n",
      "Epoch [273/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8118\n",
      "Epoch [274/500], Average Training Loss: 0.4251\n",
      "Epoch [274/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8118\n",
      "Epoch [275/500], Average Training Loss: 0.4250\n",
      "Epoch [275/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8121\n",
      "Epoch [276/500], Average Training Loss: 0.4251\n",
      "Epoch [276/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8121\n",
      "Epoch [277/500], Average Training Loss: 0.4250\n",
      "Epoch [277/500], Average Validation Loss: 0.4289, Average Validation Accuracy: 0.8119\n",
      "Epoch [278/500], Average Training Loss: 0.4250\n",
      "Epoch [278/500], Average Validation Loss: 0.4289, Average Validation Accuracy: 0.8118\n",
      "Epoch [279/500], Average Training Loss: 0.4251\n",
      "Epoch [279/500], Average Validation Loss: 0.4290, Average Validation Accuracy: 0.8123\n",
      "Epoch [280/500], Average Training Loss: 0.4250\n",
      "Epoch [280/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8118\n",
      "Epoch [281/500], Average Training Loss: 0.4249\n",
      "Epoch [281/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8118\n",
      "Epoch [282/500], Average Training Loss: 0.4249\n",
      "Epoch [282/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8121\n",
      "Epoch [283/500], Average Training Loss: 0.4249\n",
      "Epoch [283/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8118\n",
      "Epoch [284/500], Average Training Loss: 0.4250\n",
      "Epoch [284/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8121\n",
      "Epoch [285/500], Average Training Loss: 0.4247\n",
      "Epoch [285/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8119\n",
      "Epoch [286/500], Average Training Loss: 0.4248\n",
      "Epoch [286/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8124\n",
      "Epoch [287/500], Average Training Loss: 0.4248\n",
      "Epoch [287/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8119\n",
      "Epoch [288/500], Average Training Loss: 0.4249\n",
      "Epoch [288/500], Average Validation Loss: 0.4286, Average Validation Accuracy: 0.8124\n",
      "Epoch [289/500], Average Training Loss: 0.4247\n",
      "Epoch [289/500], Average Validation Loss: 0.4286, Average Validation Accuracy: 0.8119\n",
      "Epoch [290/500], Average Training Loss: 0.4248\n",
      "Epoch [290/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8123\n",
      "Epoch [291/500], Average Training Loss: 0.4247\n",
      "Epoch [291/500], Average Validation Loss: 0.4288, Average Validation Accuracy: 0.8117\n",
      "Epoch [292/500], Average Training Loss: 0.4245\n",
      "Epoch [292/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8121\n",
      "Epoch [293/500], Average Training Loss: 0.4246\n",
      "Epoch [293/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8120\n",
      "Epoch [294/500], Average Training Loss: 0.4247\n",
      "Epoch [294/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8122\n",
      "Epoch [295/500], Average Training Loss: 0.4246\n",
      "Epoch [295/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8122\n",
      "Epoch [296/500], Average Training Loss: 0.4245\n",
      "Epoch [296/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8121\n",
      "Epoch [297/500], Average Training Loss: 0.4245\n",
      "Epoch [297/500], Average Validation Loss: 0.4284, Average Validation Accuracy: 0.8122\n",
      "Epoch [298/500], Average Training Loss: 0.4246\n",
      "Epoch [298/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8125\n",
      "Epoch [299/500], Average Training Loss: 0.4246\n",
      "Epoch [299/500], Average Validation Loss: 0.4286, Average Validation Accuracy: 0.8123\n",
      "Epoch [300/500], Average Training Loss: 0.4244\n",
      "Epoch [300/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8123\n",
      "Epoch [301/500], Average Training Loss: 0.4244\n",
      "Epoch [301/500], Average Validation Loss: 0.4285, Average Validation Accuracy: 0.8119\n",
      "Epoch [302/500], Average Training Loss: 0.4244\n",
      "Epoch [302/500], Average Validation Loss: 0.4284, Average Validation Accuracy: 0.8125\n",
      "Epoch [303/500], Average Training Loss: 0.4245\n",
      "Epoch [303/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8119\n",
      "Epoch [304/500], Average Training Loss: 0.4244\n",
      "Epoch [304/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8123\n",
      "Epoch [305/500], Average Training Loss: 0.4244\n",
      "Epoch [305/500], Average Validation Loss: 0.4283, Average Validation Accuracy: 0.8119\n",
      "Epoch [306/500], Average Training Loss: 0.4243\n",
      "Epoch [306/500], Average Validation Loss: 0.4282, Average Validation Accuracy: 0.8119\n",
      "Epoch [307/500], Average Training Loss: 0.4243\n",
      "Epoch [307/500], Average Validation Loss: 0.4282, Average Validation Accuracy: 0.8119\n",
      "Epoch [308/500], Average Training Loss: 0.4242\n",
      "Epoch [308/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8121\n",
      "Epoch [309/500], Average Training Loss: 0.4242\n",
      "Epoch [309/500], Average Validation Loss: 0.4282, Average Validation Accuracy: 0.8124\n",
      "Epoch [310/500], Average Training Loss: 0.4242\n",
      "Epoch [310/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8126\n",
      "Epoch [311/500], Average Training Loss: 0.4240\n",
      "Epoch [311/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8123\n",
      "Epoch [312/500], Average Training Loss: 0.4241\n",
      "Epoch [312/500], Average Validation Loss: 0.4280, Average Validation Accuracy: 0.8123\n",
      "Epoch [313/500], Average Training Loss: 0.4241\n",
      "Epoch [313/500], Average Validation Loss: 0.4280, Average Validation Accuracy: 0.8123\n",
      "Epoch [314/500], Average Training Loss: 0.4241\n",
      "Epoch [314/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8125\n",
      "Epoch [315/500], Average Training Loss: 0.4240\n",
      "Epoch [315/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8122\n",
      "Epoch [316/500], Average Training Loss: 0.4240\n",
      "Epoch [316/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8122\n",
      "Epoch [317/500], Average Training Loss: 0.4239\n",
      "Epoch [317/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8123\n",
      "Epoch [318/500], Average Training Loss: 0.4239\n",
      "Epoch [318/500], Average Validation Loss: 0.4279, Average Validation Accuracy: 0.8121\n",
      "Epoch [319/500], Average Training Loss: 0.4238\n",
      "Epoch [319/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8126\n",
      "Epoch [320/500], Average Training Loss: 0.4238\n",
      "Epoch [320/500], Average Validation Loss: 0.4280, Average Validation Accuracy: 0.8119\n",
      "Epoch [321/500], Average Training Loss: 0.4238\n",
      "Epoch [321/500], Average Validation Loss: 0.4281, Average Validation Accuracy: 0.8120\n",
      "Epoch [322/500], Average Training Loss: 0.4238\n",
      "Epoch [322/500], Average Validation Loss: 0.4287, Average Validation Accuracy: 0.8112\n",
      "Epoch [323/500], Average Training Loss: 0.4238\n",
      "Epoch [323/500], Average Validation Loss: 0.4278, Average Validation Accuracy: 0.8123\n",
      "Epoch [324/500], Average Training Loss: 0.4239\n",
      "Epoch [324/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8123\n",
      "Epoch [325/500], Average Training Loss: 0.4238\n",
      "Epoch [325/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8122\n",
      "Epoch [326/500], Average Training Loss: 0.4237\n",
      "Epoch [326/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8126\n",
      "Epoch [327/500], Average Training Loss: 0.4236\n",
      "Epoch [327/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8124\n",
      "Epoch [328/500], Average Training Loss: 0.4236\n",
      "Epoch [328/500], Average Validation Loss: 0.4277, Average Validation Accuracy: 0.8131\n",
      "Epoch [329/500], Average Training Loss: 0.4236\n",
      "Epoch [329/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8126\n",
      "Epoch [330/500], Average Training Loss: 0.4236\n",
      "Epoch [330/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8118\n",
      "Epoch [331/500], Average Training Loss: 0.4236\n",
      "Epoch [331/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8122\n",
      "Epoch [332/500], Average Training Loss: 0.4235\n",
      "Epoch [332/500], Average Validation Loss: 0.4276, Average Validation Accuracy: 0.8118\n",
      "Epoch [333/500], Average Training Loss: 0.4235\n",
      "Epoch [333/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8122\n",
      "Epoch [334/500], Average Training Loss: 0.4234\n",
      "Epoch [334/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8132\n",
      "Epoch [335/500], Average Training Loss: 0.4234\n",
      "Epoch [335/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8120\n",
      "Epoch [336/500], Average Training Loss: 0.4234\n",
      "Epoch [336/500], Average Validation Loss: 0.4275, Average Validation Accuracy: 0.8121\n",
      "Epoch [337/500], Average Training Loss: 0.4234\n",
      "Epoch [337/500], Average Validation Loss: 0.4274, Average Validation Accuracy: 0.8122\n",
      "Epoch [338/500], Average Training Loss: 0.4233\n",
      "Epoch [338/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8126\n",
      "Epoch [339/500], Average Training Loss: 0.4233\n",
      "Epoch [339/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8124\n",
      "Epoch [340/500], Average Training Loss: 0.4234\n",
      "Epoch [340/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8123\n",
      "Epoch [341/500], Average Training Loss: 0.4233\n",
      "Epoch [341/500], Average Validation Loss: 0.4274, Average Validation Accuracy: 0.8131\n",
      "Epoch [342/500], Average Training Loss: 0.4231\n",
      "Epoch [342/500], Average Validation Loss: 0.4272, Average Validation Accuracy: 0.8123\n",
      "Epoch [343/500], Average Training Loss: 0.4232\n",
      "Epoch [343/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8117\n",
      "Epoch [344/500], Average Training Loss: 0.4233\n",
      "Epoch [344/500], Average Validation Loss: 0.4272, Average Validation Accuracy: 0.8125\n",
      "Epoch [345/500], Average Training Loss: 0.4231\n",
      "Epoch [345/500], Average Validation Loss: 0.4272, Average Validation Accuracy: 0.8132\n",
      "Epoch [346/500], Average Training Loss: 0.4232\n",
      "Epoch [346/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8128\n",
      "Epoch [347/500], Average Training Loss: 0.4231\n",
      "Epoch [347/500], Average Validation Loss: 0.4273, Average Validation Accuracy: 0.8131\n",
      "Epoch [348/500], Average Training Loss: 0.4230\n",
      "Epoch [348/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8121\n",
      "Epoch [349/500], Average Training Loss: 0.4230\n",
      "Epoch [349/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8118\n",
      "Epoch [350/500], Average Training Loss: 0.4230\n",
      "Epoch [350/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8118\n",
      "Epoch [351/500], Average Training Loss: 0.4229\n",
      "Epoch [351/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8126\n",
      "Epoch [352/500], Average Training Loss: 0.4229\n",
      "Epoch [352/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8127\n",
      "Epoch [353/500], Average Training Loss: 0.4227\n",
      "Epoch [353/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8123\n",
      "Epoch [354/500], Average Training Loss: 0.4228\n",
      "Epoch [354/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8126\n",
      "Epoch [355/500], Average Training Loss: 0.4227\n",
      "Epoch [355/500], Average Validation Loss: 0.4271, Average Validation Accuracy: 0.8121\n",
      "Epoch [356/500], Average Training Loss: 0.4228\n",
      "Epoch [356/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8133\n",
      "Epoch [357/500], Average Training Loss: 0.4227\n",
      "Epoch [357/500], Average Validation Loss: 0.4268, Average Validation Accuracy: 0.8130\n",
      "Epoch [358/500], Average Training Loss: 0.4227\n",
      "Epoch [358/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8120\n",
      "Epoch [359/500], Average Training Loss: 0.4228\n",
      "Epoch [359/500], Average Validation Loss: 0.4268, Average Validation Accuracy: 0.8128\n",
      "Epoch [360/500], Average Training Loss: 0.4226\n",
      "Epoch [360/500], Average Validation Loss: 0.4269, Average Validation Accuracy: 0.8120\n",
      "Epoch [361/500], Average Training Loss: 0.4226\n",
      "Epoch [361/500], Average Validation Loss: 0.4270, Average Validation Accuracy: 0.8121\n",
      "Epoch [362/500], Average Training Loss: 0.4226\n",
      "Epoch [362/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8123\n",
      "Epoch [363/500], Average Training Loss: 0.4225\n",
      "Epoch [363/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8123\n",
      "Epoch [364/500], Average Training Loss: 0.4225\n",
      "Epoch [364/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8128\n",
      "Epoch [365/500], Average Training Loss: 0.4225\n",
      "Epoch [365/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8121\n",
      "Epoch [366/500], Average Training Loss: 0.4225\n",
      "Epoch [366/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8131\n",
      "Epoch [367/500], Average Training Loss: 0.4224\n",
      "Epoch [367/500], Average Validation Loss: 0.4267, Average Validation Accuracy: 0.8118\n",
      "Epoch [368/500], Average Training Loss: 0.4224\n",
      "Epoch [368/500], Average Validation Loss: 0.4266, Average Validation Accuracy: 0.8122\n",
      "Epoch [369/500], Average Training Loss: 0.4224\n",
      "Epoch [369/500], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8132\n",
      "Epoch [370/500], Average Training Loss: 0.4223\n",
      "Epoch [370/500], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8120\n",
      "Epoch [371/500], Average Training Loss: 0.4223\n",
      "Epoch [371/500], Average Validation Loss: 0.4265, Average Validation Accuracy: 0.8121\n",
      "Epoch [372/500], Average Training Loss: 0.4223\n",
      "Epoch [372/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8120\n",
      "Epoch [373/500], Average Training Loss: 0.4222\n",
      "Epoch [373/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8124\n",
      "Epoch [374/500], Average Training Loss: 0.4223\n",
      "Epoch [374/500], Average Validation Loss: 0.4264, Average Validation Accuracy: 0.8132\n",
      "Epoch [375/500], Average Training Loss: 0.4221\n",
      "Epoch [375/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8124\n",
      "Epoch [376/500], Average Training Loss: 0.4221\n",
      "Epoch [376/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8130\n",
      "Epoch [377/500], Average Training Loss: 0.4221\n",
      "Epoch [377/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8123\n",
      "Epoch [378/500], Average Training Loss: 0.4220\n",
      "Epoch [378/500], Average Validation Loss: 0.4263, Average Validation Accuracy: 0.8134\n",
      "Epoch [379/500], Average Training Loss: 0.4221\n",
      "Epoch [379/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8135\n",
      "Epoch [380/500], Average Training Loss: 0.4220\n",
      "Epoch [380/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8124\n",
      "Epoch [381/500], Average Training Loss: 0.4220\n",
      "Epoch [381/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8125\n",
      "Epoch [382/500], Average Training Loss: 0.4219\n",
      "Epoch [382/500], Average Validation Loss: 0.4262, Average Validation Accuracy: 0.8134\n",
      "Epoch [383/500], Average Training Loss: 0.4219\n",
      "Epoch [383/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8131\n",
      "Epoch [384/500], Average Training Loss: 0.4218\n",
      "Epoch [384/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8130\n",
      "Epoch [385/500], Average Training Loss: 0.4218\n",
      "Epoch [385/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8126\n",
      "Epoch [386/500], Average Training Loss: 0.4219\n",
      "Epoch [386/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8127\n",
      "Epoch [387/500], Average Training Loss: 0.4218\n",
      "Epoch [387/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8125\n",
      "Epoch [388/500], Average Training Loss: 0.4218\n",
      "Epoch [388/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8126\n",
      "Epoch [389/500], Average Training Loss: 0.4217\n",
      "Epoch [389/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8125\n",
      "Epoch [390/500], Average Training Loss: 0.4217\n",
      "Epoch [390/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8126\n",
      "Epoch [391/500], Average Training Loss: 0.4215\n",
      "Epoch [391/500], Average Validation Loss: 0.4261, Average Validation Accuracy: 0.8131\n",
      "Epoch [392/500], Average Training Loss: 0.4217\n",
      "Epoch [392/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8134\n",
      "Epoch [393/500], Average Training Loss: 0.4216\n",
      "Epoch [393/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8128\n",
      "Epoch [394/500], Average Training Loss: 0.4216\n",
      "Epoch [394/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8131\n",
      "Epoch [395/500], Average Training Loss: 0.4216\n",
      "Epoch [395/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8127\n",
      "Epoch [396/500], Average Training Loss: 0.4215\n",
      "Epoch [396/500], Average Validation Loss: 0.4259, Average Validation Accuracy: 0.8135\n",
      "Epoch [397/500], Average Training Loss: 0.4214\n",
      "Epoch [397/500], Average Validation Loss: 0.4260, Average Validation Accuracy: 0.8119\n",
      "Epoch [398/500], Average Training Loss: 0.4214\n",
      "Epoch [398/500], Average Validation Loss: 0.4258, Average Validation Accuracy: 0.8125\n",
      "Epoch [399/500], Average Training Loss: 0.4214\n",
      "Epoch [399/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8132\n",
      "Epoch [400/500], Average Training Loss: 0.4214\n",
      "Epoch [400/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8135\n",
      "Epoch [401/500], Average Training Loss: 0.4213\n",
      "Epoch [401/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8129\n",
      "Epoch [402/500], Average Training Loss: 0.4213\n",
      "Epoch [402/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8129\n",
      "Epoch [403/500], Average Training Loss: 0.4214\n",
      "Epoch [403/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8128\n",
      "Epoch [404/500], Average Training Loss: 0.4212\n",
      "Epoch [404/500], Average Validation Loss: 0.4255, Average Validation Accuracy: 0.8128\n",
      "Epoch [405/500], Average Training Loss: 0.4212\n",
      "Epoch [405/500], Average Validation Loss: 0.4256, Average Validation Accuracy: 0.8134\n",
      "Epoch [406/500], Average Training Loss: 0.4213\n",
      "Epoch [406/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8126\n",
      "Epoch [407/500], Average Training Loss: 0.4211\n",
      "Epoch [407/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8127\n",
      "Epoch [408/500], Average Training Loss: 0.4211\n",
      "Epoch [408/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8131\n",
      "Epoch [409/500], Average Training Loss: 0.4209\n",
      "Epoch [409/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8135\n",
      "Epoch [410/500], Average Training Loss: 0.4210\n",
      "Epoch [410/500], Average Validation Loss: 0.4257, Average Validation Accuracy: 0.8124\n",
      "Epoch [411/500], Average Training Loss: 0.4210\n",
      "Epoch [411/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8124\n",
      "Epoch [412/500], Average Training Loss: 0.4210\n",
      "Epoch [412/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8125\n",
      "Epoch [413/500], Average Training Loss: 0.4211\n",
      "Epoch [413/500], Average Validation Loss: 0.4253, Average Validation Accuracy: 0.8135\n",
      "Epoch [414/500], Average Training Loss: 0.4209\n",
      "Epoch [414/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8127\n",
      "Epoch [415/500], Average Training Loss: 0.4208\n",
      "Epoch [415/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8127\n",
      "Epoch [416/500], Average Training Loss: 0.4209\n",
      "Epoch [416/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8128\n",
      "Epoch [417/500], Average Training Loss: 0.4210\n",
      "Epoch [417/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8125\n",
      "Epoch [418/500], Average Training Loss: 0.4208\n",
      "Epoch [418/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8131\n",
      "Epoch [419/500], Average Training Loss: 0.4208\n",
      "Epoch [419/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8126\n",
      "Epoch [420/500], Average Training Loss: 0.4207\n",
      "Epoch [420/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8133\n",
      "Epoch [421/500], Average Training Loss: 0.4206\n",
      "Epoch [421/500], Average Validation Loss: 0.4252, Average Validation Accuracy: 0.8133\n",
      "Epoch [422/500], Average Training Loss: 0.4207\n",
      "Epoch [422/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8132\n",
      "Epoch [423/500], Average Training Loss: 0.4206\n",
      "Epoch [423/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8135\n",
      "Epoch [424/500], Average Training Loss: 0.4207\n",
      "Epoch [424/500], Average Validation Loss: 0.4249, Average Validation Accuracy: 0.8131\n",
      "Epoch [425/500], Average Training Loss: 0.4205\n",
      "Epoch [425/500], Average Validation Loss: 0.4251, Average Validation Accuracy: 0.8126\n",
      "Epoch [426/500], Average Training Loss: 0.4206\n",
      "Epoch [426/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8131\n",
      "Epoch [427/500], Average Training Loss: 0.4206\n",
      "Epoch [427/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8131\n",
      "Epoch [428/500], Average Training Loss: 0.4205\n",
      "Epoch [428/500], Average Validation Loss: 0.4250, Average Validation Accuracy: 0.8133\n",
      "Epoch [429/500], Average Training Loss: 0.4205\n",
      "Epoch [429/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8132\n",
      "Epoch [430/500], Average Training Loss: 0.4203\n",
      "Epoch [430/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8126\n",
      "Epoch [431/500], Average Training Loss: 0.4203\n",
      "Epoch [431/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8131\n",
      "Epoch [432/500], Average Training Loss: 0.4204\n",
      "Epoch [432/500], Average Validation Loss: 0.4247, Average Validation Accuracy: 0.8127\n",
      "Epoch [433/500], Average Training Loss: 0.4204\n",
      "Epoch [433/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8129\n",
      "Epoch [434/500], Average Training Loss: 0.4204\n",
      "Epoch [434/500], Average Validation Loss: 0.4254, Average Validation Accuracy: 0.8127\n",
      "Epoch [435/500], Average Training Loss: 0.4203\n",
      "Epoch [435/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8131\n",
      "Epoch [436/500], Average Training Loss: 0.4203\n",
      "Epoch [436/500], Average Validation Loss: 0.4248, Average Validation Accuracy: 0.8127\n",
      "Epoch [437/500], Average Training Loss: 0.4203\n",
      "Epoch [437/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8132\n",
      "Epoch [438/500], Average Training Loss: 0.4204\n",
      "Epoch [438/500], Average Validation Loss: 0.4246, Average Validation Accuracy: 0.8130\n",
      "Epoch [439/500], Average Training Loss: 0.4202\n",
      "Epoch [439/500], Average Validation Loss: 0.4245, Average Validation Accuracy: 0.8132\n",
      "Epoch [440/500], Average Training Loss: 0.4202\n",
      "Epoch [440/500], Average Validation Loss: 0.4245, Average Validation Accuracy: 0.8131\n",
      "Epoch [441/500], Average Training Loss: 0.4201\n",
      "Epoch [441/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8130\n",
      "Epoch [442/500], Average Training Loss: 0.4201\n",
      "Epoch [442/500], Average Validation Loss: 0.4245, Average Validation Accuracy: 0.8129\n",
      "Epoch [443/500], Average Training Loss: 0.4200\n",
      "Epoch [443/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8132\n",
      "Epoch [444/500], Average Training Loss: 0.4201\n",
      "Epoch [444/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8132\n",
      "Epoch [445/500], Average Training Loss: 0.4200\n",
      "Epoch [445/500], Average Validation Loss: 0.4244, Average Validation Accuracy: 0.8133\n",
      "Epoch [446/500], Average Training Loss: 0.4200\n",
      "Epoch [446/500], Average Validation Loss: 0.4245, Average Validation Accuracy: 0.8126\n",
      "Epoch [447/500], Average Training Loss: 0.4199\n",
      "Epoch [447/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8132\n",
      "Epoch [448/500], Average Training Loss: 0.4200\n",
      "Epoch [448/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8129\n",
      "Epoch [449/500], Average Training Loss: 0.4200\n",
      "Epoch [449/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8133\n",
      "Epoch [450/500], Average Training Loss: 0.4197\n",
      "Epoch [450/500], Average Validation Loss: 0.4243, Average Validation Accuracy: 0.8130\n",
      "Epoch [451/500], Average Training Loss: 0.4198\n",
      "Epoch [451/500], Average Validation Loss: 0.4242, Average Validation Accuracy: 0.8130\n",
      "Epoch [452/500], Average Training Loss: 0.4199\n",
      "Epoch [452/500], Average Validation Loss: 0.4245, Average Validation Accuracy: 0.8127\n",
      "Epoch [453/500], Average Training Loss: 0.4198\n",
      "Epoch [453/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8133\n",
      "Epoch [454/500], Average Training Loss: 0.4198\n",
      "Epoch [454/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8132\n",
      "Epoch [455/500], Average Training Loss: 0.4198\n",
      "Epoch [455/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8135\n",
      "Epoch [456/500], Average Training Loss: 0.4197\n",
      "Epoch [456/500], Average Validation Loss: 0.4242, Average Validation Accuracy: 0.8135\n",
      "Epoch [457/500], Average Training Loss: 0.4197\n",
      "Epoch [457/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8134\n",
      "Epoch [458/500], Average Training Loss: 0.4198\n",
      "Epoch [458/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8134\n",
      "Epoch [459/500], Average Training Loss: 0.4196\n",
      "Epoch [459/500], Average Validation Loss: 0.4241, Average Validation Accuracy: 0.8131\n",
      "Epoch [460/500], Average Training Loss: 0.4196\n",
      "Epoch [460/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8136\n",
      "Epoch [461/500], Average Training Loss: 0.4196\n",
      "Epoch [461/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8133\n",
      "Epoch [462/500], Average Training Loss: 0.4195\n",
      "Epoch [462/500], Average Validation Loss: 0.4245, Average Validation Accuracy: 0.8131\n",
      "Epoch [463/500], Average Training Loss: 0.4195\n",
      "Epoch [463/500], Average Validation Loss: 0.4240, Average Validation Accuracy: 0.8133\n",
      "Epoch [464/500], Average Training Loss: 0.4195\n",
      "Epoch [464/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8133\n",
      "Epoch [465/500], Average Training Loss: 0.4194\n",
      "Epoch [465/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8134\n",
      "Epoch [466/500], Average Training Loss: 0.4196\n",
      "Epoch [466/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8135\n",
      "Epoch [467/500], Average Training Loss: 0.4196\n",
      "Epoch [467/500], Average Validation Loss: 0.4239, Average Validation Accuracy: 0.8132\n",
      "Epoch [468/500], Average Training Loss: 0.4195\n",
      "Epoch [468/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8135\n",
      "Epoch [469/500], Average Training Loss: 0.4193\n",
      "Epoch [469/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8132\n",
      "Epoch [470/500], Average Training Loss: 0.4194\n",
      "Epoch [470/500], Average Validation Loss: 0.4237, Average Validation Accuracy: 0.8138\n",
      "Epoch [471/500], Average Training Loss: 0.4194\n",
      "Epoch [471/500], Average Validation Loss: 0.4237, Average Validation Accuracy: 0.8136\n",
      "Epoch [472/500], Average Training Loss: 0.4193\n",
      "Epoch [472/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8135\n",
      "Epoch [473/500], Average Training Loss: 0.4193\n",
      "Epoch [473/500], Average Validation Loss: 0.4238, Average Validation Accuracy: 0.8134\n",
      "Epoch [474/500], Average Training Loss: 0.4193\n",
      "Epoch [474/500], Average Validation Loss: 0.4237, Average Validation Accuracy: 0.8132\n",
      "Epoch [475/500], Average Training Loss: 0.4193\n",
      "Epoch [475/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8137\n",
      "Epoch [476/500], Average Training Loss: 0.4193\n",
      "Epoch [476/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8135\n",
      "Epoch [477/500], Average Training Loss: 0.4193\n",
      "Epoch [477/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8137\n",
      "Epoch [478/500], Average Training Loss: 0.4192\n",
      "Epoch [478/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8137\n",
      "Epoch [479/500], Average Training Loss: 0.4192\n",
      "Epoch [479/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8138\n",
      "Epoch [480/500], Average Training Loss: 0.4191\n",
      "Epoch [480/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8137\n",
      "Epoch [481/500], Average Training Loss: 0.4192\n",
      "Epoch [481/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8137\n",
      "Epoch [482/500], Average Training Loss: 0.4191\n",
      "Epoch [482/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8135\n",
      "Epoch [483/500], Average Training Loss: 0.4191\n",
      "Epoch [483/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8138\n",
      "Epoch [484/500], Average Training Loss: 0.4191\n",
      "Epoch [484/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8135\n",
      "Epoch [485/500], Average Training Loss: 0.4191\n",
      "Epoch [485/500], Average Validation Loss: 0.4235, Average Validation Accuracy: 0.8138\n",
      "Epoch [486/500], Average Training Loss: 0.4190\n",
      "Epoch [486/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8136\n",
      "Epoch [487/500], Average Training Loss: 0.4191\n",
      "Epoch [487/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8138\n",
      "Epoch [488/500], Average Training Loss: 0.4190\n",
      "Epoch [488/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8136\n",
      "Epoch [489/500], Average Training Loss: 0.4189\n",
      "Epoch [489/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8137\n",
      "Epoch [490/500], Average Training Loss: 0.4189\n",
      "Epoch [490/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8137\n",
      "Epoch [491/500], Average Training Loss: 0.4188\n",
      "Epoch [491/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8139\n",
      "Epoch [492/500], Average Training Loss: 0.4189\n",
      "Epoch [492/500], Average Validation Loss: 0.4233, Average Validation Accuracy: 0.8138\n",
      "Epoch [493/500], Average Training Loss: 0.4190\n",
      "Epoch [493/500], Average Validation Loss: 0.4236, Average Validation Accuracy: 0.8134\n",
      "Epoch [494/500], Average Training Loss: 0.4190\n",
      "Epoch [494/500], Average Validation Loss: 0.4234, Average Validation Accuracy: 0.8135\n",
      "Epoch [495/500], Average Training Loss: 0.4188\n",
      "Epoch [495/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8135\n",
      "Epoch [496/500], Average Training Loss: 0.4189\n",
      "Epoch [496/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8137\n",
      "Epoch [497/500], Average Training Loss: 0.4188\n",
      "Epoch [497/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8138\n",
      "Epoch [498/500], Average Training Loss: 0.4188\n",
      "Epoch [498/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8139\n",
      "Epoch [499/500], Average Training Loss: 0.4188\n",
      "Epoch [499/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8136\n",
      "Epoch [500/500], Average Training Loss: 0.4187\n",
      "Epoch [500/500], Average Validation Loss: 0.4232, Average Validation Accuracy: 0.8140\n",
      "Best Validation Accuracy: 0.8140 at epoch 500 for trial 19\n",
      "Best accuracy: 0.8268\n",
      "Best parameters: {'Learning Rate': 0.0001, 'Batch Size': 128, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Epochs': 500}\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "NUM_TRAILS = 20\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "for t in range(NUM_TRAILS):\n",
    "    lr = random.choice(learning_rates)\n",
    "    batch_size = random.choice(batch_sizes)\n",
    "    optimizer_choice = random.choice(optimizers)\n",
    "    epochs = random.choice(epochs_range)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = FeedforwardNeuralNetModel(input_dim).to(device)\n",
    "    optimizer = optimizer_choice(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    accuracy = train_and_validate(model, criterion, optimizer, train_loader, val_loader, epochs, t)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = {\n",
    "            \"Learning Rate\": lr,\n",
    "            \"Batch Size\": batch_size,\n",
    "            \"Optimizer\": optimizer_choice,\n",
    "            \"Epochs\": epochs\n",
    "        }\n",
    "\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Learning Rate': 0.0001, 'Batch Size': 128, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Epochs': 500}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best for Relu activation forward NN : {'Learning Rate': 0.0001, 'Batch Size': 64, 'Optimizer': <class 'torch.optim.rmsprop.RMSprop'>, 'Epochs': 500}. Accuracy 0.822"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best for LeakyRelu forward NN : {'Learning Rate': 0.001, 'Batch Size': 256, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Epochs': 50}. Accuracy 0.825 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best for PRelu: {'Learning Rate': 0.0001, 'Batch Size': 32, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Epochs': 500} Accuracy 0.824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best for Tanh: Best parameters: {'Learning Rate': 0.0001, 'Batch Size': 128, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Epochs': 500} Accuracy 0.827"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
